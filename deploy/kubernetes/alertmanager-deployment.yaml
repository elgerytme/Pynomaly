apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/instance: production
    app.kubernetes.io/component: alerting
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'smtp.gmail.com:587'
      smtp_from: 'alerts@pynomaly.ai'
      smtp_auth_username: 'alerts@pynomaly.ai'
      smtp_auth_password: 'REPLACE_WITH_SMTP_PASSWORD'
      slack_api_url: 'REPLACE_WITH_SLACK_WEBHOOK'

    route:
      group_by: ['alertname']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'web.hook'
      routes:
      - match:
          severity: critical
        receiver: 'critical-alerts'
        group_wait: 5s
        repeat_interval: 5m
      - match:
          severity: warning
        receiver: 'warning-alerts'
        group_wait: 30s
        repeat_interval: 30m
      - match:
          alertname: PynomalyAPIDown
        receiver: 'api-down-alerts'
        group_wait: 5s
        repeat_interval: 2m
      - match:
          alertname: PostgreSQLDown
        receiver: 'database-alerts'
        group_wait: 5s
        repeat_interval: 5m
      - match:
          alertname: RedisDown
        receiver: 'cache-alerts'
        group_wait: 5s
        repeat_interval: 5m

    receivers:
    - name: 'web.hook'
      webhook_configs:
      - url: 'http://webhook-service:9093/hook'
        send_resolved: true
        http_config:
          basic_auth:
            username: 'webhook_user'
            password: 'REPLACE_WITH_WEBHOOK_PASSWORD'

    - name: 'critical-alerts'
      email_configs:
      - to: 'oncall@pynomaly.ai'
        subject: '[CRITICAL] Pynomaly Production Alert'
        body: |
          Alert: {{ .GroupLabels.alertname }}
          Summary: {{ .CommonAnnotations.summary }}
          Description: {{ .CommonAnnotations.description }}
          
          Details:
          {{ range .Alerts }}
          - Instance: {{ .Labels.instance }}
          - Status: {{ .Status }}
          - Started: {{ .StartsAt }}
          {{ end }}
          
          Dashboard: https://monitoring.pynomaly.ai/grafana
          Runbook: https://docs.pynomaly.ai/runbooks/{{ .GroupLabels.alertname }}
        headers:
          X-Priority: 'high'
      slack_configs:
      - channel: '#alerts-critical'
        title: 'üö® CRITICAL Alert - {{ .GroupLabels.alertname }}'
        text: |
          *Summary:* {{ .CommonAnnotations.summary }}
          *Description:* {{ .CommonAnnotations.description }}
          
          *Affected Services:*
          {{ range .Alerts }}
          ‚Ä¢ {{ .Labels.instance }} - {{ .Status }}
          {{ end }}
          
          <https://monitoring.pynomaly.ai/grafana|üìä Dashboard> | <https://docs.pynomaly.ai/runbooks/{{ .GroupLabels.alertname }}|üìñ Runbook>
        color: 'danger'
        send_resolved: true

    - name: 'warning-alerts'
      email_configs:
      - to: 'alerts@pynomaly.ai'
        subject: '[WARNING] Pynomaly Production Alert'
        body: |
          Alert: {{ .GroupLabels.alertname }}
          Summary: {{ .CommonAnnotations.summary }}
          Description: {{ .CommonAnnotations.description }}
          
          Details:
          {{ range .Alerts }}
          - Instance: {{ .Labels.instance }}
          - Status: {{ .Status }}
          - Started: {{ .StartsAt }}
          {{ end }}
          
          Dashboard: https://monitoring.pynomaly.ai/grafana
      slack_configs:
      - channel: '#alerts-warning'
        title: '‚ö†Ô∏è Warning - {{ .GroupLabels.alertname }}'
        text: |
          *Summary:* {{ .CommonAnnotations.summary }}
          *Description:* {{ .CommonAnnotations.description }}
          
          <https://monitoring.pynomaly.ai/grafana|üìä Dashboard>
        color: 'warning'
        send_resolved: true

    - name: 'api-down-alerts'
      email_configs:
      - to: 'oncall@pynomaly.ai, dev-team@pynomaly.ai'
        subject: '[URGENT] Pynomaly API is DOWN'
        body: |
          üö® URGENT: The Pynomaly API is currently down!
          
          This affects all users and integrations. Immediate attention required.
          
          Time: {{ .CommonAnnotations.startsAt }}
          Duration: {{ .CommonAnnotations.duration }}
          
          Immediate Actions:
          1. Check API pods: kubectl get pods -n pynomaly-production -l app.kubernetes.io/component=api
          2. Check logs: kubectl logs -n pynomaly-production -l app.kubernetes.io/component=api --tail=100
          3. Check load balancer health
          4. Verify database connectivity
          
          Dashboard: https://monitoring.pynomaly.ai/grafana
          Incident Response: https://docs.pynomaly.ai/incident-response
        headers:
          X-Priority: 'urgent'
      slack_configs:
      - channel: '#incidents'
        title: 'üö® URGENT: Pynomaly API DOWN'
        text: |
          <!channel> The Pynomaly API is currently down!
          
          This is affecting all users and integrations.
          
          *Immediate Actions Required:*
          1. Check API pods and logs
          2. Verify load balancer and database
          3. Start incident response procedure
          
          <https://monitoring.pynomaly.ai/grafana|üìä Dashboard> | <https://docs.pynomaly.ai/incident-response|üö® Incident Response>
        color: 'danger'
        send_resolved: true

    - name: 'database-alerts'
      email_configs:
      - to: 'dba@pynomaly.ai, oncall@pynomaly.ai'
        subject: '[CRITICAL] Database Issue - {{ .GroupLabels.alertname }}'
        body: |
          üö® CRITICAL: Database issue detected!
          
          Alert: {{ .GroupLabels.alertname }}
          Summary: {{ .CommonAnnotations.summary }}
          
          This may affect data integrity and application functionality.
          
          Immediate Actions:
          1. Check PostgreSQL pod status
          2. Verify data consistency
          3. Check backup status
          4. Monitor disk space and performance
          
          Dashboard: https://monitoring.pynomaly.ai/grafana
          Database Runbook: https://docs.pynomaly.ai/runbooks/database
      slack_configs:
      - channel: '#database-alerts'
        title: 'üóÑÔ∏è Database Alert - {{ .GroupLabels.alertname }}'
        text: |
          *Summary:* {{ .CommonAnnotations.summary }}
          
          Database issue detected - may affect data operations.
          
          <https://monitoring.pynomaly.ai/grafana|üìä Dashboard> | <https://docs.pynomaly.ai/runbooks/database|üìñ Database Runbook>
        color: 'danger'
        send_resolved: true

    - name: 'cache-alerts'
      email_configs:
      - to: 'oncall@pynomaly.ai'
        subject: '[WARNING] Redis Cache Issue'
        body: |
          ‚ö†Ô∏è WARNING: Redis cache issue detected!
          
          This may affect application performance but not core functionality.
          
          Alert: {{ .GroupLabels.alertname }}
          Summary: {{ .CommonAnnotations.summary }}
          
          Actions:
          1. Check Redis pod status
          2. Verify memory usage
          3. Monitor cache hit rates
          4. Consider cache warmup if needed
          
          Dashboard: https://monitoring.pynomaly.ai/grafana
      slack_configs:
      - channel: '#cache-alerts'
        title: 'üíæ Cache Alert - {{ .GroupLabels.alertname }}'
        text: |
          *Summary:* {{ .CommonAnnotations.summary }}
          
          Redis cache issue - may affect performance.
          
          <https://monitoring.pynomaly.ai/grafana|üìä Dashboard>
        color: 'warning'
        send_resolved: true

    inhibit_rules:
    # Inhibit any warning-level alerts when the same alert is critical
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'instance']

    # Inhibit API alerts when the entire service is down
    - source_match:
        alertname: 'PynomalyAPIDown'
      target_match_re:
        alertname: 'Pynomaly.*'
      equal: ['instance']

    templates:
    - '/etc/alertmanager/templates/*.tmpl'
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-templates
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/instance: production
    app.kubernetes.io/component: alerting
data:
  default.tmpl: |
    {{ define "__alertmanager" }}AlertManager{{ end }}
    {{ define "__alertmanagerURL" }}{{ .ExternalURL }}/#/alerts?receiver={{ .Receiver }}{{ end }}

    {{ define "__subject" }}[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .GroupLabels.SortedPairs.Values | join " " }} {{ if gt (len .CommonLabels) (len .GroupLabels) }}({{ with .CommonLabels.Remove .GroupLabels.Names }}{{ .Values | join " " }}{{ end }}){{ end }}{{ end }}

    {{ define "__description" }}{{ end }}

    {{ define "__text_alert_list" }}{{ range . }}Labels:
    {{ range .Labels.SortedPairs }} - {{ .Name }} = {{ .Value }}
    {{ end }}Annotations:
    {{ range .Annotations.SortedPairs }} - {{ .Name }} = {{ .Value }}
    {{ end }}Source: {{ .GeneratorURL }}
    {{ end }}{{ end }}

    {{ define "slack.pynomaly.title" }}
    {{- if eq .Status "firing" -}}
    üö® [{{ .Status | title }}{{ if gt (len .Alerts.Firing) 1 }} - {{ len .Alerts.Firing }}{{ end }}] 
    {{- else -}}
    ‚úÖ [{{ .Status | title }}{{ if gt (len .Alerts.Resolved) 1 }} - {{ len .Alerts.Resolved }}{{ end }}] 
    {{- end -}}
    {{ .GroupLabels.alertname }}{{ if .CommonLabels.instance }} on {{ .CommonLabels.instance }}{{ end }}
    {{ end }}

    {{ define "slack.pynomaly.text" }}
    {{- if eq .Status "firing" -}}
    *Alert Summary:*
    {{ range .Alerts.Firing }}
    ‚Ä¢ *{{ .Annotations.summary }}*
    {{ if .Annotations.description }}  {{ .Annotations.description }}{{ end }}
    {{ if .Annotations.runbook_url }}  üìñ <{{ .Annotations.runbook_url }}|Runbook>{{ end }}
    {{ end }}
    {{- else -}}
    *Resolved:*
    {{ range .Alerts.Resolved }}
    ‚Ä¢ {{ .Annotations.summary }}
    {{ end }}
    {{- end }}

    *Details:*
    {{ range .Alerts }}
    {{ if .Labels.instance }}‚Ä¢ Instance: `{{ .Labels.instance }}`{{ end }}
    {{ if .Labels.job }}‚Ä¢ Job: `{{ .Labels.job }}`{{ end }}
    {{ if .Labels.severity }}‚Ä¢ Severity: `{{ .Labels.severity }}`{{ end }}
    {{ end }}

    <{{ .ExternalURL }}|üîó AlertManager> | <https://monitoring.pynomaly.ai/grafana|üìä Grafana>
    {{ end }}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/instance: production
    app.kubernetes.io/component: alerting
    app.kubernetes.io/version: "0.26"
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/instance: production
      app.kubernetes.io/component: alerting
  template:
    metadata:
      labels:
        app.kubernetes.io/name: alertmanager
        app.kubernetes.io/instance: production
        app.kubernetes.io/component: alerting
        app.kubernetes.io/version: "0.26"
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        runAsGroup: 65534
        fsGroup: 65534
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: alertmanager
        image: prom/alertmanager:v0.26.0
        imagePullPolicy: IfNotPresent
        args:
        - --config.file=/etc/alertmanager/alertmanager.yml
        - --storage.path=/alertmanager
        - --web.external-url=https://monitoring.pynomaly.ai/alertmanager
        - --web.route-prefix=/alertmanager
        - --cluster.listen-address=0.0.0.0:9094
        - --cluster.advertise-address=$(POD_IP):9094
        - --log.level=info
        env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        ports:
        - name: web
          containerPort: 9093
          protocol: TCP
        - name: cluster
          containerPort: 9094
          protocol: TCP
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 65534
          runAsGroup: 65534
          capabilities:
            drop:
            - ALL
        volumeMounts:
        - name: config
          mountPath: /etc/alertmanager
        - name: templates
          mountPath: /etc/alertmanager/templates
        - name: storage
          mountPath: /alertmanager
        livenessProbe:
          httpGet:
            path: /alertmanager/-/healthy
            port: web
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /alertmanager/-/ready
            port: web
          initialDelaySeconds: 30
          periodSeconds: 5
          timeoutSeconds: 4
          failureThreshold: 3
      volumes:
      - name: config
        configMap:
          name: alertmanager-config
      - name: templates
        configMap:
          name: alertmanager-templates
      - name: storage
        persistentVolumeClaim:
          claimName: alertmanager-storage-pvc
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app.kubernetes.io/name
                  operator: In
                  values:
                  - alertmanager
              topologyKey: kubernetes.io/hostname
---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager-service
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/instance: production
    app.kubernetes.io/component: alerting
spec:
  type: ClusterIP
  ports:
  - name: web
    port: 9093
    targetPort: web
    protocol: TCP
  - name: cluster
    port: 9094
    targetPort: cluster
    protocol: TCP
  selector:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/instance: production
    app.kubernetes.io/component: alerting
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: alertmanager-storage-pvc
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/instance: production
    app.kubernetes.io/component: alerting
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: gp3-encrypted
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: blackbox-config
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: blackbox-exporter
    app.kubernetes.io/instance: production
    app.kubernetes.io/component: monitoring
data:
  blackbox.yml: |
    modules:
      http_2xx:
        prober: http
        timeout: 5s
        http:
          valid_http_versions: ["HTTP/1.1", "HTTP/2.0"]
          valid_status_codes: []  # Defaults to 2xx
          method: GET
          headers:
            Host: api.pynomaly.ai
            User-Agent: "Blackbox Exporter"
          preferred_ip_protocol: "ip4"
          ip_protocol_fallback: false
          fail_if_ssl: false
          fail_if_not_ssl: true
          tls_config:
            insecure_skip_verify: false

      http_health_check:
        prober: http
        timeout: 10s
        http:
          valid_http_versions: ["HTTP/1.1", "HTTP/2.0"]
          valid_status_codes: [200]
          method: GET
          headers:
            Host: api.pynomaly.ai
          preferred_ip_protocol: "ip4"
          fail_if_not_ssl: true
          tls_config:
            insecure_skip_verify: false

      tcp_connect:
        prober: tcp
        timeout: 5s
        tcp:
          preferred_ip_protocol: "ip4"

      icmp:
        prober: icmp
        timeout: 5s
        icmp:
          preferred_ip_protocol: "ip4"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blackbox-exporter
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: blackbox-exporter
    app.kubernetes.io/instance: production
    app.kubernetes.io/component: monitoring
    app.kubernetes.io/version: "0.24"
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: blackbox-exporter
      app.kubernetes.io/instance: production
      app.kubernetes.io/component: monitoring
  template:
    metadata:
      labels:
        app.kubernetes.io/name: blackbox-exporter
        app.kubernetes.io/instance: production
        app.kubernetes.io/component: monitoring
        app.kubernetes.io/version: "0.24"
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        runAsGroup: 65534
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: blackbox-exporter
        image: prom/blackbox-exporter:v0.24.0
        imagePullPolicy: IfNotPresent
        args:
        - --config.file=/config/blackbox.yml
        - --web.listen-address=:9115
        - --log.level=info
        ports:
        - name: http
          containerPort: 9115
          protocol: TCP
        resources:
          requests:
            memory: "32Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "200m"
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 65534
          runAsGroup: 65534
          capabilities:
            drop:
            - ALL
            add:
            - NET_RAW  # Required for ICMP probes
        volumeMounts:
        - name: config
          mountPath: /config
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: http
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /-/ready
            port: http
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 4
          failureThreshold: 3
      volumes:
      - name: config
        configMap:
          name: blackbox-config
---
apiVersion: v1
kind: Service
metadata:
  name: blackbox-exporter-service
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: blackbox-exporter
    app.kubernetes.io/instance: production
    app.kubernetes.io/component: monitoring
spec:
  type: ClusterIP
  ports:
  - name: http
    port: 9115
    targetPort: http
    protocol: TCP
  selector:
    app.kubernetes.io/name: blackbox-exporter
    app.kubernetes.io/instance: production
    app.kubernetes.io/component: monitoring