# Pynomaly Alert Rules
groups:
  - name: pynomaly-application
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: (
          rate(pynomaly_http_requests_total{status=~"5.."}[5m]) /
          rate(pynomaly_http_requests_total[5m])
        ) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.job }}"

      # Critical error rate
      - alert: CriticalErrorRate
        expr: (
          rate(pynomaly_http_requests_total{status=~"5.."}[5m]) /
          rate(pynomaly_http_requests_total[5m])
        ) > 0.25
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Critical error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.job }}"

      # High response time
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(pynomaly_http_request_duration_seconds_bucket[5m])) > 2.0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s for {{ $labels.job }}"

      # Memory usage
      - alert: HighMemoryUsage
        expr: (pynomaly_memory_usage_bytes / pynomaly_memory_limit_bytes) > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ $value | humanizePercentage }} for {{ $labels.job }}"

      # Critical memory usage
      - alert: CriticalMemoryUsage
        expr: (pynomaly_memory_usage_bytes / pynomaly_memory_limit_bytes) > 0.9
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Critical memory usage detected"
          description: "Memory usage is {{ $value | humanizePercentage }} for {{ $labels.job }}"

      # High detection failure rate
      - alert: HighDetectionFailureRate
        expr: (
          rate(pynomaly_detections_total{status="failed"}[5m]) /
          rate(pynomaly_detections_total[5m])
        ) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High detection failure rate"
          description: "Detection failure rate is {{ $value | humanizePercentage }}"

      # Training job failures
      - alert: TrainingJobFailures
        expr: increase(pynomaly_training_jobs_total{status="failed"}[1h]) > 5
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: "Multiple training job failures"
          description: "{{ $value }} training jobs have failed in the last hour"

      # Database connection issues
      - alert: DatabaseConnectionIssues
        expr: pynomaly_database_connections_active == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Database connection issues"
          description: "No active database connections detected"

      # Cache hit rate too low
      - alert: LowCacheHitRate
        expr: (
          rate(pynomaly_cache_hits_total[5m]) /
          (rate(pynomaly_cache_hits_total[5m]) + rate(pynomaly_cache_misses_total[5m]))
        ) < 0.5
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Low cache hit rate"
          description: "Cache hit rate is {{ $value | humanizePercentage }}"

  - name: pynomaly-infrastructure
    rules:
      # Service down
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service is down"
          description: "{{ $labels.job }} has been down for more than 1 minute"

      # High CPU usage
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }}"

      # High disk usage
      - alert: HighDiskUsage
        expr: (
          (node_filesystem_size_bytes{fstype!="tmpfs"} - node_filesystem_avail_bytes{fstype!="tmpfs"}) /
          node_filesystem_size_bytes{fstype!="tmpfs"}
        ) > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High disk usage"
          description: "Disk usage is {{ $value | humanizePercentage }} on {{ $labels.instance }}"

      # Redis down
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis is down"
          description: "Redis instance {{ $labels.instance }} is down"

      # PostgreSQL down
      - alert: PostgreSQLDown
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL instance {{ $labels.instance }} is down"

      # Elasticsearch cluster health
      - alert: ElasticsearchClusterNotHealthy
        expr: elasticsearch_cluster_health_status{color="red"} == 1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Elasticsearch cluster is not healthy"
          description: "Elasticsearch cluster health is RED"

      # High number of pending tasks
      - alert: HighPendingTasks
        expr: pynomaly_pending_tasks > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High number of pending tasks"
          description: "{{ $value }} tasks are pending processing"