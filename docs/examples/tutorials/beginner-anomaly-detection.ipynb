{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginner's Guide to Anomaly Detection with Pynomaly\n",
    "\n",
    "Welcome to the world of anomaly detection! This tutorial will teach you the fundamentals of detecting outliers and anomalies in data using Pynomaly.\n",
    "\n",
    "## 📚 What You'll Learn\n",
    "\n",
    "1. **What is anomaly detection?**\n",
    "2. **Types of anomalies**\n",
    "3. **Basic detection algorithms**\n",
    "4. **Hands-on implementation**\n",
    "5. **Evaluation and interpretation**\n",
    "6. **Real-world applications**\n",
    "\n",
    "## 🎯 Prerequisites\n",
    "\n",
    "- Basic Python knowledge\n",
    "- Familiarity with pandas and numpy\n",
    "- High school level statistics\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Anomaly Detection\n",
    "\n",
    "### What is an Anomaly?\n",
    "\n",
    "An **anomaly** (also called an outlier) is a data point that significantly differs from the majority of the data. Think of it as:\n",
    "\n",
    "- A fraudulent credit card transaction among normal purchases\n",
    "- A faulty sensor reading in a smart home system\n",
    "- An unusual network access pattern indicating a security breach\n",
    "- A defective product in a manufacturing line\n",
    "\n",
    "### Why is Anomaly Detection Important?\n",
    "\n",
    "- **Security**: Detect cyber attacks and fraud\n",
    "- **Quality Control**: Find defective products\n",
    "- **Health Monitoring**: Identify system failures early\n",
    "- **Business Intelligence**: Discover unusual customer behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by installing and importing the necessary libraries\n",
    "# If you haven't installed pynomaly yet, uncomment the next line:\n",
    "# !pip install pynomaly\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_blobs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(\"🚀 Ready to explore anomaly detection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Types of Anomalies\n",
    "\n",
    "There are three main types of anomalies:\n",
    "\n",
    "### 1. Point Anomalies\n",
    "Individual data points that are unusual\n",
    "\n",
    "### 2. Contextual Anomalies\n",
    "Data points that are normal in one context but anomalous in another\n",
    "\n",
    "### 3. Collective Anomalies\n",
    "A collection of data points that together form an anomalous pattern\n",
    "\n",
    "Let's create some example data to visualize these concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data to demonstrate different types of anomalies\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate normal data points\n",
    "normal_data = np.random.normal(0, 1, (200, 2))\n",
    "\n",
    "# Add point anomalies (outliers)\n",
    "point_anomalies = np.array([[-4, -4], [4, 4], [-3, 4], [4, -3]])\n",
    "\n",
    "# Combine data\n",
    "all_data = np.vstack([normal_data, point_anomalies])\n",
    "labels = np.hstack([np.zeros(200), np.ones(4)])  # 0 = normal, 1 = anomaly\n",
    "\n",
    "# Create a DataFrame for easier handling\n",
    "df = pd.DataFrame(all_data, columns=['Feature_1', 'Feature_2'])\n",
    "df['Is_Anomaly'] = labels\n",
    "\n",
    "print(f\"Dataset created with {len(df)} data points\")\n",
    "print(f\"Normal points: {sum(labels == 0)}\")\n",
    "print(f\"Anomalous points: {sum(labels == 1)}\")\n",
    "print(f\"Anomaly rate: {sum(labels == 1) / len(labels):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize our data\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot normal points\n",
    "normal_points = df[df['Is_Anomaly'] == 0]\n",
    "anomaly_points = df[df['Is_Anomaly'] == 1]\n",
    "\n",
    "plt.scatter(normal_points['Feature_1'], normal_points['Feature_2'], \n",
    "           c='blue', alpha=0.6, label='Normal Points', s=30)\n",
    "plt.scatter(anomaly_points['Feature_1'], anomaly_points['Feature_2'], \n",
    "           c='red', alpha=0.8, label='Anomalies', s=100, marker='x')\n",
    "\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Point Anomalies Example')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"👆 Notice how the red X marks are clearly separated from the blue cluster!\")\n",
    "print(\"These are classic examples of point anomalies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Your First Anomaly Detection Algorithm\n",
    "\n",
    "Let's start with the simplest method: **Statistical Outlier Detection** using the Z-score.\n",
    "\n",
    "### Z-Score Method\n",
    "\n",
    "The Z-score tells us how many standard deviations a point is from the mean:\n",
    "\n",
    "```\n",
    "Z = (x - μ) / σ\n",
    "```\n",
    "\n",
    "Where:\n",
    "- x = data point\n",
    "- μ = mean\n",
    "- σ = standard deviation\n",
    "\n",
    "Typically, points with |Z| > 3 are considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's implement a simple Z-score anomaly detector\n",
    "def detect_anomalies_zscore(data, threshold=3):\n",
    "    \"\"\"\n",
    "    Detect anomalies using Z-score method.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: array-like, the data to analyze\n",
    "    - threshold: float, Z-score threshold (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "    - anomalies: boolean array, True for anomalies\n",
    "    - z_scores: float array, Z-scores for each point\n",
    "    \"\"\"\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    \n",
    "    # Calculate Z-scores\n",
    "    z_scores = np.abs((data - mean) / std)\n",
    "    \n",
    "    # Identify anomalies\n",
    "    anomalies = z_scores > threshold\n",
    "    \n",
    "    return anomalies, z_scores\n",
    "\n",
    "# Let's test it on a simple 1D dataset\n",
    "# Create sample data with some outliers\n",
    "np.random.seed(42)\n",
    "sample_data = np.concatenate([\n",
    "    np.random.normal(0, 1, 100),  # Normal data\n",
    "    [5, -5, 6]  # Clear outliers\n",
    "])\n",
    "\n",
    "# Detect anomalies\n",
    "anomalies, z_scores = detect_anomalies_zscore(sample_data)\n",
    "\n",
    "print(f\"Total data points: {len(sample_data)}\")\n",
    "print(f\"Anomalies detected: {sum(anomalies)}\")\n",
    "print(f\"Anomaly indices: {np.where(anomalies)[0]}\")\n",
    "print(f\"Anomaly values: {sample_data[anomalies]}\")\n",
    "print(f\"Z-scores of anomalies: {z_scores[anomalies]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Z-score results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Data points\n",
    "plt.subplot(1, 2, 1)\n",
    "normal_indices = ~anomalies\n",
    "plt.scatter(range(len(sample_data)), sample_data, c='blue', alpha=0.6, label='Normal')\n",
    "plt.scatter(np.where(anomalies)[0], sample_data[anomalies], \n",
    "           c='red', s=100, marker='x', label='Anomalies')\n",
    "plt.xlabel('Data Point Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Detected Anomalies')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Z-scores\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(len(z_scores)), z_scores, \n",
    "        color=['red' if a else 'blue' for a in anomalies], alpha=0.7)\n",
    "plt.axhline(y=3, color='red', linestyle='--', label='Threshold (Z=3)')\n",
    "plt.xlabel('Data Point Index')\n",
    "plt.ylabel('Z-Score')\n",
    "plt.title('Z-Scores for Each Point')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"🎯 The red bars show Z-scores above the threshold of 3!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Introduction to Pynomaly\n",
    "\n",
    "Now let's use Pynomaly's built-in algorithms. Pynomaly provides many advanced algorithms that work better than simple statistical methods, especially for complex, multi-dimensional data.\n",
    "\n",
    "### Isolation Forest\n",
    "\n",
    "Isolation Forest is one of the most popular anomaly detection algorithms. It works by:\n",
    "\n",
    "1. **Randomly selecting** a feature and a split value\n",
    "2. **Isolating** points by splitting the data\n",
    "3. **Measuring** how many splits it takes to isolate each point\n",
    "4. **Anomalies** require fewer splits (easier to isolate)\n",
    "\n",
    "Think of it like this: if you're in a crowded room, it's hard to isolate you. But if you're standing alone in a corner, it's easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pynomaly's Isolation Forest\n",
    "from pynomaly.detectors import IsolationForest\n",
    "\n",
    "# Let's go back to our 2D dataset\n",
    "X = df[['Feature_1', 'Feature_2']].values\n",
    "y_true = df['Is_Anomaly'].values\n",
    "\n",
    "# Create and train the Isolation Forest detector\n",
    "# contamination = expected proportion of anomalies in the data\n",
    "detector = IsolationForest(\n",
    "    contamination=0.02,  # We expect about 2% of data to be anomalies\n",
    "    random_state=42,     # For reproducible results\n",
    "    n_estimators=100     # Number of trees in the forest\n",
    ")\n",
    "\n",
    "# Fit the detector to our data\n",
    "detector.fit(X)\n",
    "\n",
    "# Get predictions (-1 for anomaly, 1 for normal)\n",
    "predictions = detector.predict(X)\n",
    "\n",
    "# Convert to binary (0 for normal, 1 for anomaly)\n",
    "predicted_anomalies = (predictions == -1).astype(int)\n",
    "\n",
    "# Get anomaly scores (lower scores indicate more anomalous)\n",
    "anomaly_scores = detector.decision_function(X)\n",
    "\n",
    "print(f\"Total data points: {len(X)}\")\n",
    "print(f\"Predicted anomalies: {sum(predicted_anomalies)}\")\n",
    "print(f\"Actual anomalies: {sum(y_true)}\")\n",
    "print(f\"Detection rate: {sum(predicted_anomalies & y_true) / sum(y_true):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Isolation Forest results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: True anomalies vs predictions\n",
    "plt.subplot(1, 3, 1)\n",
    "colors = ['blue' if p == 0 else 'red' for p in predicted_anomalies]\n",
    "plt.scatter(X[:, 0], X[:, 1], c=colors, alpha=0.6)\n",
    "plt.title('Isolation Forest Predictions')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "# Plot 2: Anomaly scores\n",
    "plt.subplot(1, 3, 2)\n",
    "scatter = plt.scatter(X[:, 0], X[:, 1], c=anomaly_scores, \n",
    "                     cmap='viridis', alpha=0.7)\n",
    "plt.colorbar(scatter, label='Anomaly Score')\n",
    "plt.title('Anomaly Scores\\n(Lower = More Anomalous)')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "# Plot 3: True vs Predicted\n",
    "plt.subplot(1, 3, 3)\n",
    "# Normal points correctly classified\n",
    "correct_normal = (y_true == 0) & (predicted_anomalies == 0)\n",
    "# Anomalies correctly detected\n",
    "correct_anomaly = (y_true == 1) & (predicted_anomalies == 1)\n",
    "# False positives\n",
    "false_positive = (y_true == 0) & (predicted_anomalies == 1)\n",
    "# False negatives\n",
    "false_negative = (y_true == 1) & (predicted_anomalies == 0)\n",
    "\n",
    "plt.scatter(X[correct_normal, 0], X[correct_normal, 1], \n",
    "           c='green', alpha=0.6, label='Correct Normal', s=30)\n",
    "plt.scatter(X[correct_anomaly, 0], X[correct_anomaly, 1], \n",
    "           c='red', marker='x', s=100, label='Correct Anomaly')\n",
    "plt.scatter(X[false_positive, 0], X[false_positive, 1], \n",
    "           c='orange', marker='^', s=60, label='False Positive')\n",
    "plt.scatter(X[false_negative, 0], X[false_negative, 1], \n",
    "           c='purple', marker='v', s=60, label='False Negative')\n",
    "\n",
    "plt.title('Classification Results')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"🎯 Green dots: Normal points correctly identified\")\n",
    "print(\"❌ Red X's: Anomalies correctly detected\")\n",
    "print(\"🔺 Orange triangles: False positives (normal labeled as anomaly)\")\n",
    "print(\"🔻 Purple triangles: False negatives (anomaly missed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluating Anomaly Detection Performance\n",
    "\n",
    "How do we know if our detector is working well? We use several metrics:\n",
    "\n",
    "### Key Metrics:\n",
    "\n",
    "- **Precision**: Of all points flagged as anomalies, how many are actually anomalies?\n",
    "- **Recall**: Of all actual anomalies, how many did we detect?\n",
    "- **F1-Score**: Harmonic mean of precision and recall\n",
    "- **AUC-ROC**: Area under the ROC curve (measures overall performance)\n",
    "\n",
    "### Business Perspective:\n",
    "\n",
    "- **High Precision**: Few false alarms, but might miss some anomalies\n",
    "- **High Recall**: Catch most anomalies, but might have false alarms\n",
    "- **Balance**: Usually we want a good balance between both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_true, predicted_anomalies)\n",
    "recall = recall_score(y_true, predicted_anomalies)\n",
    "f1 = f1_score(y_true, predicted_anomalies)\n",
    "auc = roc_auc_score(y_true, -anomaly_scores)  # Note: negative scores because lower = more anomalous\n",
    "\n",
    "print(\"🔍 Performance Metrics:\")\n",
    "print(f\"Precision: {precision:.3f} ({precision:.1%})\")\n",
    "print(f\"Recall:    {recall:.3f} ({recall:.1%})\")\n",
    "print(f\"F1-Score:  {f1:.3f} ({f1:.1%})\")\n",
    "print(f\"AUC-ROC:   {auc:.3f} ({auc:.1%})\")\n",
    "\n",
    "print(\"\\n📊 What this means:\")\n",
    "print(f\"• Out of {sum(predicted_anomalies)} flagged anomalies, {sum(predicted_anomalies & y_true)} were actually anomalous\")\n",
    "print(f\"• Out of {sum(y_true)} actual anomalies, {sum(predicted_anomalies & y_true)} were detected\")\n",
    "print(f\"• We missed {sum(y_true) - sum(predicted_anomalies & y_true)} anomalies\")\n",
    "print(f\"• We had {sum(predicted_anomalies & (1-y_true))} false alarms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_true, predicted_anomalies)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                             display_labels=['Normal', 'Anomaly'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix\\nIsolation Forest Results')\n",
    "\n",
    "# Add explanations\n",
    "plt.text(0.5, -0.1, \n",
    "         f\"True Negatives: {cm[0,0]} | False Positives: {cm[0,1]}\\n\" +\n",
    "         f\"False Negatives: {cm[1,0]} | True Positives: {cm[1,1]}\", \n",
    "         transform=plt.gca().transAxes, ha='center', fontsize=10)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"📖 Reading the Confusion Matrix:\")\n",
    "print(\"• Top-left (True Negatives): Normal points correctly identified as normal\")\n",
    "print(\"• Top-right (False Positives): Normal points incorrectly flagged as anomalies\")\n",
    "print(\"• Bottom-left (False Negatives): Anomalies missed by the detector\")\n",
    "print(\"• Bottom-right (True Positives): Anomalies correctly detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparing Different Algorithms\n",
    "\n",
    "Let's compare multiple anomaly detection algorithms to see which works best for our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import multiple detectors from Pynomaly\n",
    "from pynomaly.detectors import (\n",
    "    IsolationForest, \n",
    "    LocalOutlierFactor, \n",
    "    OneClassSVM,\n",
    "    EllipticEnvelope\n",
    ")\n",
    "\n",
    "# Define our detectors\n",
    "detectors = {\n",
    "    'Isolation Forest': IsolationForest(contamination=0.02, random_state=42),\n",
    "    'Local Outlier Factor': LocalOutlierFactor(contamination=0.02),\n",
    "    'One-Class SVM': OneClassSVM(nu=0.02),  # nu is similar to contamination\n",
    "    'Elliptic Envelope': EllipticEnvelope(contamination=0.02, random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "print(\"🔄 Training and evaluating detectors...\\n\")\n",
    "\n",
    "for name, detector in detectors.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Fit and predict\n",
    "    if name == 'Local Outlier Factor':\n",
    "        # LOF doesn't have separate fit/predict methods\n",
    "        predictions = detector.fit_predict(X)\n",
    "    else:\n",
    "        detector.fit(X)\n",
    "        predictions = detector.predict(X)\n",
    "    \n",
    "    # Convert predictions to binary\n",
    "    predicted_anomalies = (predictions == -1).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_true, predicted_anomalies)\n",
    "    recall = recall_score(y_true, predicted_anomalies)\n",
    "    f1 = f1_score(y_true, predicted_anomalies)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'predictions': predicted_anomalies\n",
    "    }\n",
    "    \n",
    "    print(f\"  Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "print(\"\\n✅ All detectors trained and evaluated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison chart\n",
    "import pandas as pd\n",
    "\n",
    "# Convert results to DataFrame for easy visualization\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.drop('predictions', axis=1)  # Remove predictions column for plotting\n",
    "\n",
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot each metric\n",
    "metrics = ['precision', 'recall', 'f1_score']\n",
    "titles = ['Precision', 'Recall', 'F1-Score']\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "\n",
    "for i, (metric, title, color) in enumerate(zip(metrics, titles, colors)):\n",
    "    ax = axes[i]\n",
    "    bars = ax.bar(results_df.index, results_df[metric], color=color, alpha=0.7)\n",
    "    ax.set_title(f'{title} Comparison')\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, results_df[metric]):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "               f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find the best performer\n",
    "best_f1 = results_df['f1_score'].idxmax()\n",
    "print(f\"🏆 Best overall performer (F1-Score): {best_f1}\")\n",
    "print(f\"   F1-Score: {results_df.loc[best_f1, 'f1_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Real-World Example: Credit Card Fraud Detection\n",
    "\n",
    "Let's apply what we've learned to a realistic scenario: detecting fraudulent credit card transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic credit card transaction dataset\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate features for normal transactions\n",
    "n_normal = 5000\n",
    "n_fraud = 50  # 1% fraud rate (realistic)\n",
    "\n",
    "# Normal transactions\n",
    "normal_amounts = np.random.lognormal(mean=3, sigma=1, size=n_normal)  # $20-$200 typical\n",
    "normal_times = np.random.uniform(6, 22, size=n_normal)  # Business hours\n",
    "normal_locations = np.random.choice(['domestic'], size=n_normal)  # Domestic transactions\n",
    "normal_frequency = np.random.poisson(3, size=n_normal)  # 3 transactions per day average\n",
    "\n",
    "# Fraudulent transactions (different patterns)\n",
    "fraud_amounts = np.concatenate([\n",
    "    np.random.uniform(1000, 5000, size=n_fraud//2),  # Large amounts\n",
    "    np.random.uniform(1, 5, size=n_fraud//2)        # Very small amounts\n",
    "])\n",
    "fraud_times = np.random.uniform(0, 4, size=n_fraud)  # Night hours\n",
    "fraud_locations = np.random.choice(['foreign'], size=n_fraud)  # Foreign transactions\n",
    "fraud_frequency = np.random.poisson(10, size=n_fraud)  # High frequency\n",
    "\n",
    "# Combine data\n",
    "amounts = np.concatenate([normal_amounts, fraud_amounts])\n",
    "times = np.concatenate([normal_times, fraud_times])\n",
    "is_foreign = np.concatenate(\n",
    "    [np.zeros(n_normal), np.ones(n_fraud)]  # 0=domestic, 1=foreign\n",
    ")\n",
    "frequency = np.concatenate([normal_frequency, fraud_frequency])\n",
    "labels = np.concatenate([np.zeros(n_normal), np.ones(n_fraud)])  # 0=normal, 1=fraud\n",
    "\n",
    "# Create DataFrame\n",
    "fraud_df = pd.DataFrame({\n",
    "    'amount': amounts,\n",
    "    'hour_of_day': times,\n",
    "    'is_foreign': is_foreign,\n",
    "    'daily_frequency': frequency,\n",
    "    'is_fraud': labels\n",
    "})\n",
    "\n",
    "# Add derived features\n",
    "fraud_df['amount_log'] = np.log1p(fraud_df['amount'])\n",
    "fraud_df['is_night'] = (fraud_df['hour_of_day'] < 6).astype(int)\n",
    "fraud_df['high_frequency'] = (fraud_df['daily_frequency'] > 5).astype(int)\n",
    "\n",
    "print(f\"📊 Credit Card Dataset Created:\")\n",
    "print(f\"Total transactions: {len(fraud_df):,}\")\n",
    "print(f\"Normal transactions: {sum(fraud_df['is_fraud'] == 0):,}\")\n",
    "print(f\"Fraudulent transactions: {sum(fraud_df['is_fraud'] == 1):,}\")\n",
    "print(f\"Fraud rate: {fraud_df['is_fraud'].mean():.1%}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\n📋 Sample transactions:\")\n",
    "print(fraud_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the fraud patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Amount distribution\n",
    "axes[0,0].hist(fraud_df[fraud_df['is_fraud']==0]['amount'], bins=50, alpha=0.7, label='Normal', density=True)\n",
    "axes[0,0].hist(fraud_df[fraud_df['is_fraud']==1]['amount'], bins=20, alpha=0.7, label='Fraud', density=True)\n",
    "axes[0,0].set_xlabel('Transaction Amount ($)')\n",
    "axes[0,0].set_ylabel('Density')\n",
    "axes[0,0].set_title('Transaction Amount Distribution')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].set_xlim(0, 1000)  # Focus on lower amounts for visibility\n",
    "\n",
    "# Time of day distribution\n",
    "axes[0,1].hist(fraud_df[fraud_df['is_fraud']==0]['hour_of_day'], bins=24, alpha=0.7, label='Normal', density=True)\n",
    "axes[0,1].hist(fraud_df[fraud_df['is_fraud']==1]['hour_of_day'], bins=24, alpha=0.7, label='Fraud', density=True)\n",
    "axes[0,1].set_xlabel('Hour of Day')\n",
    "axes[0,1].set_ylabel('Density')\n",
    "axes[0,1].set_title('Transaction Time Distribution')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Foreign transaction comparison\n",
    "foreign_counts = fraud_df.groupby(['is_foreign', 'is_fraud']).size().unstack()\n",
    "foreign_counts.plot(kind='bar', ax=axes[1,0], color=['blue', 'red'], alpha=0.7)\n",
    "axes[1,0].set_xlabel('Location (0=Domestic, 1=Foreign)')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].set_title('Domestic vs Foreign Transactions')\n",
    "axes[1,0].legend(['Normal', 'Fraud'])\n",
    "axes[1,0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Frequency distribution\n",
    "axes[1,1].hist(fraud_df[fraud_df['is_fraud']==0]['daily_frequency'], bins=20, alpha=0.7, label='Normal', density=True)\n",
    "axes[1,1].hist(fraud_df[fraud_df['is_fraud']==1]['daily_frequency'], bins=10, alpha=0.7, label='Fraud', density=True)\n",
    "axes[1,1].set_xlabel('Daily Transaction Frequency')\n",
    "axes[1,1].set_ylabel('Density')\n",
    "axes[1,1].set_title('Transaction Frequency Distribution')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"🔍 Notice the different patterns:\")\n",
    "print(\"• Fraud transactions often have extreme amounts (very high or very low)\")\n",
    "print(\"• Fraud occurs more often at night\")\n",
    "print(\"• Fraud transactions are often foreign\")\n",
    "print(\"• Fraud accounts often have high transaction frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train fraud detection model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare features (exclude the target variable)\n",
    "feature_columns = ['amount_log', 'hour_of_day', 'is_foreign', 'daily_frequency', 'is_night', 'high_frequency']\n",
    "X_fraud = fraud_df[feature_columns].values\n",
    "y_fraud = fraud_df['is_fraud'].values\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_fraud, y_fraud, test_size=0.3, random_state=42, stratify=y_fraud\n",
    ")\n",
    "\n",
    "# Scale features (important for some algorithms)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Isolation Forest for fraud detection\n",
    "fraud_detector = IsolationForest(\n",
    "    contamination=0.01,  # Expect 1% fraud\n",
    "    random_state=42,\n",
    "    n_estimators=200\n",
    ")\n",
    "\n",
    "# Fit on training data (only normal transactions for unsupervised learning)\n",
    "normal_transactions = X_train_scaled[y_train == 0]\n",
    "fraud_detector.fit(normal_transactions)\n",
    "\n",
    "# Predict on test set\n",
    "test_predictions = fraud_detector.predict(X_test_scaled)\n",
    "test_scores = fraud_detector.decision_function(X_test_scaled)\n",
    "\n",
    "# Convert predictions to binary\n",
    "test_predictions_binary = (test_predictions == -1).astype(int)\n",
    "\n",
    "print(\"🚀 Fraud Detection Model Trained!\")\n",
    "print(f\"Training set size: {len(X_train):,} transactions\")\n",
    "print(f\"Test set size: {len(X_test):,} transactions\")\n",
    "print(f\"Normal transactions in training: {sum(y_train == 0):,}\")\n",
    "print(f\"Fraud transactions in test: {sum(y_test == 1):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate fraud detection performance\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_test, test_predictions_binary)\n",
    "recall = recall_score(y_test, test_predictions_binary)\n",
    "f1 = f1_score(y_test, test_predictions_binary)\n",
    "auc = roc_auc_score(y_test, -test_scores)\n",
    "\n",
    "print(\"🎯 Fraud Detection Performance:\")\n",
    "print(f\"Precision: {precision:.3f} ({precision:.1%})\")\n",
    "print(f\"Recall:    {recall:.3f} ({recall:.1%})\")\n",
    "print(f\"F1-Score:  {f1:.3f}\")\n",
    "print(f\"AUC-ROC:   {auc:.3f}\")\n",
    "\n",
    "# Business interpretation\n",
    "tp = sum((y_test == 1) & (test_predictions_binary == 1))\n",
    "fp = sum((y_test == 0) & (test_predictions_binary == 1))\n",
    "fn = sum((y_test == 1) & (test_predictions_binary == 0))\n",
    "\n",
    "print(f\"\\n💼 Business Impact:\")\n",
    "print(f\"• Detected {tp} out of {sum(y_test)} fraud cases ({tp/sum(y_test):.1%})\")\n",
    "print(f\"• {fp} false alarms out of {sum(test_predictions_binary)} flagged transactions\")\n",
    "print(f\"• Missed {fn} fraud cases\")\n",
    "\n",
    "# Estimate monetary impact (example)\n",
    "avg_fraud_amount = fraud_df[fraud_df['is_fraud']==1]['amount'].mean()\n",
    "fraud_prevented = tp * avg_fraud_amount\n",
    "fraud_missed = fn * avg_fraud_amount\n",
    "review_cost = fp * 50  # Assume $50 cost per manual review\n",
    "\n",
    "print(f\"\\n💰 Estimated Impact:\")\n",
    "print(f\"• Fraud prevented: ${fraud_prevented:,.0f}\")\n",
    "print(f\"• Fraud missed: ${fraud_missed:,.0f}\")\n",
    "print(f\"• Review costs: ${review_cost:,.0f}\")\n",
    "print(f\"• Net benefit: ${fraud_prevented - fraud_missed - review_cost:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud detection results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, -test_scores)\n",
    "axes[0,0].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {auc:.3f})')\n",
    "axes[0,0].plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "axes[0,0].set_xlabel('False Positive Rate')\n",
    "axes[0,0].set_ylabel('True Positive Rate')\n",
    "axes[0,0].set_title('ROC Curve')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, -test_scores)\n",
    "axes[0,1].plot(recall_curve, precision_curve, linewidth=2, label=f'PR Curve')\n",
    "axes[0,1].axhline(y=sum(y_test)/len(y_test), color='k', linestyle='--', label='Random Classifier')\n",
    "axes[0,1].set_xlabel('Recall')\n",
    "axes[0,1].set_ylabel('Precision')\n",
    "axes[0,1].set_title('Precision-Recall Curve')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Score distribution\n",
    "normal_scores = test_scores[y_test == 0]\n",
    "fraud_scores = test_scores[y_test == 1]\n",
    "axes[1,0].hist(normal_scores, bins=50, alpha=0.7, label='Normal', density=True)\n",
    "axes[1,0].hist(fraud_scores, bins=20, alpha=0.7, label='Fraud', density=True)\n",
    "axes[1,0].set_xlabel('Anomaly Score')\n",
    "axes[1,0].set_ylabel('Density')\n",
    "axes[1,0].set_title('Score Distribution')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].axvline(x=0, color='red', linestyle='--', label='Decision Threshold')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, test_predictions_binary)\n",
    "im = axes[1,1].imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "axes[1,1].set_title('Confusion Matrix')\n",
    "tick_marks = np.arange(2)\n",
    "axes[1,1].set_xticks(tick_marks)\n",
    "axes[1,1].set_yticks(tick_marks)\n",
    "axes[1,1].set_xticklabels(['Normal', 'Fraud'])\n",
    "axes[1,1].set_yticklabels(['Normal', 'Fraud'])\n",
    "axes[1,1].set_ylabel('True Label')\n",
    "axes[1,1].set_xlabel('Predicted Label')\n",
    "\n",
    "# Add text annotations to confusion matrix\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[1,1].text(j, i, f'{cm[i, j]}', \n",
    "                      ha=\"center\", va=\"center\", fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 Chart Explanations:\")\n",
    "print(\"• ROC Curve: Higher curve = better performance\")\n",
    "print(\"• PR Curve: Higher curve = better performance\")\n",
    "print(\"• Score Distribution: Good separation between normal and fraud scores\")\n",
    "print(\"• Confusion Matrix: Diagonal elements should be high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Takeaways and Next Steps\n",
    "\n",
    "Congratulations! You've learned the fundamentals of anomaly detection. Here's what we covered:\n",
    "\n",
    "### 🎓 What You Learned:\n",
    "\n",
    "1. **Anomaly Types**: Point, contextual, and collective anomalies\n",
    "2. **Algorithms**: Statistical methods, Isolation Forest, LOF, and more\n",
    "3. **Evaluation**: Precision, recall, F1-score, and AUC-ROC\n",
    "4. **Real Application**: Credit card fraud detection\n",
    "5. **Business Impact**: Converting technical metrics to business value\n",
    "\n",
    "### 🚀 Next Steps:\n",
    "\n",
    "1. **Practice** with your own datasets\n",
    "2. **Explore** advanced algorithms (deep learning, ensemble methods)\n",
    "3. **Learn** about time series anomaly detection\n",
    "4. **Study** real-time detection systems\n",
    "5. **Understand** domain-specific applications\n",
    "\n",
    "### 🔧 Practical Tips:\n",
    "\n",
    "- **Start simple** with statistical methods, then move to complex algorithms\n",
    "- **Understand your data** before choosing an algorithm\n",
    "- **Consider the business context** when setting thresholds\n",
    "- **Always validate** on held-out test data\n",
    "- **Monitor performance** in production\n",
    "\n",
    "### 📚 Further Learning Resources:\n",
    "\n",
    "- [Intermediate Tutorial: Time Series Anomaly Detection](./intermediate-time-series.ipynb)\n",
    "- [Advanced Tutorial: Deep Learning for Anomalies](./advanced-deep-learning.ipynb)\n",
    "- [Industry Examples](../practical-examples/)\n",
    "- [API Documentation](../../api/README.md)\n",
    "\n",
    "Happy detecting! 🕵️‍♂️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final exercise: Try it yourself!\n",
    "print(\"🎉 Congratulations on completing the tutorial!\")\n",
    "print(\"\\n🏆 Your Turn:\")\n",
    "print(\"1. Try modifying the contamination parameter in the fraud detection example\")\n",
    "print(\"2. Add new features to improve detection performance\")\n",
    "print(\"3. Test different algorithms and compare their results\")\n",
    "print(\"4. Create visualizations for your own dataset\")\n",
    "print(\"\\n💡 Remember: The best anomaly detector is the one that works for YOUR specific problem!\")\n",
    "\n",
    "# Show final summary\n",
    "print(\"\\n📊 Summary of Key Algorithms:\")\n",
    "algorithms_summary = pd.DataFrame({\n",
    "    'Algorithm': ['Z-Score', 'Isolation Forest', 'Local Outlier Factor', 'One-Class SVM'],\n",
    "    'Best For': [\n",
    "        'Simple, univariate data',\n",
    "        'High-dimensional, mixed data types',\n",
    "        'Local density-based anomalies',\n",
    "        'Complex decision boundaries'\n",
    "    ],\n",
    "    'Speed': ['Fast', 'Fast', 'Medium', 'Slow'],\n",
    "    'Interpretability': ['High', 'Medium', 'Medium', 'Low']\n",
    "})\n",
    "print(algorithms_summary.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}