---
# Complete Kubernetes Production Deployment for Pynomaly
# Includes all services: app, monitoring, tracing, logging, databases

apiVersion: v1
kind: Namespace
metadata:
  name: pynomaly-production
  labels:
    name: pynomaly-production
    environment: production
    app.kubernetes.io/name: pynomaly
    app.kubernetes.io/instance: production
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/component: namespace
    app.kubernetes.io/managed-by: kubectl

---
# ConfigMap for Application Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: pynomaly-config
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: pynomaly
    app.kubernetes.io/component: config
data:
  ENVIRONMENT: "production"
  LOG_LEVEL: "INFO"
  PROMETHEUS_METRICS_PORT: "9090"
  OTEL_EXPORTER_OTLP_ENDPOINT: "http://otel-collector:4317"
  OTEL_SERVICE_NAME: "pynomaly"
  OTEL_SERVICE_VERSION: "1.0.0"
  JAEGER_AGENT_HOST: "jaeger-agent"
  JAEGER_AGENT_PORT: "6831"
  API_HOST: "0.0.0.0"
  API_PORT: "8000"
  WORKER_CONCURRENCY: "4"
  DRIFT_CHECK_INTERVAL: "3600"

---
# Secret for sensitive configuration
apiVersion: v1
kind: Secret
metadata:
  name: pynomaly-secrets
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: pynomaly
    app.kubernetes.io/component: secrets
type: Opaque
stringData:
  POSTGRES_PASSWORD: "pynomaly_prod_secret_2024"
  POSTGRES_USER: "pynomaly"
  POSTGRES_DB: "pynomaly"
  REDIS_PASSWORD: "redis_prod_secret_2024"
  JWT_SECRET_KEY: "jwt_super_secret_key_for_production_2024"
  SECRET_KEY: "app_super_secret_key_for_production_2024"
  GRAFANA_ADMIN_PASSWORD: "grafana_admin_secret_2024"
  FLOWER_PASSWORD: "flower_monitor_secret_2024"
  ENCRYPTION_KEY: "fernet_encryption_key_for_production_2024"

---
# Persistent Volume Claims
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: postgres
    app.kubernetes.io/component: database
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
  storageClassName: fast-ssd

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: redis-pvc
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: redis
    app.kubernetes.io/component: cache
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: fast-ssd

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-pvc
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: monitoring
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: fast-ssd

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: grafana-pvc
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: grafana
    app.kubernetes.io/component: visualization
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: fast-ssd

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: elasticsearch-pvc
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/component: logging
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: fast-ssd

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: jaeger-pvc
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/component: tracing
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 30Gi
  storageClassName: fast-ssd

---
# PostgreSQL Database
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: postgres
    app.kubernetes.io/component: database
    app.kubernetes.io/part-of: pynomaly
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: postgres
  template:
    metadata:
      labels:
        app.kubernetes.io/name: postgres
        app.kubernetes.io/component: database
    spec:
      containers:
      - name: postgres
        image: postgres:16-alpine
        ports:
        - containerPort: 5432
          name: postgres
        env:
        - name: POSTGRES_DB
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_DB
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_USER
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_PASSWORD
        - name: POSTGRES_INITDB_ARGS
          value: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - pynomaly
            - -d
            - pynomaly
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - pynomaly
            - -d
            - pynomaly
          initialDelaySeconds: 10
          periodSeconds: 10
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 20Gi

---
apiVersion: v1
kind: Service
metadata:
  name: postgres
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: postgres
    app.kubernetes.io/component: database
spec:
  selector:
    app.kubernetes.io/name: postgres
  ports:
  - port: 5432
    targetPort: 5432
    name: postgres
  type: ClusterIP

---
# Redis Cache
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: redis
    app.kubernetes.io/component: cache
    app.kubernetes.io/part-of: pynomaly
spec:
  serviceName: redis
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: redis
  template:
    metadata:
      labels:
        app.kubernetes.io/name: redis
        app.kubernetes.io/component: cache
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
          name: redis
        command:
        - redis-server
        - --appendonly
        - "yes"
        - --requirepass
        - $(REDIS_PASSWORD)
        env:
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: REDIS_PASSWORD
        volumeMounts:
        - name: redis-storage
          mountPath: /data
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 10
          periodSeconds: 10
  volumeClaimTemplates:
  - metadata:
      name: redis-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 5Gi

---
apiVersion: v1
kind: Service
metadata:
  name: redis
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: redis
    app.kubernetes.io/component: cache
spec:
  selector:
    app.kubernetes.io/name: redis
  ports:
  - port: 6379
    targetPort: 6379
    name: redis
  type: ClusterIP

---
# Pynomaly API Application
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pynomaly-api
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: pynomaly-api
    app.kubernetes.io/component: api
    app.kubernetes.io/part-of: pynomaly
    app.kubernetes.io/version: "1.0.0"
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app.kubernetes.io/name: pynomaly-api
  template:
    metadata:
      labels:
        app.kubernetes.io/name: pynomaly-api
        app.kubernetes.io/component: api
        app.kubernetes.io/version: "1.0.0"
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
    spec:
      containers:
      - name: pynomaly-api
        image: pynomaly/api:1.0.0
        ports:
        - containerPort: 8000
          name: http
        - containerPort: 9090
          name: metrics
        env:
        - name: DATABASE_URL
          value: "postgresql://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@postgres:5432/$(POSTGRES_DB)"
        - name: REDIS_URL
          value: "redis://:$(REDIS_PASSWORD)@redis:6379/0"
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_USER
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_PASSWORD
        - name: POSTGRES_DB
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_DB
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: REDIS_PASSWORD
        - name: JWT_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: JWT_SECRET_KEY
        - name: SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: SECRET_KEY
        envFrom:
        - configMapRef:
            name: pynomaly-config
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        volumeMounts:
        - name: app-storage
          mountPath: /app/storage
        - name: app-logs
          mountPath: /app/logs
      volumes:
      - name: app-storage
        emptyDir: {}
      - name: app-logs
        emptyDir: {}

---
apiVersion: v1
kind: Service
metadata:
  name: pynomaly-api
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: pynomaly-api
    app.kubernetes.io/component: api
spec:
  selector:
    app.kubernetes.io/name: pynomaly-api
  ports:
  - port: 8000
    targetPort: 8000
    name: http
  - port: 9090
    targetPort: 9090
    name: metrics
  type: ClusterIP

---
# Pynomaly Worker - Training
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pynomaly-worker-training
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: pynomaly-worker-training
    app.kubernetes.io/component: worker
    app.kubernetes.io/part-of: pynomaly
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: pynomaly-worker-training
  template:
    metadata:
      labels:
        app.kubernetes.io/name: pynomaly-worker-training
        app.kubernetes.io/component: worker
    spec:
      containers:
      - name: training-worker
        image: pynomaly/worker:1.0.0
        command: ["celery", "worker", "-A", "pynomaly.workers", "-Q", "model_training,anomaly_detection", "--concurrency=4"]
        env:
        - name: CELERY_BROKER_URL
          value: "redis://:$(REDIS_PASSWORD)@redis:6379/0"
        - name: CELERY_RESULT_BACKEND
          value: "redis://:$(REDIS_PASSWORD)@redis:6379/0"
        - name: DATABASE_URL
          value: "postgresql://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@postgres:5432/$(POSTGRES_DB)"
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_USER
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_PASSWORD
        - name: POSTGRES_DB
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_DB
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: REDIS_PASSWORD
        envFrom:
        - configMapRef:
            name: pynomaly-config
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "8Gi"
            cpu: "4000m"
        volumeMounts:
        - name: worker-storage
          mountPath: /app/storage
        - name: worker-logs
          mountPath: /app/logs
      volumes:
      - name: worker-storage
        emptyDir: {}
      - name: worker-logs
        emptyDir: {}

---
# Pynomaly Worker - Drift Monitoring
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pynomaly-worker-drift
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: pynomaly-worker-drift
    app.kubernetes.io/component: worker
    app.kubernetes.io/part-of: pynomaly
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: pynomaly-worker-drift
  template:
    metadata:
      labels:
        app.kubernetes.io/name: pynomaly-worker-drift
        app.kubernetes.io/component: worker
    spec:
      containers:
      - name: drift-worker
        image: pynomaly/worker:1.0.0
        command: ["celery", "worker", "-A", "pynomaly.workers", "-Q", "drift_monitoring,alert_processing", "--concurrency=2"]
        env:
        - name: CELERY_BROKER_URL
          value: "redis://:$(REDIS_PASSWORD)@redis:6379/0"
        - name: CELERY_RESULT_BACKEND
          value: "redis://:$(REDIS_PASSWORD)@redis:6379/0"
        - name: DATABASE_URL
          value: "postgresql://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@postgres:5432/$(POSTGRES_DB)"
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_USER
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_PASSWORD
        - name: POSTGRES_DB
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_DB
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: REDIS_PASSWORD
        envFrom:
        - configMapRef:
            name: pynomaly-config
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        volumeMounts:
        - name: worker-storage
          mountPath: /app/storage
        - name: worker-logs
          mountPath: /app/logs
      volumes:
      - name: worker-storage
        emptyDir: {}
      - name: worker-logs
        emptyDir: {}

---
# Celery Scheduler
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pynomaly-scheduler
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: pynomaly-scheduler
    app.kubernetes.io/component: scheduler
    app.kubernetes.io/part-of: pynomaly
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: pynomaly-scheduler
  template:
    metadata:
      labels:
        app.kubernetes.io/name: pynomaly-scheduler
        app.kubernetes.io/component: scheduler
    spec:
      containers:
      - name: celery-beat
        image: pynomaly/scheduler:1.0.0
        command: ["celery", "beat", "-A", "pynomaly.workers", "--loglevel=info"]
        env:
        - name: CELERY_BROKER_URL
          value: "redis://:$(REDIS_PASSWORD)@redis:6379/0"
        - name: CELERY_RESULT_BACKEND
          value: "redis://:$(REDIS_PASSWORD)@redis:6379/0"
        - name: DATABASE_URL
          value: "postgresql://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@postgres:5432/$(POSTGRES_DB)"
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_USER
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_PASSWORD
        - name: POSTGRES_DB
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: POSTGRES_DB
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: REDIS_PASSWORD
        envFrom:
        - configMapRef:
            name: pynomaly-config
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        volumeMounts:
        - name: scheduler-storage
          mountPath: /app/storage
        - name: scheduler-logs
          mountPath: /app/logs
      volumes:
      - name: scheduler-storage
        emptyDir: {}
      - name: scheduler-logs
        emptyDir: {}

---
# Prometheus Monitoring
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: monitoring
    app.kubernetes.io/part-of: pynomaly
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: prometheus
  template:
    metadata:
      labels:
        app.kubernetes.io/name: prometheus
        app.kubernetes.io/component: monitoring
    spec:
      containers:
      - name: prometheus
        image: prom/prometheus:latest
        ports:
        - containerPort: 9090
          name: web
        args:
        - '--config.file=/etc/prometheus/prometheus.yml'
        - '--storage.tsdb.path=/prometheus'
        - '--web.console.libraries=/etc/prometheus/console_libraries'
        - '--web.console.templates=/etc/prometheus/consoles'
        - '--storage.tsdb.retention.time=30d'
        - '--storage.tsdb.retention.size=10GB'
        - '--web.enable-lifecycle'
        - '--web.enable-admin-api'
        volumeMounts:
        - name: prometheus-config
          mountPath: /etc/prometheus
        - name: prometheus-storage
          mountPath: /prometheus
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "8Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9090
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9090
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: prometheus-config
        configMap:
          name: prometheus-config
      - name: prometheus-storage
        persistentVolumeClaim:
          claimName: prometheus-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: monitoring
spec:
  selector:
    app.kubernetes.io/name: prometheus
  ports:
  - port: 9090
    targetPort: 9090
    name: web
  type: ClusterIP

---
# Grafana Visualization
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: grafana
    app.kubernetes.io/component: visualization
    app.kubernetes.io/part-of: pynomaly
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: grafana
  template:
    metadata:
      labels:
        app.kubernetes.io/name: grafana
        app.kubernetes.io/component: visualization
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:latest
        ports:
        - containerPort: 3000
          name: web
        env:
        - name: GF_SECURITY_ADMIN_USER
          value: "admin"
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pynomaly-secrets
              key: GRAFANA_ADMIN_PASSWORD
        - name: GF_USERS_ALLOW_SIGN_UP
          value: "false"
        - name: GF_SERVER_DOMAIN
          value: "grafana.pynomaly.local"
        - name: GF_INSTALL_PLUGINS
          value: "grafana-clock-panel,grafana-simple-json-datasource"
        volumeMounts:
        - name: grafana-storage
          mountPath: /var/lib/grafana
        - name: grafana-config
          mountPath: /etc/grafana/provisioning
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: grafana-storage
        persistentVolumeClaim:
          claimName: grafana-pvc
      - name: grafana-config
        configMap:
          name: grafana-config

---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: grafana
    app.kubernetes.io/component: visualization
spec:
  selector:
    app.kubernetes.io/name: grafana
  ports:
  - port: 3000
    targetPort: 3000
    name: web
  type: ClusterIP

---
# Jaeger All-in-One for Distributed Tracing
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jaeger
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/component: tracing
    app.kubernetes.io/part-of: pynomaly
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: jaeger
  template:
    metadata:
      labels:
        app.kubernetes.io/name: jaeger
        app.kubernetes.io/component: tracing
    spec:
      containers:
      - name: jaeger
        image: jaegertracing/all-in-one:latest
        ports:
        - containerPort: 16686
          name: web
        - containerPort: 14268
          name: collector
        - containerPort: 14250
          name: grpc
        - containerPort: 6831
          name: agent-udp
          protocol: UDP
        - containerPort: 6832
          name: agent-udp2
          protocol: UDP
        - containerPort: 5778
          name: agent-http
        env:
        - name: COLLECTOR_ZIPKIN_HOST_PORT
          value: ":9411"
        - name: COLLECTOR_OTLP_ENABLED
          value: "true"
        - name: SPAN_STORAGE_TYPE
          value: "badger"
        - name: BADGER_EPHEMERAL
          value: "false"
        - name: BADGER_DIRECTORY_VALUE
          value: "/badger/data"
        - name: BADGER_DIRECTORY_KEY
          value: "/badger/key"
        volumeMounts:
        - name: jaeger-storage
          mountPath: /badger
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /
            port: 16686
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /
            port: 16686
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: jaeger-storage
        persistentVolumeClaim:
          claimName: jaeger-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: jaeger
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/component: tracing
spec:
  selector:
    app.kubernetes.io/name: jaeger
  ports:
  - port: 16686
    targetPort: 16686
    name: web
  - port: 14268
    targetPort: 14268
    name: collector
  - port: 14250
    targetPort: 14250
    name: grpc
  - port: 6831
    targetPort: 6831
    name: agent-udp
    protocol: UDP
  - port: 6832
    targetPort: 6832
    name: agent-udp2
    protocol: UDP
  - port: 5778
    targetPort: 5778
    name: agent-http
  type: ClusterIP

---
# Service alias for jaeger-agent
apiVersion: v1
kind: Service
metadata:
  name: jaeger-agent
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: jaeger-agent
    app.kubernetes.io/component: tracing
spec:
  selector:
    app.kubernetes.io/name: jaeger
  ports:
  - port: 6831
    targetPort: 6831
    name: agent-udp
    protocol: UDP
  - port: 6832
    targetPort: 6832
    name: agent-udp2
    protocol: UDP
  - port: 5778
    targetPort: 5778
    name: agent-http
  type: ClusterIP

---
# OpenTelemetry Collector
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: otel-collector
    app.kubernetes.io/component: tracing
    app.kubernetes.io/part-of: pynomaly
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: otel-collector
  template:
    metadata:
      labels:
        app.kubernetes.io/name: otel-collector
        app.kubernetes.io/component: tracing
    spec:
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:latest
        ports:
        - containerPort: 4317
          name: otlp-grpc
        - containerPort: 4318
          name: otlp-http
        - containerPort: 8889
          name: prometheus
        command:
        - /otelcol-contrib
        - --config=/etc/otel-collector-config.yaml
        volumeMounts:
        - name: otel-config
          mountPath: /etc/otel-collector-config.yaml
          subPath: otel-collector-config.yaml
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: otel-config
        configMap:
          name: otel-collector-config

---
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: otel-collector
    app.kubernetes.io/component: tracing
spec:
  selector:
    app.kubernetes.io/name: otel-collector
  ports:
  - port: 4317
    targetPort: 4317
    name: otlp-grpc
  - port: 4318
    targetPort: 4318
    name: otlp-http
  - port: 8889
    targetPort: 8889
    name: prometheus
  type: ClusterIP

---
# Elasticsearch for Logging
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/component: logging
    app.kubernetes.io/part-of: pynomaly
spec:
  serviceName: elasticsearch
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: elasticsearch
  template:
    metadata:
      labels:
        app.kubernetes.io/name: elasticsearch
        app.kubernetes.io/component: logging
    spec:
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
        ports:
        - containerPort: 9200
          name: rest
        - containerPort: 9300
          name: inter-node
        env:
        - name: node.name
          value: "pynomaly-es-node"
        - name: cluster.name
          value: "pynomaly-cluster"
        - name: discovery.type
          value: "single-node"
        - name: bootstrap.memory_lock
          value: "true"
        - name: xpack.security.enabled
          value: "false"
        - name: xpack.security.enrollment.enabled
          value: "false"
        - name: ES_JAVA_OPTS
          value: "-Xms1g -Xmx1g"
        volumeMounts:
        - name: elasticsearch-storage
          mountPath: /usr/share/elasticsearch/data
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /_cluster/health
            port: 9200
          initialDelaySeconds: 90
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /_cluster/health
            port: 9200
          initialDelaySeconds: 60
          periodSeconds: 10
      volumes:
      - name: elasticsearch-storage
        persistentVolumeClaim:
          claimName: elasticsearch-pvc
      initContainers:
      - name: increase-vm-max-map
        image: busybox
        command: ["sysctl", "-w", "vm.max_map_count=262144"]
        securityContext:
          privileged: true

---
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/component: logging
spec:
  selector:
    app.kubernetes.io/name: elasticsearch
  ports:
  - port: 9200
    targetPort: 9200
    name: rest
  - port: 9300
    targetPort: 9300
    name: inter-node
  type: ClusterIP

---
# Ingress Controller for External Access
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: pynomaly-ingress
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: pynomaly-ingress
    app.kubernetes.io/component: ingress
    app.kubernetes.io/part-of: pynomaly
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - api.pynomaly.local
    - grafana.pynomaly.local
    - jaeger.pynomaly.local
    secretName: pynomaly-tls-secret
  rules:
  - host: api.pynomaly.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: pynomaly-api
            port:
              number: 8000
  - host: grafana.pynomaly.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: grafana
            port:
              number: 3000
  - host: jaeger.pynomaly.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: jaeger
            port:
              number: 16686

---
# Horizontal Pod Autoscaler for API
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: pynomaly-api-hpa
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: pynomaly-api-hpa
    app.kubernetes.io/component: autoscaling
    app.kubernetes.io/part-of: pynomaly
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: pynomaly-api
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 25
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30

---
# Network Policies for Security
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: pynomaly-network-policy
  namespace: pynomaly-production
  labels:
    app.kubernetes.io/name: pynomaly-network-policy
    app.kubernetes.io/component: security
    app.kubernetes.io/part-of: pynomaly
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    - namespaceSelector:
        matchLabels:
          name: pynomaly-production
    ports:
    - protocol: TCP
      port: 8000
    - protocol: TCP
      port: 3000
    - protocol: TCP
      port: 16686
    - protocol: TCP
      port: 9090
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: pynomaly-production
  - to: []
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 443
    - protocol: TCP
      port: 80
