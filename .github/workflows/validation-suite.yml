name: Nightly Full Test Suite Validation

on:
  schedule:
    - cron: '0 3 * * *' # Every day at 3 AM UTC
  workflow_dispatch: # Allow manual runs
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

permissions:
  contents: read
  pull-requests: write
  checks: write
  actions: read

env:
  PYTHON_VERSION: "3.11"
  HATCH_VERBOSE: 1
  COVERAGE_THRESHOLD: 95
  COVERAGE_THRESHOLD_DOMAIN: 98
  COVERAGE_THRESHOLD_APPLICATION: 95
  COVERAGE_THRESHOLD_INFRASTRUCTURE: 90
  COVERAGE_THRESHOLD_PRESENTATION: 85

jobs:
  # Job 1: Fast Quality Checks
  quality-checks:
    name: Quality Checks
    runs-on: ubuntu-latest
    outputs:
      quality-status: ${{ steps.quality-summary.outputs.status }}
      quality-report: ${{ steps.quality-summary.outputs.report }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Hatch
      run: |
        python -m pip install --upgrade pip
        pip install hatch

    - name: Cache Hatch environments
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/hatch
          ~/.local/share/hatch
        key: ${{ runner.os }}-hatch-${{ hashFiles('pyproject.toml') }}

    - name: Run code style checks
      id: style-check
      run: |
        echo "::group::Code Style Check"
        hatch env run lint:style
        echo "::endgroup::"
      continue-on-error: true

    - name: Run type checking
      id: type-check
      run: |
        echo "::group::Type Checking"
        hatch env run lint:typing
        echo "::endgroup::"
      continue-on-error: true

    - name: Run formatting check
      id: format-check
      run: |
        echo "::group::Format Check"
        hatch env run lint:fmt
        echo "::endgroup::"
      continue-on-error: true

    - name: Quality summary
      id: quality-summary
      run: |
        STYLE_STATUS="${{ steps.style-check.outcome }}"
        TYPE_STATUS="${{ steps.type-check.outcome }}"
        FORMAT_STATUS="${{ steps.format-check.outcome }}"

        if [[ "$STYLE_STATUS" == "success" && "$TYPE_STATUS" == "success" && "$FORMAT_STATUS" == "success" ]]; then
          echo "status=success" >> $GITHUB_OUTPUT
          echo "report=✅ All quality checks passed" >> $GITHUB_OUTPUT
        else
          echo "status=failure" >> $GITHUB_OUTPUT
          echo "report=❌ Quality checks failed: Style($STYLE_STATUS), Type($TYPE_STATUS), Format($FORMAT_STATUS)" >> $GITHUB_OUTPUT
        fi

  # Job 2: Build and Package
  build-validation:
    name: Build Validation
    runs-on: ubuntu-latest
    outputs:
      build-status: ${{ steps.build-summary.outputs.status }}
      build-report: ${{ steps.build-summary.outputs.report }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Hatch
      run: |
        python -m pip install --upgrade pip
        pip install hatch

    - name: Build package
      id: build-package
      run: |
        echo "::group::Building Package"
        hatch build --clean
        echo "::endgroup::"
      continue-on-error: true

    - name: Test package installation
      id: test-install
      run: |
        echo "::group::Testing Installation"
        pip install dist/*.whl
        python -c "import pynomaly; print('✅ Package installation successful')"
        echo "::endgroup::"
      continue-on-error: true

    - name: Build summary
      id: build-summary
      run: |
        BUILD_STATUS="${{ steps.build-package.outcome }}"
        INSTALL_STATUS="${{ steps.test-install.outcome }}"

        if [[ "$BUILD_STATUS" == "success" && "$INSTALL_STATUS" == "success" ]]; then
          echo "status=success" >> $GITHUB_OUTPUT
          echo "report=✅ Build and installation successful" >> $GITHUB_OUTPUT
        else
          echo "status=failure" >> $GITHUB_OUTPUT
          echo "report=❌ Build failed: Build($BUILD_STATUS), Install($INSTALL_STATUS)" >> $GITHUB_OUTPUT
        fi

    - name: Upload build artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: build-artifacts
        path: dist/
        retention-days: 7

  # Job 3: Test Suite with Coverage
  test-validation:
    name: Test Validation
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test-type: [unit, integration]
      fail-fast: false
    outputs:
      test-status: ${{ steps.test-summary.outputs.status }}
      coverage-status: ${{ steps.coverage-check.outputs.status }}
      test-report: ${{ steps.test-summary.outputs.report }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Hatch
      run: |
        python -m pip install --upgrade pip
        pip install hatch

    - name: Cache Hatch environments
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/hatch
          ~/.local/share/hatch
        key: ${{ runner.os }}-hatch-test-${{ hashFiles('pyproject.toml') }}

    - name: Run unit tests
      if: matrix.test-type == 'unit'
      id: unit-tests
      run: |
        echo "::group::Unit Tests"
        hatch run test:run tests/domain/ tests/application/ -v --tb=short \
          --cov=src/pynomaly --cov-report=xml --cov-report=term \
          --cov-report=html --cov-fail-under=${{ env.COVERAGE_THRESHOLD }}
        echo "::endgroup::"
      continue-on-error: true

    - name: Run integration tests
      if: matrix.test-type == 'integration'
      id: integration-tests
      run: |
        echo "::group::Integration Tests"
        hatch run test:run tests/infrastructure/ tests/presentation/ -v --tb=short \
          --cov=src/pynomaly --cov-report=xml --cov-report=term \
          --cov-append
        echo "::endgroup::"
      continue-on-error: true

    - name: Check coverage thresholds
      id: coverage-check
      run: |
        echo "::group::Coverage Analysis"

        # Extract coverage information
        if [ -f coverage.xml ]; then
          # Parse overall coverage
          OVERALL_COVERAGE=$(python -c "
          import xml.etree.ElementTree as ET
          tree = ET.parse('coverage.xml')
          root = tree.getroot()
          line_rate = float(root.get('line-rate', 0))
          print(f'{line_rate * 100:.1f}')
          ")

          echo "Overall coverage: ${OVERALL_COVERAGE}%"

          # Check if meets threshold
          if (( $(echo "$OVERALL_COVERAGE >= ${{ env.COVERAGE_THRESHOLD }}" | bc -l) )); then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "✅ Coverage threshold met: ${OVERALL_COVERAGE}% >= ${{ env.COVERAGE_THRESHOLD }}%"
          else
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "❌ Coverage threshold not met: ${OVERALL_COVERAGE}% < ${{ env.COVERAGE_THRESHOLD }}%"
          fi
        else
          echo "status=failure" >> $GITHUB_OUTPUT
          echo "❌ No coverage report found"
        fi
        echo "::endgroup::"
      continue-on-error: true

    - name: Test summary
      id: test-summary
      run: |
        TEST_STATUS="${{ matrix.test-type == 'unit' && steps.unit-tests.outcome || steps.integration-tests.outcome }}"
        COVERAGE_STATUS="${{ steps.coverage-check.outcome }}"

        if [[ "$TEST_STATUS" == "success" && "$COVERAGE_STATUS" == "success" ]]; then
          echo "status=success" >> $GITHUB_OUTPUT
          echo "report=✅ ${{ matrix.test-type }} tests passed with adequate coverage" >> $GITHUB_OUTPUT
        else
          echo "status=failure" >> $GITHUB_OUTPUT
          echo "report=❌ ${{ matrix.test-type }} tests failed: Tests($TEST_STATUS), Coverage($COVERAGE_STATUS)" >> $GITHUB_OUTPUT
        fi

    - name: Upload test artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ matrix.test-type }}
        path: |
          htmlcov/
          coverage.xml
          .coverage
        retention-days: 7

  # Job 4: Security Validation
  security-validation:
    name: Security Validation
    runs-on: ubuntu-latest
    outputs:
      security-status: ${{ steps.security-summary.outputs.status }}
      security-report: ${{ steps.security-summary.outputs.report }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety

    - name: Run Bandit security scan
      id: bandit-scan
      run: |
        echo "::group::Bandit Security Scan"
        bandit -r src/ -f json -o bandit-report.json
        bandit -r src/ -f txt
        echo "::endgroup::"
      continue-on-error: true

    - name: Run Safety dependency check
      id: safety-check
      run: |
        echo "::group::Safety Dependency Check"
        safety check --json --output safety-report.json
        safety check
        echo "::endgroup::"
      continue-on-error: true

    - name: Security summary
      id: security-summary
      run: |
        BANDIT_STATUS="${{ steps.bandit-scan.outcome }}"
        SAFETY_STATUS="${{ steps.safety-check.outcome }}"

        if [[ "$BANDIT_STATUS" == "success" && "$SAFETY_STATUS" == "success" ]]; then
          echo "status=success" >> $GITHUB_OUTPUT
          echo "report=✅ Security scans passed" >> $GITHUB_OUTPUT
        else
          echo "status=failure" >> $GITHUB_OUTPUT
          echo "report=❌ Security issues found: Bandit($BANDIT_STATUS), Safety($SAFETY_STATUS)" >> $GITHUB_OUTPUT
        fi

    - name: Upload security reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
        retention-days: 30

  # Job 5: Documentation Validation
  documentation-validation:
    name: Documentation Validation
    runs-on: ubuntu-latest
    outputs:
      docs-status: ${{ steps.docs-summary.outputs.status }}
      docs-report: ${{ steps.docs-summary.outputs.report }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install documentation dependencies
      run: |
        python -m pip install --upgrade pip
        pip install mkdocs mkdocs-material mkdocstrings[python] pymdown-extensions

    - name: Build documentation
      id: build-docs
      run: |
        echo "::group::Building Documentation"
        mkdocs build --config-file=config/docs/mkdocs.yml --strict
        echo "::endgroup::"
      continue-on-error: true

    - name: Check documentation links
      id: link-check
      run: |
        echo "::group::Checking Documentation Links"
        if [ -f scripts/analysis/check_documentation_links.py ]; then
          python scripts/analysis/check_documentation_links.py
        else
          echo "Link checker not found, skipping"
        fi
        echo "::endgroup::"
      continue-on-error: true

    - name: Documentation summary
      id: docs-summary
      run: |
        BUILD_STATUS="${{ steps.build-docs.outcome }}"
        LINK_STATUS="${{ steps.link-check.outcome }}"

        if [[ "$BUILD_STATUS" == "success" ]]; then
          echo "status=success" >> $GITHUB_OUTPUT
          echo "report=✅ Documentation builds successfully" >> $GITHUB_OUTPUT
        else
          echo "status=failure" >> $GITHUB_OUTPUT
          echo "report=❌ Documentation build failed" >> $GITHUB_OUTPUT
        fi

    - name: Upload documentation
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: documentation-build
        path: site/
        retention-days: 7

  # Job 6: Validation Summary and PR Comment
  validation-summary:
    name: Validation Summary
    runs-on: ubuntu-latest
    needs: [quality-checks, build-validation, test-validation, security-validation, documentation-validation]
    if: always()

    steps:
    - name: Generate validation summary
      id: generate-summary
      run: |
        echo "::group::Generating Validation Summary"

        # Collect all job statuses
        QUALITY_STATUS="${{ needs.quality-checks.outputs.quality-status }}"
        BUILD_STATUS="${{ needs.build-validation.outputs.build-status }}"
        SECURITY_STATUS="${{ needs.security-validation.outputs.security-status }}"
        DOCS_STATUS="${{ needs.documentation-validation.outputs.docs-status }}"

        # Check test results (matrix job)
        TEST_RESULTS="${{ needs.test-validation.result }}"

        # Determine overall status
        if [[ "$QUALITY_STATUS" == "success" && "$BUILD_STATUS" == "success" && "$TEST_RESULTS" == "success" && "$SECURITY_STATUS" == "success" && "$DOCS_STATUS" == "success" ]]; then
          OVERALL_STATUS="✅ PASSED"
          MERGE_READY="true"
        else
          OVERALL_STATUS="❌ FAILED"
          MERGE_READY="false"
        fi

        # Create summary report
        cat > validation-summary.md << 'EOF'
        # 🔍 Validation Suite Results

        **Overall Status: $OVERALL_STATUS**

        **Commit:** ${{ github.sha }}
        **Branch:** ${{ github.ref_name }}
        **Run Date:** $(date)

        ## 📊 Detailed Results

        | Component | Status | Details |
        |-----------|--------|---------|
        | Quality Checks | ${{ needs.quality-checks.outputs.quality-status == 'success' && '✅ Passed' || '❌ Failed' }} | ${{ needs.quality-checks.outputs.quality-report }} |
        | Build & Package | ${{ needs.build-validation.outputs.build-status == 'success' && '✅ Passed' || '❌ Failed' }} | ${{ needs.build-validation.outputs.build-report }} |
        | Test Suite | ${{ needs.test-validation.result == 'success' && '✅ Passed' || '❌ Failed' }} | Unit & Integration tests with coverage |
        | Security Scan | ${{ needs.security-validation.outputs.security-status == 'success' && '✅ Passed' || '❌ Failed' }} | ${{ needs.security-validation.outputs.security-report }} |
        | Documentation | ${{ needs.documentation-validation.outputs.docs-status == 'success' && '✅ Passed' || '❌ Failed' }} | ${{ needs.documentation-validation.outputs.docs-report }} |

        ## 🎯 Coverage Requirements

        - **Overall Project**: ≥95% (Required for merge)
        - **Domain Layer**: ≥98%
        - **Application Layer**: ≥95%
        - **Infrastructure Layer**: ≥90%
        - **Presentation Layer**: ≥85%

        ## 🚀 Merge Status

        **Ready for merge:** $MERGE_READY

        EOF

        if [[ "$MERGE_READY" == "true" ]]; then
          cat >> validation-summary.md << 'EOF'
        ✅ **All validation checks passed!** This PR meets all quality gates:
        - 100% test pass rate
        - ≥95% code coverage
        - No security vulnerabilities
        - Clean code quality
        - Documentation builds successfully

        The PR is ready to be merged to the main branch.
        EOF
        else
          cat >> validation-summary.md << 'EOF'
        ❌ **Some validation checks failed.** Please address the issues above before merging.

        **Required for merge:**
        - All tests must pass (100% pass rate)
        - Code coverage must be ≥95%
        - No high-severity security issues
        - Code quality checks must pass
        - Documentation must build successfully
        EOF
        fi

        echo "merge-ready=$MERGE_READY" >> $GITHUB_OUTPUT
        echo "::endgroup::"

    - name: Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');

          // Read the validation summary
          const summary = fs.readFileSync('validation-summary.md', 'utf8');

          // Post the comment
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: summary
          });

    - name: Set final status
      run: |
        if [[ "${{ steps.generate-summary.outputs.merge-ready }}" == "true" ]]; then
          echo "✅ All validation checks passed - PR is ready for merge"
          exit 0
        else
          echo "❌ Some validation checks failed - PR is not ready for merge"
          exit 1
        fi

    - name: Upload validation summary
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: validation-summary
        path: validation-summary.md
        retention-days: 30
