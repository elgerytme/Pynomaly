name: Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHONPATH: ${{ github.workspace }}/src

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.11", "3.12", "3.13"]
        test-type: [unit, integration, performance]
        
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Install system dependencies (Ubuntu)
      if: matrix.os == 'ubuntu-latest'
      run: |
        sudo apt-get update
        sudo apt-get install -y graphviz graphviz-dev
        
    - name: Install system dependencies (macOS)
      if: matrix.os == 'macos-latest'
      run: |
        brew install graphviz
        
    - name: Install Hatch
      run: |
        pip install --upgrade pip
        pip install hatch
        
    - name: Create test environment
      run: |
        hatch env create test
        
    - name: Run unit tests
      if: matrix.test-type == 'unit'
      run: |
        hatch run test:pytest tests/ -v --tb=short \
          --cov=src/pynomaly --cov-report=xml --cov-report=term \
          --cov-fail-under=80 \
          -m "not slow and not integration and not benchmark" \
          --maxfail=10
          
    - name: Run integration tests
      if: matrix.test-type == 'integration'
      run: |
        hatch run test:pytest tests/ -v --tb=short \
          -m "integration" \
          --maxfail=5 \
          --timeout=300
          
    - name: Run performance tests
      if: matrix.test-type == 'performance'
      run: |
        hatch run test:pytest tests/ -v --tb=short \
          -m "benchmark or performance" \
          --benchmark-only \
          --benchmark-json=benchmark.json
          
    - name: Upload coverage to Codecov
      if: matrix.test-type == 'unit' && matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
        
    - name: Upload benchmark results
      if: matrix.test-type == 'performance' && matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: benchmark.json

  test-matrix:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test-suite:
          - name: "Domain Tests"
            path: "tests/domain/"
            markers: "not slow"
          - name: "Application Tests" 
            path: "tests/application/"
            markers: "not slow and not integration"
          - name: "Infrastructure Tests"
            path: "tests/infrastructure/"
            markers: "not slow and not integration"
          - name: "End-to-End Tests"
            path: "tests/e2e/"
            markers: "integration"
          - name: "Contract Tests"
            path: "tests/contract/"
            markers: "contract"
            
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"
        
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install hatch
        hatch env create test
        
    - name: Run ${{ matrix.test-suite.name }}
      run: |
        hatch run test:pytest ${{ matrix.test-suite.path }} \
          -v --tb=short \
          -m "${{ matrix.test-suite.markers }}" \
          --maxfail=10 \
          --cov=src/pynomaly \
          --cov-report=xml \
          --cov-report=term
          
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: ${{ matrix.test-suite.name }}
        name: ${{ matrix.test-suite.name }}
        fail_ci_if_error: false

  test-dependencies:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        dependency-level: [minimal, standard, full]
        
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"
        
    - name: Install minimal dependencies
      if: matrix.dependency-level == 'minimal'
      run: |
        pip install --upgrade pip
        pip install hatch
        hatch env create test.py3.11
        hatch run test:pip install -e ".[minimal,test]"
        
    - name: Install standard dependencies
      if: matrix.dependency-level == 'standard'
      run: |
        pip install --upgrade pip
        pip install hatch
        hatch env create test.py3.11
        hatch run test:pip install -e ".[standard,test]"
        
    - name: Install full dependencies
      if: matrix.dependency-level == 'full'
      run: |
        pip install --upgrade pip
        pip install hatch
        hatch env create test.py3.11
        hatch run test:pip install -e ".[ml-all,production,test]"
        
    - name: Run dependency-specific tests
      run: |
        hatch run test:pytest tests/dependency_tests/ \
          -v --tb=short \
          -k "${{ matrix.dependency-level }}" \
          --maxfail=5

  security-tests:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"
        
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install hatch
        hatch env create lint
        
    - name: Run security scan with bandit
      run: |
        hatch run lint:bandit -r src/ -f json -o bandit-report.json
        
    - name: Run safety check
      run: |
        hatch run lint:safety check --json --output safety-report.json
        
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  test-reports:
    runs-on: ubuntu-latest
    needs: [test, test-matrix]
    if: always()
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"
        
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install hatch
        hatch env create test
        
    - name: Generate test report
      run: |
        hatch run test:pytest tests/ \
          --html=test-report.html \
          --self-contained-html \
          --tb=short \
          -v \
          -m "not slow and not benchmark" \
          --maxfail=20
          
    - name: Upload test report
      uses: actions/upload-artifact@v3
      with:
        name: test-report
        path: test-report.html
        
    - name: Comment PR with test results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          if (fs.existsSync('test-report.html')) {
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: 'ðŸ“Š Test report has been generated and uploaded as an artifact.'
            });
          }
