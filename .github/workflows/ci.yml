name: Continuous Integration

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  checks: write

env:
  PYTHON_VERSION: "3.11"
  HATCH_VERBOSE: 1

jobs:

  pre-commit:
    name: Pre-commit Hooks
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install pre-commit
      run: |
        python -m pip install --upgrade pip
        pip install pre-commit

    - name: Run pre-commit hooks
      run: |
        pre-commit run --all-files
      continue-on-error: true
      id: pre-commit-check

    - name: Upload pre-commit results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: pre-commit-results
        path: |
          reports/
          .pre-commit-hook-*
        retention-days: 30

  validate-structure:
    name: Validate Structure
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Run validation scripts
      run: |
        python scripts/validation/validate_structure.py
        python scripts/validation/validate_environment_organization.py
        python scripts/validation/validate_file_organization.py
        python scripts/validation/validate_quality_gates.py
  
  docs-lint:
    name: Documentation Lint
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install documentation dependencies
      run: |
        python -m pip install --upgrade pip
        pip install mkdocs mkdocs-material mkdocstrings[python] pymdown-extensions

    - name: Check for NotImplementedError usage
      run: |
        echo "Checking for undocumented NotImplementedError usage..."
        if grep -r "NotImplementedError" src/ --include="*.py" | grep -v "test_" | grep -v "#.*NotImplementedError"; then
          echo "❌ Found undocumented NotImplementedError usage in source code"
          echo "Please document these experimental features in README.md"
          exit 1
        else
          echo "✅ All NotImplementedError usage is properly documented"
        fi

    - name: Build MkDocs documentation
      run: |
        mkdocs build --config-file=config/docs/mkdocs.yml --strict

    - name: Check documentation links
      run: |
        python scripts/analysis/check_documentation_links.py
      continue-on-error: true

    - name: Upload documentation artifacts
      uses: actions/upload-artifact@v4
      with:
        name: documentation-build
        path: site/
        retention-days: 30
  # Job 1: Code Quality & Linting
  code-quality:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Hatch
      run: |
        python -m pip install --upgrade pip
        pip install hatch

    - name: Show Hatch version and project info
      run: |
        hatch --version
        hatch version
        hatch env show

    - name: Run code style checks
      run: |
        hatch env run lint:style
      continue-on-error: true
      id: style-check

    - name: Run type checking
      run: |
        hatch env run lint:typing
      continue-on-error: true
      id: type-check

    - name: Run code formatting check
      run: |
        hatch env run lint:fmt
      continue-on-error: true
      id: format-check

    - name: Generate quality report
      if: always()
      run: |
        mkdir -p reports
        echo "# Code Quality Report" > reports/quality-report.md
        echo "" >> reports/quality-report.md
        echo "**Generated:** $(date)" >> reports/quality-report.md
        echo "**Commit:** ${{ github.sha }}" >> reports/quality-report.md
        echo "" >> reports/quality-report.md
        echo "## Results Summary" >> reports/quality-report.md
        echo "" >> reports/quality-report.md
        echo "| Check | Status |" >> reports/quality-report.md
        echo "|-------|--------|" >> reports/quality-report.md
        echo "| Style Check | ${{ steps.style-check.outcome == 'success' && '✅ Passed' || '❌ Failed' }} |" >> reports/quality-report.md
        echo "| Type Check | ${{ steps.type-check.outcome == 'success' && '✅ Passed' || '❌ Failed' }} |" >> reports/quality-report.md
        echo "| Format Check | ${{ steps.format-check.outcome == 'success' && '✅ Passed' || '❌ Failed' }} |" >> reports/quality-report.md

    - name: Upload quality report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: code-quality-report
        path: reports/
        retention-days: 30

  # Job 2: Build & Package
  build:
    name: Build & Package
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Hatch
      run: |
        python -m pip install --upgrade pip
        pip install hatch

    - name: Show project version
      run: |
        echo "Project version: $(hatch version)"

    - name: Build package
      run: |
        hatch build --clean

    - name: Verify build artifacts
      run: |
        ls -la dist/
        echo "✅ Build artifacts created successfully"
        
        # Test installation
        pip install dist/*.whl
        python -c "import pynomaly; print('✅ Package installation test successful')"

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: build-artifacts
        path: dist/
        retention-days: 30

  # Job 3: Test Suite (Matrix)
  test:
    name: Test Suite
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.11", "3.12"]
        test-type: ["unit", "integration"]
      fail-fast: false
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install Hatch
      run: |
        python -m pip install --upgrade pip
        pip install hatch

    - name: Run unit tests
      if: matrix.test-type == 'unit'
      run: |
        hatch env run test:run tests/domain/ tests/application/ -v --tb=short
      continue-on-error: true

    - name: Run integration tests
      if: matrix.test-type == 'integration'
      run: |
        hatch env run test:run tests/infrastructure/ -v --tb=short --ignore=tests/infrastructure/test_*_performance*
      continue-on-error: true

    - name: Run tests with coverage
      run: |
        hatch env run test:run-cov --cov-report=xml --cov-report=html
      continue-on-error: true

    - name: Upload coverage to Codecov
      if: matrix.test-type == 'unit'
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        flags: py${{ matrix.python-version }}
        name: codecov-py${{ matrix.python-version }}

    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ matrix.test-type }}-py${{ matrix.python-version }}
        path: |
          htmlcov/
          coverage-reports/
          .coverage
          coverage-combined.xml
        retention-days: 30

  # Job 4: API & CLI Testing
  api-cli-test:
    name: API & CLI Testing
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Hatch
      run: |
        python -m pip install --upgrade pip
        pip install hatch

    - name: Test CLI help
      run: |
        hatch env run cli:test-cli
      continue-on-error: true

    - name: Test core functionality
      run: |
        python -c "
        import sys
        sys.path.insert(0, 'src')
        from pynomaly.domain.entities import Dataset, Anomaly
        from pynomaly.domain.value_objects import AnomalyScore, ContaminationRate
        print('✅ Core domain imports successful')
        "

    - name: Install API dependencies for testing
      run: |
        pip install "fastapi>=0.100.0" "uvicorn[standard]>=0.20.0"

    - name: Test API startup (10 second timeout)
      run: |
        timeout 10s python -m uvicorn pynomaly.presentation.api.app:app --host 0.0.0.0 --port 8000 || echo "✅ API startup test completed (expected timeout)"
      continue-on-error: true

  # Job 5: Security & Dependencies
  security:
    name: Security & Dependencies
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety

    - name: Run Bandit security scan
      run: |
        mkdir -p reports
        bandit -r src/ -f json -o reports/bandit-report.json || true
        bandit -r src/ -f txt || true
      continue-on-error: true

    - name: Run Safety dependency check
      run: |
        safety check --json --output reports/safety-report.json || true
        safety check || true
      continue-on-error: true

    - name: Upload security reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: security-reports
        path: reports/
        retention-days: 30

  # Job 6: Docker Build
  docker:
    name: Docker Build
    runs-on: ubuntu-latest
    needs: [build]
    
    steps:
    - name: Cache Python packages
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/scripts/**
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}

    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: deploy/docker/Dockerfile
        push: false
        tags: pynomaly:latest
        cache-from: type=gha
        cache-to: type=gha,mode=max

  # Job 7: Final CI Summary
  ci-summary:
    name: CI Summary
    runs-on: ubuntu-latest
    needs: [pre-commit, validate-structure, docs-lint, code-quality, build, test, api-cli-test, security, docker]
    if: always()
    
    steps:
    - name: Generate CI summary
      run: |
        mkdir -p ci-reports
        
        echo "# 🚀 CI Pipeline Summary" > ci-reports/ci-summary.md
        echo "" >> ci-reports/ci-summary.md
        echo "**Run Date:** $(date)" >> ci-reports/ci-summary.md
        echo "**Commit:** ${{ github.sha }}" >> ci-reports/ci-summary.md
        echo "**Branch:** ${{ github.ref_name }}" >> ci-reports/ci-summary.md
        echo "**Trigger:** ${{ github.event_name }}" >> ci-reports/ci-summary.md
        echo "" >> ci-reports/ci-summary.md
        
        echo "## 📊 Job Results" >> ci-reports/ci-summary.md
        echo "" >> ci-reports/ci-summary.md
        echo "| Job | Status | Description |" >> ci-reports/ci-summary.md
        echo "|-----|--------|-------------|" >> ci-reports/ci-summary.md
        echo "| Documentation | ${{ needs.docs-lint.result == 'success' && '✅ Passed' || needs.docs-lint.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | MkDocs build, link checking, NotImplementedError validation |" >> ci-reports/ci-summary.md
        echo "| Code Quality | ${{ needs.code-quality.result == 'success' && '✅ Passed' || needs.code-quality.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | Linting, formatting, type checking |" >> ci-reports/ci-summary.md
        echo "| Build & Package | ${{ needs.build.result == 'success' && '✅ Passed' || needs.build.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | Hatch build, wheel/sdist creation |" >> ci-reports/ci-summary.md
        echo "| Test Suite | ${{ needs.test.result == 'success' && '✅ Passed' || needs.test.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | Unit & integration tests (Python 3.11/3.12) |" >> ci-reports/ci-summary.md
        echo "| API & CLI | ${{ needs.api-cli-test.result == 'success' && '✅ Passed' || needs.api-cli-test.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | CLI commands, API startup test |" >> ci-reports/ci-summary.md
        echo "| Security Scan | ${{ needs.security.result == 'success' && '✅ Passed' || needs.security.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | Bandit security scan, Safety check |" >> ci-reports/ci-summary.md
        echo "| Docker Build | ${{ needs.docker.result == 'success' && '✅ Passed' || needs.docker.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | Container image build test |" >> ci-reports/ci-summary.md
        echo "" >> ci-reports/ci-summary.md
        
        # Overall status
        if [[ "${{ needs.build.result }}" == "success" && 
              "${{ needs.test.result }}" == "success" ]]; then
          echo "## 🎉 Overall Status: **PASSED**" >> ci-reports/ci-summary.md
          echo "" >> ci-reports/ci-summary.md
          echo "✅ All critical CI checks have passed successfully!" >> ci-reports/ci-summary.md
          echo "" >> ci-reports/ci-summary.md
          echo "**Ready for:**" >> ci-reports/ci-summary.md
          echo "- Merge to main branch" >> ci-reports/ci-summary.md
          echo "- Production deployment" >> ci-reports/ci-summary.md
          echo "- Release creation" >> ci-reports/ci-summary.md
        else
          echo "## ❌ Overall Status: **FAILED**" >> ci-reports/ci-summary.md
          echo "" >> ci-reports/ci-summary.md
          echo "Some critical CI checks have failed. Please review and fix issues before merging." >> ci-reports/ci-summary.md
          echo "" >> ci-reports/ci-summary.md
          echo "**Required for merge:**" >> ci-reports/ci-summary.md
          echo "- Build & Package must pass" >> ci-reports/ci-summary.md
          echo "- Test Suite must pass" >> ci-reports/ci-summary.md
        fi
        
        echo "" >> ci-reports/ci-summary.md
        echo "## 🔧 Hatch Commands Used" >> ci-reports/ci-summary.md
        echo "" >> ci-reports/ci-summary.md
        echo "- \`hatch version\` - Git-based version management" >> ci-reports/ci-summary.md
        echo "- \`hatch build --clean\` - Package building" >> ci-reports/ci-summary.md
        echo "- \`hatch env run lint:style\` - Code style checking" >> ci-reports/ci-summary.md
        echo "- \`hatch env run lint:typing\` - Type checking" >> ci-reports/ci-summary.md
        echo "- \`hatch env run test:run\` - Test execution" >> ci-reports/ci-summary.md
        echo "- \`hatch env run test:run-cov\` - Coverage analysis" >> ci-reports/ci-summary.md
        echo "- \`hatch env run cli:test-cli\` - CLI testing" >> ci-reports/ci-summary.md

    - name: Upload CI summary
      uses: actions/upload-artifact@v4
      with:
        name: ci-summary-report
        path: ci-reports/
        retention-days: 90

    - name: Comment on PR (if applicable)
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          // Generate summary comment
          const summary = `## 🚀 CI Pipeline Results

**Status Summary:**
- Documentation: ${{ needs.docs-lint.result == 'success' && '✅ Passed' || needs.docs-lint.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}
- Code Quality: ${{ needs.code-quality.result == 'success' && '✅ Passed' || needs.code-quality.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}
- Build & Package: ${{ needs.build.result == 'success' && '✅ Passed' || needs.build.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}
- Test Suite: ${{ needs.test.result == 'success' && '✅ Passed' || needs.test.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}
- API & CLI: ${{ needs.api-cli-test.result == 'success' && '✅ Passed' || needs.api-cli-test.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}
- Security: ${{ needs.security.result == 'success' && '✅ Passed' || needs.security.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}
- Docker: ${{ needs.docker.result == 'success' && '✅ Passed' || needs.docker.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}

**Hatch Migration:** ✅ Successfully using Hatch for build system and environment management

**Artifacts Generated:**
- Build artifacts (wheel and source distribution)
- Test coverage reports  
- Code quality analysis
- Security scan results

View detailed reports in the Actions artifacts.`;
          
          // Post comment
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: summary
          });

    - name: Set final exit code
      run: |
        if [[ "${{ needs.build.result }}" == "success" && 
              "${{ needs.test.result }}" == "success" ]]; then
          echo "✅ CI Pipeline completed successfully"
          exit 0
        else
          echo "❌ CI Pipeline failed - critical jobs did not pass"
          exit 1
        fi