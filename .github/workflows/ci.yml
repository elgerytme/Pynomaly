name: Continuous Integration

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  checks: write

env:
  PYTHON_VERSION: "3.11"
  HATCH_VERBOSE: 1
  # Cache configuration
  POETRY_CACHE_DIR: ~/.cache/pypoetry
  PIP_CACHE_DIR: ~/.cache/pip
  WHEEL_CACHE_DIR: ~/.cache/wheels

jobs:

  validate-structure:
    name: Validate Structure
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Run validation scripts
      run: |
        python scripts/validation/validate_structure.py
        python scripts/validation/validate_environment_organization.py
        python scripts/validation/validate_file_organization.py
        python scripts/validation/validate_quality_gates.py
  
  docs-lint:
    name: Documentation Lint
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install documentation dependencies
      run: |
        python -m pip install --upgrade pip
        pip install mkdocs mkdocs-material mkdocstrings[python] pymdown-extensions

    - name: Check for NotImplementedError usage
      run: |
        echo "Checking for undocumented NotImplementedError usage..."
        if grep -r "NotImplementedError" src/ --include="*.py" | grep -v "test_" | grep -v "#.*NotImplementedError"; then
          echo "❌ Found undocumented NotImplementedError usage in source code"
          echo "Please document these experimental features in README.md"
          exit 1
        else
          echo "✅ All NotImplementedError usage is properly documented"
        fi

    - name: Build MkDocs documentation
      run: |
        mkdocs build --config-file=config/docs/mkdocs.yml --strict

    - name: Check documentation links
      run: |
        python scripts/analysis/check_documentation_links.py
      continue-on-error: true

    - name: Upload documentation artifacts
      uses: actions/upload-artifact@v4
      with:
        name: documentation-build
        path: site/
        retention-days: 30
  # Job 1: Code Quality & Linting
  code-quality:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Hatch
      run: |
        python -m pip install --upgrade pip
        pip install hatch

    - name: Show Hatch version and project info
      run: |
        hatch --version
        hatch version
        hatch env show

    - name: Run code style checks
      run: |
        hatch env run lint:style
      continue-on-error: true
      id: style-check

    - name: Run type checking
      run: |
        hatch env run lint:typing
      continue-on-error: true
      id: type-check

    - name: Run code formatting check
      run: |
        hatch env run lint:fmt
      continue-on-error: true
      id: format-check

    - name: Generate quality report
      if: always()
      run: |
        mkdir -p reports
        echo "# Code Quality Report" > reports/quality-report.md
        echo "" >> reports/quality-report.md
        echo "**Generated:** $(date)" >> reports/quality-report.md
        echo "**Commit:** ${{ github.sha }}" >> reports/quality-report.md
        echo "" >> reports/quality-report.md
        echo "## Results Summary" >> reports/quality-report.md
        echo "" >> reports/quality-report.md
        echo "| Check | Status |" >> reports/quality-report.md
        echo "|-------|--------|" >> reports/quality-report.md
        echo "| Style Check | ${{ steps.style-check.outcome == 'success' && '✅ Passed' || '❌ Failed' }} |" >> reports/quality-report.md
        echo "| Type Check | ${{ steps.type-check.outcome == 'success' && '✅ Passed' || '❌ Failed' }} |" >> reports/quality-report.md
        echo "| Format Check | ${{ steps.format-check.outcome == 'success' && '✅ Passed' || '❌ Failed' }} |" >> reports/quality-report.md

    - name: Upload quality report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: code-quality-report
        path: reports/
        retention-days: 30

  # Job 2: Build & Package
  build:
    name: Build & Package
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Hatch
      run: |
        python -m pip install --upgrade pip
        pip install hatch

    - name: Show project version
      run: |
        echo "Project version: $(hatch version)"

    - name: Build package
      run: |
        hatch build --clean

    - name: Verify build artifacts
      run: |
        ls -la dist/
        echo "✅ Build artifacts created successfully"
        
        # Test installation
        pip install dist/*.whl
        python -c "import pynomaly; print('✅ Package installation test successful')"

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: build-artifacts
        path: dist/
        retention-days: 30

  # Job 3: Test Suite (Matrix) with Services
  test:
    name: Test Suite
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.11", "3.12"]
        test-type: ["unit", "integration"]
      fail-fast: false
    
    # Add services for integration tests
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_DB: pynomaly_test
          POSTGRES_USER: pynomaly
          POSTGRES_PASSWORD: pynomaly_test_password
        options: >
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 3s
          --health-retries 3
        ports:
          - 6379:6379
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
        cache-dependency-path: 'pyproject.toml'

    - name: Cache Python wheels for ML dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.cache/wheels
          ~/.cache/torch
          ~/.cache/tensorflow
          ~/.cache/jax
        key: ${{ runner.os }}-wheels-${{ matrix.python-version }}-${{ hashFiles('pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-wheels-${{ matrix.python-version }}-
          ${{ runner.os }}-wheels-

    - name: Install Hatch
      run: |
        python -m pip install --upgrade pip
        pip install hatch

    - name: Pre-install heavy ML dependencies (cached)
      run: |
        # Install heavy ML dependencies with caching
        python -m pip install --upgrade pip wheel setuptools
        
        # Install core ML dependencies that are commonly cached
        pip install --cache-dir ~/.cache/pip numpy==1.26.0 scipy scikit-learn
        
        # Only install deep learning deps for specific tests
        if [ "${{ matrix.test-type }}" = "integration" ]; then
          pip install --cache-dir ~/.cache/pip torch --index-url https://download.pytorch.org/whl/cpu
          pip install --cache-dir ~/.cache/pip tensorflow-cpu
        fi

    - name: Set up test environment variables
      run: |
        echo "PYNOMALY_DB_HOST=localhost" >> $GITHUB_ENV
        echo "PYNOMALY_DB_PORT=5432" >> $GITHUB_ENV
        echo "PYNOMALY_DB_NAME=pynomaly_test" >> $GITHUB_ENV
        echo "PYNOMALY_DB_USER=pynomaly" >> $GITHUB_ENV
        echo "PYNOMALY_DB_PASSWORD=pynomaly_test_password" >> $GITHUB_ENV
        echo "PYNOMALY_REDIS_HOST=localhost" >> $GITHUB_ENV
        echo "PYNOMALY_REDIS_PORT=6379" >> $GITHUB_ENV
        echo "PYNOMALY_REDIS_DB=0" >> $GITHUB_ENV
        echo "PYNOMALY_ENVIRONMENT=testing" >> $GITHUB_ENV

    - name: Run unit tests
      if: matrix.test-type == 'unit'
      run: |
        hatch env run test:run tests/domain/ tests/application/ -v --tb=short
      continue-on-error: true

    - name: Run integration tests
      if: matrix.test-type == 'integration'
      run: |
        # Wait for services to be ready
        timeout 60 bash -c 'until pg_isready -h localhost -p 5432; do sleep 1; done'
        timeout 30 bash -c 'until redis-cli -h localhost -p 6379 ping; do sleep 1; done'
        
        hatch env run test:run tests/infrastructure/ -v --tb=short --ignore=tests/infrastructure/test_*_performance*
      continue-on-error: true

    - name: Run tests with coverage
      run: |
        hatch env run test:run-cov --cov-report=xml --cov-report=html
      continue-on-error: true

    - name: Upload coverage to Codecov
      if: matrix.test-type == 'unit'
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        flags: py${{ matrix.python-version }}
        name: codecov-py${{ matrix.python-version }}

    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ matrix.test-type }}-py${{ matrix.python-version }}
        path: |
          htmlcov/
          coverage-reports/
          .coverage
          coverage-combined.xml
        retention-days: 30

  # Job 4: API & CLI Testing with Services
  api-cli-test:
    name: API & CLI Testing
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_DB: pynomaly_test
          POSTGRES_USER: pynomaly
          POSTGRES_PASSWORD: pynomaly_test_password
        options: >
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 3s
          --health-retries 3
        ports:
          - 6379:6379
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        cache-dependency-path: 'pyproject.toml'

    - name: Cache Python wheels
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.cache/wheels
        key: ${{ runner.os }}-api-cli-${{ hashFiles('pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-api-cli-

    - name: Install Hatch
      run: |
        python -m pip install --upgrade pip
        pip install hatch

    - name: Test CLI help
      run: |
        hatch env run cli:test-cli
      continue-on-error: true

    - name: Test core functionality
      run: |
        python -c "
        import sys
        sys.path.insert(0, 'src')
        from pynomaly.domain.entities import Dataset, Anomaly
        from pynomaly.domain.value_objects import AnomalyScore, ContaminationRate
        print('✅ Core domain imports successful')
        "

    - name: Set up API test environment
      run: |
        echo "PYNOMALY_DB_HOST=localhost" >> $GITHUB_ENV
        echo "PYNOMALY_DB_PORT=5432" >> $GITHUB_ENV
        echo "PYNOMALY_DB_NAME=pynomaly_test" >> $GITHUB_ENV
        echo "PYNOMALY_DB_USER=pynomaly" >> $GITHUB_ENV
        echo "PYNOMALY_DB_PASSWORD=pynomaly_test_password" >> $GITHUB_ENV
        echo "PYNOMALY_REDIS_HOST=localhost" >> $GITHUB_ENV
        echo "PYNOMALY_REDIS_PORT=6379" >> $GITHUB_ENV
        echo "PYNOMALY_ENVIRONMENT=testing" >> $GITHUB_ENV

    - name: Install API dependencies for testing
      run: |
        pip install "fastapi>=0.100.0" "uvicorn[standard]>=0.20.0"

    - name: Test API startup (10 second timeout)
      run: |
        # Wait for services to be ready
        timeout 60 bash -c 'until pg_isready -h localhost -p 5432; do sleep 1; done'
        timeout 30 bash -c 'until redis-cli -h localhost -p 6379 ping; do sleep 1; done'
        
        timeout 10s python -m uvicorn pynomaly.presentation.api.app:app --host 0.0.0.0 --port 8000 || echo "✅ API startup test completed (expected timeout)"
      continue-on-error: true

  # Job 5: Security & Dependencies
  security:
    name: Security & Dependencies
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety

    - name: Run Bandit security scan
      run: |
        mkdir -p reports
        bandit -r src/ -f json -o reports/bandit-report.json || true
        bandit -r src/ -f txt || true
      continue-on-error: true

    - name: Run Safety dependency check
      run: |
        safety check --json --output reports/safety-report.json || true
        safety check || true
      continue-on-error: true

    - name: Upload security reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: security-reports
        path: reports/
        retention-days: 30

  # Job 6: Security Scan (Dependency Graph)
  security-scan:
    name: Security Scan
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
      fail-fast: false
    runs-on: ${{ matrix.os }}
    needs: [build]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: build-artifacts
        path: dist/

    - name: Install built wheel for dependency analysis
      shell: bash
      run: |
        python -m pip install --upgrade pip
        # Install the wheel - handle different platforms
        if [[ "${{ matrix.os }}" == "windows-latest" ]]; then
          pip install dist/*.whl
        else
          pip install $(ls dist/*.whl)
        fi

    - name: Install security scanning tools
      run: |
        pip install bandit safety pip-audit cyclonedx-bom

    - name: Generate dependency graph (SBOM)
      shell: bash
      run: |
        mkdir -p security-reports
        cyclonedx-py -o security-reports/sbom.json
        echo "✅ Software Bill of Materials (SBOM) generated"

    - name: Run pip-audit for known vulnerabilities
      shell: bash
      run: |
        pip-audit --format=json --output=security-reports/pip-audit.json --progress-spinner=off
        pip-audit --format=sarif --output=security-reports/pip-audit.sarif --progress-spinner=off
        echo "✅ Vulnerability scan completed"
      continue-on-error: true

    - name: Run Bandit security scan on installed package
      shell: bash
      run: |
        python -c "import pynomaly; print('Package location:', pynomaly.__file__)"
        bandit -r $(python -c "import pynomaly; import os; print(os.path.dirname(pynomaly.__file__))") -f json -o security-reports/bandit-package.json
        echo "✅ Static security analysis completed"
      continue-on-error: true

    - name: Generate security summary
      shell: bash
      run: |
        echo "# Security Scan Report - ${{ matrix.os }}" > security-reports/security-summary.md
        echo "" >> security-reports/security-summary.md
        echo "**Generated:** $(date)" >> security-reports/security-summary.md
        echo "**OS:** ${{ matrix.os }}" >> security-reports/security-summary.md
        echo "**Python Version:** ${{ env.PYTHON_VERSION }}" >> security-reports/security-summary.md
        echo "" >> security-reports/security-summary.md
        echo "## Scans Performed" >> security-reports/security-summary.md
        echo "- ✅ SBOM (Software Bill of Materials) generated" >> security-reports/security-summary.md
        echo "- ✅ pip-audit vulnerability scan" >> security-reports/security-summary.md
        echo "- ✅ Bandit static security analysis" >> security-reports/security-summary.md
        echo "" >> security-reports/security-summary.md
        echo "## Artifacts" >> security-reports/security-summary.md
        echo "- SBOM: \`sbom.json\`" >> security-reports/security-summary.md
        echo "- Vulnerability Report: \`pip-audit.json\`, \`pip-audit.sarif\`" >> security-reports/security-summary.md
        echo "- Security Analysis: \`bandit-package.json\`" >> security-reports/security-summary.md

    - name: Upload security scan results
      uses: actions/upload-artifact@v4
      with:
        name: security-scan-${{ matrix.os }}
        path: security-reports/
        retention-days: 30

    - name: Upload SARIF results to GitHub Security
      if: matrix.os == 'ubuntu-latest' && github.event_name == 'push'
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: security-reports/pip-audit.sarif
        category: pip-audit

  # Job 7: Docker Build with Services Testing
  docker:
    name: Docker Build
    runs-on: ubuntu-latest
    needs: [build]
    
    steps:
    - name: Cache Python packages
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/scripts/**
        key: ${{ runner.os }}-docker-${{ hashFiles('**/requirements.txt', 'pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-docker-

    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: deploy/docker/Dockerfile
        push: false
        tags: pynomaly:latest
        cache-from: type=gha
        cache-to: type=gha,mode=max
        build-args: |
          BUILDKIT_INLINE_CACHE=1

    - name: Test Docker Compose development setup
      run: |
        # Test that docker-compose file is valid
        docker-compose -f docker-compose.development.yml config
        
        # Start services in background
        docker-compose -f docker-compose.development.yml up -d postgres redis
        
        # Wait for services to be ready
        timeout 60 bash -c 'until docker-compose -f docker-compose.development.yml exec -T postgres pg_isready -U pynomaly; do sleep 2; done'
        timeout 30 bash -c 'until docker-compose -f docker-compose.development.yml exec -T redis redis-cli ping; do sleep 2; done'
        
        # Clean up
        docker-compose -f docker-compose.development.yml down
        
        echo "✅ Docker Compose services test completed"

  # Job 8: Final CI Summary
  ci-summary:
    name: CI Summary
    runs-on: ubuntu-latest
    needs: [docs-lint, code-quality, build, test, api-cli-test, security, security-scan, docker]
    if: always()
    
    steps:
    - name: Generate CI summary
      run: |
        mkdir -p ci-reports
        
        echo "# 🚀 CI Pipeline Summary" > ci-reports/ci-summary.md
        echo "" >> ci-reports/ci-summary.md
        echo "**Run Date:** $(date)" >> ci-reports/ci-summary.md
        echo "**Commit:** ${{ github.sha }}" >> ci-reports/ci-summary.md
        echo "**Branch:** ${{ github.ref_name }}" >> ci-reports/ci-summary.md
        echo "**Trigger:** ${{ github.event_name }}" >> ci-reports/ci-summary.md
        echo "" >> ci-reports/ci-summary.md
        
        echo "## 📊 Job Results" >> ci-reports/ci-summary.md
        echo "" >> ci-reports/ci-summary.md
        echo "| Job | Status | Description |" >> ci-reports/ci-summary.md
        echo "|-----|--------|-------------|" >> ci-reports/ci-summary.md
        echo "| Documentation | ${{ needs.docs-lint.result == 'success' && '✅ Passed' || needs.docs-lint.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | MkDocs build, link checking, NotImplementedError validation |" >> ci-reports/ci-summary.md
        echo "| Code Quality | ${{ needs.code-quality.result == 'success' && '✅ Passed' || needs.code-quality.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | Linting, formatting, type checking |" >> ci-reports/ci-summary.md
        echo "| Build & Package | ${{ needs.build.result == 'success' && '✅ Passed' || needs.build.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | Hatch build, wheel/sdist creation |" >> ci-reports/ci-summary.md
        echo "| Test Suite | ${{ needs.test.result == 'success' && '✅ Passed' || needs.test.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | Unit & integration tests (Python 3.11/3.12) |" >> ci-reports/ci-summary.md
        echo "| API & CLI | ${{ needs.api-cli-test.result == 'success' && '✅ Passed' || needs.api-cli-test.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | CLI commands, API startup test |" >> ci-reports/ci-summary.md
        echo "| Security Scan | ${{ needs.security.result == 'success' && '✅ Passed' || needs.security.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | Bandit security scan, Safety check |" >> ci-reports/ci-summary.md
        echo "| Security Scan (Deps) | ${{ needs.security-scan.result == 'success' && '✅ Passed' || needs.security-scan.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | Dependency graph, SBOM, pip-audit vulnerability scan |" >> ci-reports/ci-summary.md
        echo "| Docker Build | ${{ needs.docker.result == 'success' && '✅ Passed' || needs.docker.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }} | Container image build test |" >> ci-reports/ci-summary.md
        echo "" >> ci-reports/ci-summary.md
        
        # Overall status
        if [[ "${{ needs.build.result }}" == "success" && 
              "${{ needs.test.result }}" == "success" && 
              "${{ needs.security-scan.result }}" == "success" ]]; then
          echo "## 🎉 Overall Status: **PASSED**" >> ci-reports/ci-summary.md
          echo "" >> ci-reports/ci-summary.md
          echo "✅ All critical CI checks have passed successfully!" >> ci-reports/ci-summary.md
          echo "" >> ci-reports/ci-summary.md
          echo "**Ready for:**" >> ci-reports/ci-summary.md
          echo "- Merge to main branch" >> ci-reports/ci-summary.md
          echo "- Production deployment" >> ci-reports/ci-summary.md
          echo "- Release creation" >> ci-reports/ci-summary.md
        else
          echo "## ❌ Overall Status: **FAILED**" >> ci-reports/ci-summary.md
          echo "" >> ci-reports/ci-summary.md
          echo "Some critical CI checks have failed. Please review and fix issues before merging." >> ci-reports/ci-summary.md
          echo "" >> ci-reports/ci-summary.md
          echo "**Required for merge:**" >> ci-reports/ci-summary.md
          echo "- Build & Package must pass" >> ci-reports/ci-summary.md
          echo "- Test Suite must pass" >> ci-reports/ci-summary.md
          echo "- Security Scan (Deps) must pass" >> ci-reports/ci-summary.md
        fi
        
        echo "" >> ci-reports/ci-summary.md
        echo "## 🔧 Hatch Commands Used" >> ci-reports/ci-summary.md
        echo "" >> ci-reports/ci-summary.md
        echo "- \`hatch version\` - Git-based version management" >> ci-reports/ci-summary.md
        echo "- \`hatch build --clean\` - Package building" >> ci-reports/ci-summary.md
        echo "- \`hatch env run lint:style\` - Code style checking" >> ci-reports/ci-summary.md
        echo "- \`hatch env run lint:typing\` - Type checking" >> ci-reports/ci-summary.md
        echo "- \`hatch env run test:run\` - Test execution" >> ci-reports/ci-summary.md
        echo "- \`hatch env run test:run-cov\` - Coverage analysis" >> ci-reports/ci-summary.md
        echo "- \`hatch env run cli:test-cli\` - CLI testing" >> ci-reports/ci-summary.md

    - name: Upload CI summary
      uses: actions/upload-artifact@v4
      with:
        name: ci-summary-report
        path: ci-reports/
        retention-days: 90

    - name: Comment on PR (if applicable)
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          // Generate summary comment
          const summary = `## 🚀 CI Pipeline Results

**Status Summary:**
- Documentation: ${{ needs.docs-lint.result == 'success' && '✅ Passed' || needs.docs-lint.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}
- Code Quality: ${{ needs.code-quality.result == 'success' && '✅ Passed' || needs.code-quality.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}
- Build & Package: ${{ needs.build.result == 'success' && '✅ Passed' || needs.build.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}
- Test Suite: ${{ needs.test.result == 'success' && '✅ Passed' || needs.test.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}
- API & CLI: ${{ needs.api-cli-test.result == 'success' && '✅ Passed' || needs.api-cli-test.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}
- Security: ${{ needs.security.result == 'success' && '✅ Passed' || needs.security.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}
- Security Scan (Deps): ${{ needs.security-scan.result == 'success' && '✅ Passed' || needs.security-scan.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}
- Docker: ${{ needs.docker.result == 'success' && '✅ Passed' || needs.docker.result == 'failure' && '❌ Failed' || '⚠️ Skipped' }}

**Hatch Migration:** ✅ Successfully using Hatch for build system and environment management

**Artifacts Generated:**
- Build artifacts (wheel and source distribution)
- Test coverage reports  
- Code quality analysis
- Security scan results

View detailed reports in the Actions artifacts.`;
          
          // Post comment
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: summary
          });

    - name: Set final exit code
      run: |
        if [[ "${{ needs.build.result }}" == "success" && 
              "${{ needs.test.result }}" == "success" && 
              "${{ needs.security-scan.result }}" == "success" ]]; then
          echo "✅ CI Pipeline completed successfully"
          exit 0
        else
          echo "❌ CI Pipeline failed - critical jobs did not pass"
          exit 1
        fi
