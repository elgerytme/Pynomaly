name: Performance Testing

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'src/pynomaly/presentation/web/**'
      - 'tests/ui/performance/**'
      - 'package.json'
      - '.github/workflows/performance-testing.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'src/pynomaly/presentation/web/**'
      - 'tests/ui/performance/**'
      - 'package.json'
  schedule:
    # Run performance tests daily at 3 AM UTC
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of performance test to run'
        required: true
        default: 'all'
        type: choice
        options:
        - all
        - core-web-vitals
        - mobile
        - slow-network
      performance_budget:
        description: 'Enable performance budget checks'
        required: false
        default: true
        type: boolean

jobs:
  performance-test:
    name: Performance Testing
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    strategy:
      fail-fast: false
      matrix:
        test-type: 
          - core-web-vitals
          - mobile
          - slow-network
        include:
          - test-type: core-web-vitals
            project: performance-chrome
            timeout: 20
          - test-type: mobile
            project: performance-mobile-chrome
            timeout: 25
          - test-type: slow-network
            project: performance-slow-network
            timeout: 30

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        npm ci
        pip install -r requirements.txt

    - name: Install Playwright Browsers
      run: npx playwright install chromium firefox webkit --with-deps

    - name: Build application
      run: |
        npm run build
        echo "Build completed successfully"

    - name: Start application server
      run: |
        # Start the Pynomaly server in the background
        python -m uvicorn src.pynomaly.presentation.api.main:app --host 0.0.0.0 --port 8000 &
        
        # Wait for server to be ready
        timeout 60 bash -c 'until curl -f http://localhost:8000/health; do sleep 2; done'
        echo "Server is ready"

    - name: Run Performance Tests
      run: |
        if [ "${{ github.event.inputs.test_type }}" = "all" ] || [ "${{ github.event.inputs.test_type }}" = "" ]; then
          npx playwright test --config=tests/ui/performance/playwright.config.ts --project=${{ matrix.project }}
        else
          npx playwright test --config=tests/ui/performance/playwright.config.ts --project=${{ matrix.project }} --grep="${{ github.event.inputs.test_type }}"
        fi
      timeout-minutes: ${{ matrix.timeout }}
      env:
        BASE_URL: http://localhost:8000
        CI: true

    - name: Generate Performance Report
      if: always()
      run: |
        # Create performance summary
        mkdir -p reports/performance
        
        # Extract performance metrics from test results
        if [ -f "test-results/performance/results.json" ]; then
          node -e "
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('test-results/performance/results.json', 'utf8'));
            
            const summary = {
              testType: '${{ matrix.test-type }}',
              timestamp: new Date().toISOString(),
              totalTests: results.suites.reduce((acc, suite) => acc + suite.specs.length, 0),
              passedTests: results.suites.reduce((acc, suite) => 
                acc + suite.specs.filter(spec => spec.tests.every(test => test.status === 'passed')).length, 0),
              failedTests: results.suites.reduce((acc, suite) => 
                acc + suite.specs.filter(spec => spec.tests.some(test => test.status === 'failed')).length, 0),
              duration: results.stats?.duration || 0
            };
            
            fs.writeFileSync('reports/performance/summary-${{ matrix.test-type }}.json', JSON.stringify(summary, null, 2));
            console.log('Performance Summary for ${{ matrix.test-type }}:');
            console.log(JSON.stringify(summary, null, 2));
          "
        fi

    - name: Upload Performance Results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: performance-results-${{ matrix.test-type }}
        path: |
          test-results/performance/
          reports/performance/
        retention-days: 30

    - name: Comment Performance Results on PR
      if: github.event_name == 'pull_request' && always()
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const path = 'reports/performance/summary-${{ matrix.test-type }}.json';
          
          if (fs.existsSync(path)) {
            const summary = JSON.parse(fs.readFileSync(path, 'utf8'));
            
            const comment = `
            ## ðŸš€ Performance Test Results (${{ matrix.test-type }})
            
            | Metric | Value |
            |--------|-------|
            | Total Tests | ${summary.totalTests} |
            | Passed | âœ… ${summary.passedTests} |
            | Failed | âŒ ${summary.failedTests} |
            | Duration | ${Math.round(summary.duration / 1000)}s |
            | Test Type | ${{ matrix.test-type }} |
            | Timestamp | ${summary.timestamp} |
            
            ${summary.failedTests > 0 ? 'âš ï¸ Some performance tests failed. Please review the results.' : 'âœ… All performance tests passed!'}
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          }

  lighthouse-audit:
    name: Lighthouse Performance Audit
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        npm ci
        pip install -r requirements.txt

    - name: Build application
      run: npm run build

    - name: Start application server
      run: |
        python -m uvicorn src.pynomaly.presentation.api.main:app --host 0.0.0.0 --port 8000 &
        timeout 60 bash -c 'until curl -f http://localhost:8000/health; do sleep 2; done'

    - name: Run Lighthouse CI
      run: |
        # Create lighthouse configuration
        cat > lighthouserc.json << EOF
        {
          "ci": {
            "collect": {
              "url": ["http://localhost:8000/", "http://localhost:8000/login", "http://localhost:8000/dashboard"],
              "numberOfRuns": 3,
              "settings": {
                "chromeFlags": "--no-sandbox --disable-dev-shm-usage"
              }
            },
            "assert": {
              "preset": "lighthouse:recommended",
              "assertions": {
                "categories:performance": ["error", {"minScore": 0.8}],
                "categories:accessibility": ["error", {"minScore": 0.9}],
                "categories:best-practices": ["error", {"minScore": 0.9}],
                "categories:seo": ["error", {"minScore": 0.8}],
                "first-contentful-paint": ["error", {"maxNumericValue": 2000}],
                "largest-contentful-paint": ["error", {"maxNumericValue": 2500}],
                "cumulative-layout-shift": ["error", {"maxNumericValue": 0.1}]
              }
            },
            "upload": {
              "target": "temporary-public-storage"
            }
          }
        }
        EOF
        
        npx lhci autorun

    - name: Upload Lighthouse Results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: lighthouse-results
        path: .lighthouseci/
        retention-days: 30

  performance-regression:
    name: Performance Regression Detection
    runs-on: ubuntu-latest
    needs: [performance-test]
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Download Performance Results
      uses: actions/download-artifact@v4
      with:
        pattern: performance-results-*
        path: performance-results/
        merge-multiple: true

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: Analyze Performance Regression
      run: |
        node -e "
          const fs = require('fs');
          const path = require('path');
          
          // Read all performance summaries
          const resultsDir = 'performance-results';
          const summaries = [];
          
          if (fs.existsSync(resultsDir)) {
            const files = fs.readdirSync(resultsDir, { recursive: true });
            
            files.forEach(file => {
              if (file.endsWith('.json') && file.includes('summary-')) {
                const filePath = path.join(resultsDir, file);
                try {
                  const summary = JSON.parse(fs.readFileSync(filePath, 'utf8'));
                  summaries.push(summary);
                } catch (e) {
                  console.log('Could not parse:', filePath);
                }
              }
            });
          }
          
          // Performance regression analysis
          const totalTests = summaries.reduce((acc, s) => acc + s.totalTests, 0);
          const totalFailed = summaries.reduce((acc, s) => acc + s.failedTests, 0);
          const averageDuration = summaries.reduce((acc, s) => acc + s.duration, 0) / summaries.length;
          
          const regressionReport = {
            timestamp: new Date().toISOString(),
            totalTests,
            totalFailed,
            successRate: ((totalTests - totalFailed) / totalTests * 100).toFixed(2),
            averageDuration: Math.round(averageDuration / 1000),
            testTypes: summaries.map(s => s.testType),
            hasRegression: totalFailed > 0
          };
          
          console.log('Performance Regression Report:');
          console.log(JSON.stringify(regressionReport, null, 2));
          
          // Write report
          fs.writeFileSync('performance-regression-report.json', JSON.stringify(regressionReport, null, 2));
          
          // Exit with error if regressions detected
          if (regressionReport.hasRegression) {
            console.error('Performance regressions detected!');
            process.exit(1);
          }
        "

    - name: Comment Regression Analysis on PR
      if: always()
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          if (fs.existsSync('performance-regression-report.json')) {
            const report = JSON.parse(fs.readFileSync('performance-regression-report.json', 'utf8'));
            
            const statusIcon = report.hasRegression ? 'âŒ' : 'âœ…';
            const statusText = report.hasRegression ? 'Performance regressions detected!' : 'No performance regressions detected';
            
            const comment = `
            ## ðŸ“Š Performance Regression Analysis
            
            ${statusIcon} **${statusText}**
            
            | Metric | Value |
            |--------|-------|
            | Total Tests | ${report.totalTests} |
            | Success Rate | ${report.successRate}% |
            | Average Duration | ${report.averageDuration}s |
            | Test Types | ${report.testTypes.join(', ')} |
            | Analysis Time | ${report.timestamp} |
            
            ${report.hasRegression ? 
              'âš ï¸ **Action Required**: Performance tests are failing. Please review and optimize before merging.' : 
              'ðŸŽ‰ **Great!**: All performance tests are passing. No regressions detected.'}
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          }

  performance-budget:
    name: Performance Budget Check
    runs-on: ubuntu-latest
    if: github.event.inputs.performance_budget == 'true' || github.event.inputs.performance_budget == ''
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Build and Analyze Bundle
      run: |
        npm run build
        npm run analyze-bundle
        
        # Create performance budget report
        node -e "
          const fs = require('fs');
          
          // Performance budget thresholds
          const budget = {
            javascript: 1024 * 1024,  // 1MB
            css: 256 * 1024,         // 256KB
            images: 2 * 1024 * 1024, // 2MB
            total: 3 * 1024 * 1024   // 3MB
          };
          
          // This would read actual bundle analysis results
          // For now, we'll create a mock report
          const budgetReport = {
            timestamp: new Date().toISOString(),
            budget,
            actual: {
              javascript: 800 * 1024,
              css: 150 * 1024,
              images: 1500 * 1024,
              total: 2450 * 1024
            },
            status: 'PASSED'
          };
          
          // Check if budget is exceeded
          Object.keys(budget).forEach(key => {
            if (budgetReport.actual[key] > budget[key]) {
              budgetReport.status = 'FAILED';
            }
          });
          
          fs.writeFileSync('performance-budget-report.json', JSON.stringify(budgetReport, null, 2));
          console.log('Performance Budget Report:');
          console.log(JSON.stringify(budgetReport, null, 2));
        "

    - name: Upload Budget Report
      uses: actions/upload-artifact@v4
      with:
        name: performance-budget-report
        path: performance-budget-report.json
        retention-days: 30
