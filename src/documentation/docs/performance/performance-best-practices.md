# Performance Best Practices Guide

ğŸ **Breadcrumb:** ğŸ  [Home](../index.md) > ğŸ“ Performance

---


## ğŸš€ **Overview**

This comprehensive guide provides performance optimization strategies, Core Web Vitals improvement techniques, and monitoring best practices for the Pynomaly platform. It covers both frontend and backend performance optimization with specific focus on anomaly detection workloads.

## ğŸ“‹ **Table of Contents**

- [ğŸ¯ Performance Strategy](#-performance-strategy)
- [âš¡ Core Web Vitals](#-core-web-vitals)
- [ğŸ—ï¸ Frontend Optimization](#ï¸-frontend-optimization)
- [ğŸ”§ Backend Optimization](#-backend-optimization)
- [ğŸ“Š Bundle Analysis](#-bundle-analysis)
- [ğŸ—„ï¸ Caching Strategies](#ï¸-caching-strategies)
- [ğŸ“± Mobile Performance](#-mobile-performance)
- [ğŸ” Monitoring and Metrics](#-monitoring-and-metrics)
- [ğŸ› ï¸ Tools and Automation](#ï¸-tools-and-automation)
- [ğŸš¨ Performance Troubleshooting](#-performance-troubleshooting)

## ğŸ¯ **Performance Strategy**

### Performance Budget

Our performance budget defines acceptable limits for key metrics:

| Metric | Target | Acceptable | Poor |
|--------|--------|------------|------|
| **First Contentful Paint (FCP)** | <1.8s | <3.0s | >3.0s |
| **Largest Contentful Paint (LCP)** | <2.5s | <4.0s | >4.0s |
| **First Input Delay (FID)** | <100ms | <300ms | >300ms |
| **Cumulative Layout Shift (CLS)** | <0.1 | <0.25 | >0.25 |
| **Total Blocking Time (TBT)** | <200ms | <600ms | >600ms |
| **Speed Index** | <3.4s | <5.8s | >5.8s |

### Performance Hierarchy

```
ğŸ”º Critical Path (Above-the-fold content)
  - Navigation header
  - Main content area
  - Primary CTAs

ğŸ”ºğŸ”º Important Content (Immediately visible)
  - Secondary navigation
  - Key data visualizations
  - Form elements

ğŸ”ºğŸ”ºğŸ”º Secondary Content (Below-the-fold)
  - Footer content
  - Additional features
  - Non-critical widgets

ğŸ”ºğŸ”ºğŸ”ºğŸ”º Enhancement Content (Progressive)
  - Advanced visualizations
  - Detailed analytics
  - Optional integrations
```

### Performance Testing Strategy

1. **Continuous Monitoring**: Real-time performance tracking in production
2. **Regression Testing**: Automated performance tests in CI/CD pipeline
3. **User Experience Monitoring**: Real User Monitoring (RUM) data collection
4. **Synthetic Testing**: Lighthouse CI and WebPageTest integration
5. **Load Testing**: Backend performance under various load conditions

## âš¡ **Core Web Vitals**

### Largest Contentful Paint (LCP) Optimization

**Target: <2.5 seconds**

#### Image Optimization
```html
<!-- Use modern image formats with fallbacks -->
<picture>
  <source srcset="hero-image.avif" type="image/avif">
  <source srcset="hero-image.webp" type="image/webp">
  <img src="hero-image.jpg" alt="Hero image"
       width="800" height="400"
       loading="eager"
       fetchpriority="high">
</picture>

<!-- Responsive images for different viewport sizes -->
<img srcset="chart-small.webp 480w,
             chart-medium.webp 800w,
             chart-large.webp 1200w"
     sizes="(max-width: 480px) 480px,
            (max-width: 800px) 800px,
            1200px"
     src="chart-medium.webp"
     alt="Data visualization chart">
```

#### Critical Resource Preloading
```html
<!-- Preload critical fonts -->
<link rel="preload" href="/fonts/inter-var.woff2" as="font" type="font/woff2" crossorigin>

<!-- Preload critical images -->
<link rel="preload" href="/images/hero-banner.webp" as="image">

<!-- Preload critical CSS -->
<link rel="preload" href="/css/critical.css" as="style" onload="this.onload=null;this.rel='stylesheet'">

<!-- Preload critical JavaScript -->
<link rel="preload" href="/js/critical.js" as="script">
```

#### Server-Side Optimization
```python
# Fast API response optimization
from fastapi import FastAPI, Response
from fastapi.responses import StreamingResponse
import gzip
import io

app = FastAPI()

@app.middleware("http")
async def add_performance_headers(request, call_next):
    response = await call_next(request)

    # Add performance-related headers
    response.headers["X-Frame-Options"] = "DENY"
    response.headers["X-Content-Type-Options"] = "nosniff"
    response.headers["Cache-Control"] = "public, max-age=31536000, immutable"

    return response

@app.get("/api/data/large-dataset")
async def get_large_dataset():
    # Stream large responses to improve TTFB
    def generate_data():
        for chunk in get_data_chunks():
            yield chunk

    return StreamingResponse(
        generate_data(),
        media_type="application/json",
        headers={"Content-Encoding": "gzip"}
    )
```

### First Input Delay (FID) Optimization

**Target: <100 milliseconds**

#### JavaScript Optimization
```javascript
// Use requestIdleCallback for non-critical work
function performNonCriticalWork() {
  if ('requestIdleCallback' in window) {
    requestIdleCallback(() => {
      // Perform heavy computations when browser is idle
      processAnalyticsData();
      updateSecondaryCharts();
    });
  } else {
    // Fallback for browsers without requestIdleCallback
    setTimeout(performNonCriticalWork, 50);
  }
}

// Use Web Workers for heavy computations
class AnomalyWorker {
  constructor() {
    this.worker = new Worker('/js/workers/anomaly-detection.js');
    this.setupMessageHandler();
  }

  setupMessageHandler() {
    this.worker.onmessage = (event) => {
      const { type, data, id } = event.data;

      switch (type) {
        case 'ANOMALY_DETECTED':
          this.handleAnomalyResult(data, id);
          break;
        case 'PROCESSING_COMPLETE':
          this.handleProcessingComplete(data, id);
          break;
      }
    };
  }

  detectAnomalies(dataset, options = {}) {
    return new Promise((resolve, reject) => {
      const id = Date.now();

      this.worker.postMessage({
        type: 'DETECT_ANOMALIES',
        data: { dataset, options },
        id
      });

      // Store resolve/reject for this operation
      this.pendingOperations.set(id, { resolve, reject });
    });
  }
}

// Optimize event handlers
class PerformantEventHandler {
  constructor() {
    this.debounceMap = new Map();
    this.throttleMap = new Map();
  }

  // Debounce for search inputs
  debounce(func, delay, key) {
    if (this.debounceMap.has(key)) {
      clearTimeout(this.debounceMap.get(key));
    }

    const timeoutId = setTimeout(() => {
      func();
      this.debounceMap.delete(key);
    }, delay);

    this.debounceMap.set(key, timeoutId);
  }

  // Throttle for scroll events
  throttle(func, delay, key) {
    if (this.throttleMap.has(key)) {
      return;
    }

    this.throttleMap.set(key, true);

    setTimeout(() => {
      func();
      this.throttleMap.delete(key);
    }, delay);
  }
}

// Example usage
const eventHandler = new PerformantEventHandler();

// Debounced search
document.getElementById('search').addEventListener('input', (e) => {
  eventHandler.debounce(() => {
    performSearch(e.target.value);
  }, 300, 'search');
});

// Throttled scroll
window.addEventListener('scroll', () => {
  eventHandler.throttle(() => {
    updateScrollProgress();
  }, 16, 'scroll'); // ~60fps
});
```

#### Code Splitting and Lazy Loading
```javascript
// Dynamic imports for route-based code splitting
const routeHandlers = {
  '/dashboard': () => import('./pages/Dashboard.js'),
  '/datasets': () => import('./pages/Datasets.js'),
  '/models': () => import('./pages/Models.js'),
  '/analytics': () => import('./pages/Analytics.js')
};

async function loadRoute(path) {
  try {
    const moduleLoader = routeHandlers[path];
    if (moduleLoader) {
      const module = await moduleLoader();
      return module.default;
    }
  } catch (error) {
    console.error('Failed to load route:', path, error);
    // Fallback to error page
    return import('./pages/ErrorPage.js');
  }
}

// Lazy load heavy libraries
async function loadChartingLibrary() {
  const { default: Chart } = await import('./vendors/charts.js');
  return Chart;
}

// Intersection Observer for lazy loading content
class LazyLoader {
  constructor() {
    this.observer = new IntersectionObserver(
      this.handleIntersection.bind(this),
      {
        rootMargin: '50px 0px',
        threshold: 0.1
      }
    );
  }

  observe(element) {
    this.observer.observe(element);
  }

  handleIntersection(entries) {
    entries.forEach(entry => {
      if (entry.isIntersecting) {
        this.loadContent(entry.target);
        this.observer.unobserve(entry.target);
      }
    });
  }

  async loadContent(element) {
    const componentType = element.dataset.component;

    switch (componentType) {
      case 'chart':
        await this.loadChart(element);
        break;
      case 'table':
        await this.loadTable(element);
        break;
      case 'map':
        await this.loadMap(element);
        break;
    }
  }

  async loadChart(element) {
    const Chart = await loadChartingLibrary();
    const config = JSON.parse(element.dataset.config);
    new Chart(element, config);
  }
}
```

### Cumulative Layout Shift (CLS) Optimization

**Target: <0.1**

#### Reserve Space for Dynamic Content
```css
/* Reserve space for images */
.image-container {
  aspect-ratio: 16 / 9;
  background-color: #f3f4f6;
  display: flex;
  align-items: center;
  justify-content: center;
}

.image-container img {
  width: 100%;
  height: 100%;
  object-fit: cover;
}

/* Reserve space for ads or widgets */
.widget-placeholder {
  min-height: 250px;
  background: linear-gradient(90deg, #f0f0f0 25%, #e0e0e0 50%, #f0f0f0 75%);
  background-size: 200% 100%;
  animation: loading 1.5s infinite;
}

@keyframes loading {
  0% { background-position: 200% 0; }
  100% { background-position: -200% 0; }
}

/* Skeleton screens for content loading */
.skeleton-text {
  background: linear-gradient(90deg, #f0f0f0 25%, #e0e0e0 50%, #f0f0f0 75%);
  background-size: 200% 100%;
  animation: loading 1.5s infinite;
  border-radius: 4px;
  height: 1em;
  margin: 0.5em 0;
}

.skeleton-text.title {
  width: 60%;
  height: 1.5em;
}

.skeleton-text.line {
  width: 100%;
}

.skeleton-text.short {
  width: 40%;
}
```

#### Font Loading Optimization
```css
/* Prevent font swap layout shift */
@font-face {
  font-family: 'Inter';
  src: url('/fonts/inter-var.woff2') format('woff2-variations');
  font-weight: 100 900;
  font-style: normal;
  font-display: swap;
  size-adjust: 100%;
  ascent-override: 90%;
  descent-override: 22%;
  line-gap-override: 0%;
}

/* Fallback font matching */
.font-loading {
  font-family: 'Inter', system-ui, -apple-system, BlinkMacSystemFont, sans-serif;
  font-size: 16px;
  line-height: 1.5;
  /* Match Inter's metrics with system fonts */
  font-feature-settings: 'kern' 1, 'liga' 1, 'calt' 1;
}
```

#### JavaScript Layout Management
```javascript
// Prevent layout shift when adding content
class LayoutStabilizer {
  static measureAndUpdate(container, updateCallback) {
    // Measure current layout
    const initialHeight = container.getBoundingClientRect().height;

    // Perform update
    updateCallback();

    // Measure new layout
    const newHeight = container.getBoundingClientRect().height;

    // If height changed significantly, animate the transition
    if (Math.abs(newHeight - initialHeight) > 5) {
      container.style.transition = 'height 0.3s ease-out';
      container.style.height = `${initialHeight}px`;

      requestAnimationFrame(() => {
        container.style.height = `${newHeight}px`;

        setTimeout(() => {
          container.style.transition = '';
          container.style.height = '';
        }, 300);
      });
    }
  }

  static async loadImageWithPlaceholder(img, src) {
    return new Promise((resolve, reject) => {
      // Create a temporary image to get dimensions
      const tempImg = new Image();

      tempImg.onload = () => {
        // Set placeholder with correct aspect ratio
        const aspectRatio = tempImg.height / tempImg.width;
        img.style.aspectRatio = `${tempImg.width} / ${tempImg.height}`;

        // Load the actual image
        img.src = src;
        img.onload = resolve;
        img.onerror = reject;
      };

      tempImg.src = src;
    });
  }
}

// Usage example
async function loadDynamicContent(container) {
  try {
    LayoutStabilizer.measureAndUpdate(container, () => {
      // Add loading skeleton
      container.innerHTML = `
        <div class="skeleton-text title"></div>
        <div class="skeleton-text line"></div>
        <div class="skeleton-text line"></div>
        <div class="skeleton-text short"></div>
      `;
    });

    // Fetch content
    const content = await fetch('/api/dynamic-content').then(r => r.json());

    LayoutStabilizer.measureAndUpdate(container, () => {
      // Replace with actual content
      container.innerHTML = content.html;
    });

  } catch (error) {
    console.error('Failed to load dynamic content:', error);
  }
}
```

## ğŸ—ï¸ **Frontend Optimization**

### Asset Optimization

#### CSS Optimization
```css
/* Use efficient selectors */
/* Good: Class selectors */
.button { }
.card { }
.navigation { }

/* Avoid: Complex descendant selectors */
/* Bad: .sidebar .navigation .menu .item .link { } */

/* Use CSS custom properties for theming */
:root {
  --color-primary: #0ea5e9;
  --color-secondary: #22c55e;
  --font-family-base: 'Inter', system-ui, sans-serif;
  --border-radius-base: 0.375rem;
  --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.05);
}

/* Optimize animations for performance */
.smooth-animation {
  /* Use transform and opacity for smooth animations */
  transform: translateX(0);
  opacity: 1;
  transition: transform 0.3s ease-out, opacity 0.3s ease-out;

  /* Use will-change sparingly */
  will-change: transform, opacity;
}

.smooth-animation.hidden {
  transform: translateX(-100%);
  opacity: 0;
}

/* Remove will-change after animation */
.animation-complete {
  will-change: auto;
}

/* Use containment for performance */
.chart-container {
  contain: layout style paint;
}

.data-table {
  contain: layout;
}
```

#### JavaScript Optimization
```javascript
// Optimize DOM manipulation
class DOMOptimizer {
  static batchUpdates(updates) {
    // Use DocumentFragment for multiple DOM insertions
    const fragment = document.createDocumentFragment();

    updates.forEach(update => {
      const element = document.createElement(update.tag);
      element.className = update.className;
      element.textContent = update.content;
      fragment.appendChild(element);
    });

    return fragment;
  }

  static measureLayout() {
    // Batch DOM reads to avoid layout thrashing
    const measurements = [];
    const elements = document.querySelectorAll('[data-measure]');

    // Read phase
    elements.forEach(element => {
      measurements.push({
        element,
        rect: element.getBoundingClientRect(),
        scrollTop: element.scrollTop
      });
    });

    // Write phase
    measurements.forEach(({ element, rect }) => {
      element.style.height = `${rect.height}px`;
    });
  }

  static virtualizeList(container, items, renderItem, itemHeight = 50) {
    const viewportHeight = container.clientHeight;
    const visibleItems = Math.ceil(viewportHeight / itemHeight) + 2;

    let scrollTop = 0;
    const totalHeight = items.length * itemHeight;

    function render() {
      const startIndex = Math.floor(scrollTop / itemHeight);
      const endIndex = Math.min(startIndex + visibleItems, items.length);

      const visibleItems = items.slice(startIndex, endIndex);
      const offsetY = startIndex * itemHeight;

      container.innerHTML = `
        <div style="height: ${totalHeight}px; position: relative;">
          <div style="transform: translateY(${offsetY}px);">
            ${visibleItems.map(renderItem).join('')}
          </div>
        </div>
      `;
    }

    container.addEventListener('scroll', (e) => {
      scrollTop = e.target.scrollTop;
      requestAnimationFrame(render);
    });

    render();
  }
}

// Memory management
class MemoryManager {
  constructor() {
    this.cache = new Map();
    this.maxCacheSize = 100;
  }

  set(key, value) {
    // Implement LRU cache
    if (this.cache.has(key)) {
      this.cache.delete(key);
    } else if (this.cache.size >= this.maxCacheSize) {
      const firstKey = this.cache.keys().next().value;
      this.cache.delete(firstKey);
    }

    this.cache.set(key, value);
  }

  get(key) {
    const value = this.cache.get(key);
    if (value !== undefined) {
      // Move to end (most recently used)
      this.cache.delete(key);
      this.cache.set(key, value);
    }
    return value;
  }

  clear() {
    this.cache.clear();
  }

  // Monitor memory usage
  getMemoryUsage() {
    if (performance.memory) {
      return {
        used: Math.round(performance.memory.usedJSHeapSize / 1048576),
        total: Math.round(performance.memory.totalJSHeapSize / 1048576),
        limit: Math.round(performance.memory.jsHeapSizeLimit / 1048576)
      };
    }
    return null;
  }
}
```

### Network Optimization

#### Resource Loading Strategy
```javascript
// Preload critical resources
class ResourcePreloader {
  constructor() {
    this.preloadedResources = new Set();
  }

  preloadFont(href) {
    if (this.preloadedResources.has(href)) return;

    const link = document.createElement('link');
    link.rel = 'preload';
    link.as = 'font';
    link.type = 'font/woff2';
    link.crossOrigin = 'anonymous';
    link.href = href;

    document.head.appendChild(link);
    this.preloadedResources.add(href);
  }

  preloadImage(src, priority = 'low') {
    if (this.preloadedResources.has(src)) return;

    const link = document.createElement('link');
    link.rel = 'preload';
    link.as = 'image';
    link.href = src;

    if (priority === 'high') {
      link.fetchPriority = 'high';
    }

    document.head.appendChild(link);
    this.preloadedResources.add(src);
  }

  preloadScript(src) {
    if (this.preloadedResources.has(src)) return;

    const link = document.createElement('link');
    link.rel = 'preload';
    link.as = 'script';
    link.href = src;

    document.head.appendChild(link);
    this.preloadedResources.add(src);
  }

  // Intelligent preloading based on user behavior
  async preloadOnHover(element, resources) {
    let preloadTimer;

    element.addEventListener('mouseenter', () => {
      preloadTimer = setTimeout(() => {
        resources.forEach(resource => {
          switch (resource.type) {
            case 'script':
              this.preloadScript(resource.src);
              break;
            case 'image':
              this.preloadImage(resource.src);
              break;
            case 'font':
              this.preloadFont(resource.src);
              break;
          }
        });
      }, 100); // Small delay to avoid unnecessary preloads
    });

    element.addEventListener('mouseleave', () => {
      clearTimeout(preloadTimer);
    });
  }
}

// HTTP/2 Server Push simulation
class HTTP2PushSimulator {
  constructor() {
    this.pushedResources = new Set();
  }

  pushCriticalResources() {
    const criticalResources = [
      { type: 'style', href: '/css/critical.css' },
      { type: 'script', href: '/js/critical.js' },
      { type: 'font', href: '/fonts/inter-var.woff2' }
    ];

    criticalResources.forEach(resource => {
      if (!this.pushedResources.has(resource.href)) {
        this.simulatePush(resource);
        this.pushedResources.add(resource.href);
      }
    });
  }

  simulatePush(resource) {
    const link = document.createElement('link');
    link.rel = 'preload';
    link.as = resource.type === 'style' ? 'style' :
               resource.type === 'script' ? 'script' : 'font';
    link.href = resource.href;

    if (resource.type === 'font') {
      link.crossOrigin = 'anonymous';
    }

    document.head.appendChild(link);
  }
}
```

#### Service Worker for Caching
```javascript
// Advanced service worker with performance optimizations
const CACHE_STRATEGY = {
  CACHE_FIRST: 'cache-first',
  NETWORK_FIRST: 'network-first',
  STALE_WHILE_REVALIDATE: 'stale-while-revalidate',
  NETWORK_ONLY: 'network-only',
  CACHE_ONLY: 'cache-only'
};

class PerformanceServiceWorker {
  constructor() {
    this.cacheStrategies = new Map();
    this.setupStrategies();
  }

  setupStrategies() {
    // Static assets - cache first
    this.cacheStrategies.set(/\.(css|js|woff2|png|jpg|webp|svg)$/, {
      strategy: CACHE_STRATEGY.CACHE_FIRST,
      cacheName: 'static-assets',
      maxAge: 31536000 // 1 year
    });

    // API responses - network first with cache fallback
    this.cacheStrategies.set(/\/api\//, {
      strategy: CACHE_STRATEGY.NETWORK_FIRST,
      cacheName: 'api-cache',
      maxAge: 300 // 5 minutes
    });

    // HTML pages - stale while revalidate
    this.cacheStrategies.set(/\.html$|^\/$/, {
      strategy: CACHE_STRATEGY.STALE_WHILE_REVALIDATE,
      cacheName: 'pages',
      maxAge: 86400 // 1 day
    });
  }

  async handleFetch(event) {
    const url = new URL(event.request.url);
    const strategy = this.getStrategy(url.pathname);

    switch (strategy.strategy) {
      case CACHE_STRATEGY.CACHE_FIRST:
        return this.cacheFirstStrategy(event.request, strategy);
      case CACHE_STRATEGY.NETWORK_FIRST:
        return this.networkFirstStrategy(event.request, strategy);
      case CACHE_STRATEGY.STALE_WHILE_REVALIDATE:
        return this.staleWhileRevalidateStrategy(event.request, strategy);
      default:
        return fetch(event.request);
    }
  }

  getStrategy(pathname) {
    for (const [pattern, strategy] of this.cacheStrategies) {
      if (pattern.test(pathname)) {
        return strategy;
      }
    }
    return { strategy: CACHE_STRATEGY.NETWORK_ONLY };
  }

  async cacheFirstStrategy(request, strategy) {
    const cache = await caches.open(strategy.cacheName);
    const cachedResponse = await cache.match(request);

    if (cachedResponse) {
      return cachedResponse;
    }

    const networkResponse = await fetch(request);
    if (networkResponse.status === 200) {
      await cache.put(request, networkResponse.clone());
    }

    return networkResponse;
  }

  async networkFirstStrategy(request, strategy) {
    try {
      const networkResponse = await fetch(request);

      if (networkResponse.status === 200) {
        const cache = await caches.open(strategy.cacheName);
        await cache.put(request, networkResponse.clone());
      }

      return networkResponse;
    } catch (error) {
      const cache = await caches.open(strategy.cacheName);
      const cachedResponse = await cache.match(request);

      if (cachedResponse) {
        return cachedResponse;
      }

      throw error;
    }
  }

  async staleWhileRevalidateStrategy(request, strategy) {
    const cache = await caches.open(strategy.cacheName);
    const cachedResponse = await cache.match(request);

    // Always try to fetch from network in background
    const fetchPromise = fetch(request).then(networkResponse => {
      if (networkResponse.status === 200) {
        cache.put(request, networkResponse.clone());
      }
      return networkResponse;
    });

    // Return cached response immediately if available
    if (cachedResponse) {
      return cachedResponse;
    }

    // If no cache, wait for network
    return fetchPromise;
  }
}
```

## ğŸ”§ **Backend Optimization**

### FastAPI Performance Optimization

```python
# High-performance FastAPI configuration
from fastapi import FastAPI, BackgroundTasks, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
import asyncio
import asyncpg
import redis
import json
from typing import AsyncGenerator
import gzip
import io

app = FastAPI(
    title="Pynomaly API",
    description="High-performance anomaly detection API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Performance middleware
app.add_middleware(GZipMiddleware, minimum_size=1000)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Connection pooling
class DatabaseManager:
    def __init__(self):
        self.pool = None
        self.redis_client = None

    async def init_db(self):
        self.pool = await asyncpg.create_pool(
            dsn="postgresql://user:pass@localhost/db",
            min_size=10,
            max_size=20,
            command_timeout=60
        )

        self.redis_client = redis.Redis(
            host='localhost',
            port=6379,
            db=0,
            decode_responses=True,
            max_connections=20
        )

    async def get_connection(self):
        return await self.pool.acquire()

    async def release_connection(self, conn):
        await self.pool.release(conn)

db_manager = DatabaseManager()

@app.on_event("startup")
async def startup_event():
    await db_manager.init_db()

# Performance monitoring middleware
@app.middleware("http")
async def performance_middleware(request: Request, call_next):
    start_time = time.time()

    # Add performance headers
    response = await call_next(request)

    process_time = time.time() - start_time
    response.headers["X-Process-Time"] = str(process_time)
    response.headers["X-Timestamp"] = str(int(time.time()))

    # Cache headers for static content
    if request.url.path.startswith("/static/"):
        response.headers["Cache-Control"] = "public, max-age=31536000, immutable"

    return response

# Efficient data streaming
@app.get("/api/datasets/{dataset_id}/stream")
async def stream_dataset(dataset_id: str) -> StreamingResponse:
    async def generate_data() -> AsyncGenerator[bytes, None]:
        conn = await db_manager.get_connection()
        try:
            async with conn.transaction():
                async for record in conn.cursor(
                    "SELECT data FROM dataset_chunks WHERE dataset_id = $1 ORDER BY chunk_id",
                    dataset_id
                ):
                    chunk_data = json.dumps(record['data']) + '\n'
                    yield chunk_data.encode('utf-8')
        finally:
            await db_manager.release_connection(conn)

    return StreamingResponse(
        generate_data(),
        media_type="application/x-ndjson",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive"
        }
    )

# Caching with Redis
class CacheManager:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.default_ttl = 3600  # 1 hour

    async def get(self, key: str):
        try:
            cached_data = await self.redis.get(key)
            if cached_data:
                return json.loads(cached_data)
        except Exception as e:
            print(f"Cache get error: {e}")
        return None

    async def set(self, key: str, value: dict, ttl: int = None):
        try:
            ttl = ttl or self.default_ttl
            await self.redis.setex(
                key,
                ttl,
                json.dumps(value, default=str)
            )
        except Exception as e:
            print(f"Cache set error: {e}")

    async def delete(self, key: str):
        try:
            await self.redis.delete(key)
        except Exception as e:
            print(f"Cache delete error: {e}")

cache_manager = CacheManager(db_manager.redis_client)

# Optimized detection endpoint
@app.post("/api/detect/anomalies")
async def detect_anomalies(
    request: AnomalyDetectionRequest,
    background_tasks: BackgroundTasks
) -> JSONResponse:
    # Check cache first
    cache_key = f"detection:{hash(str(request.dict()))}"
    cached_result = await cache_manager.get(cache_key)

    if cached_result:
        return JSONResponse(
            content=cached_result,
            headers={"X-Cache": "HIT"}
        )

    # Process detection
    try:
        # Use asyncio for concurrent processing
        tasks = []
        for algorithm in request.algorithms:
            task = asyncio.create_task(
                run_detection_algorithm(algorithm, request.data)
            )
            tasks.append(task)

        results = await asyncio.gather(*tasks, return_exceptions=True)

        # Aggregate results
        detection_result = {
            "anomalies": [],
            "confidence_scores": [],
            "processing_time": time.time() - start_time,
            "algorithms_used": request.algorithms
        }

        for i, result in enumerate(results):
            if isinstance(result, Exception):
                print(f"Algorithm {request.algorithms[i]} failed: {result}")
                continue

            detection_result["anomalies"].extend(result.anomalies)
            detection_result["confidence_scores"].extend(result.scores)

        # Cache result
        background_tasks.add_task(
            cache_manager.set,
            cache_key,
            detection_result,
            ttl=1800  # 30 minutes
        )

        return JSONResponse(
            content=detection_result,
            headers={"X-Cache": "MISS"}
        )

    except Exception as e:
        return JSONResponse(
            content={"error": str(e)},
            status_code=500
        )

# Background task processing
@app.post("/api/detect/batch")
async def batch_detection(
    request: BatchDetectionRequest,
    background_tasks: BackgroundTasks
) -> JSONResponse:
    # Generate job ID
    job_id = f"batch_{int(time.time())}_{hash(str(request.dict()))}"

    # Store job status
    await cache_manager.set(
        f"job:{job_id}",
        {"status": "queued", "progress": 0},
        ttl=3600
    )

    # Add to background processing
    background_tasks.add_task(
        process_batch_detection,
        job_id,
        request
    )

    return JSONResponse(content={
        "job_id": job_id,
        "status": "queued",
        "check_status_url": f"/api/jobs/{job_id}/status"
    })

async def process_batch_detection(job_id: str, request: BatchDetectionRequest):
    try:
        # Update status
        await cache_manager.set(
            f"job:{job_id}",
            {"status": "processing", "progress": 0},
            ttl=3600
        )

        total_datasets = len(request.datasets)
        processed = 0

        results = []

        for dataset in request.datasets:
            # Process individual dataset
            result = await run_detection_algorithm(
                request.algorithm,
                dataset
            )
            results.append(result)

            # Update progress
            processed += 1
            progress = (processed / total_datasets) * 100

            await cache_manager.set(
                f"job:{job_id}",
                {
                    "status": "processing",
                    "progress": progress,
                    "processed": processed,
                    "total": total_datasets
                },
                ttl=3600
            )

        # Store final results
        await cache_manager.set(
            f"job:{job_id}",
            {
                "status": "completed",
                "progress": 100,
                "results": results,
                "completed_at": time.time()
            },
            ttl=86400  # 24 hours
        )

    except Exception as e:
        await cache_manager.set(
            f"job:{job_id}",
            {
                "status": "failed",
                "error": str(e),
                "failed_at": time.time()
            },
            ttl=86400
        )

# Database optimization
async def run_detection_algorithm(algorithm: str, data: dict):
    conn = await db_manager.get_connection()
    try:
        # Use prepared statements for better performance
        stmt = await conn.prepare("""
            SELECT algorithm_function, parameters
            FROM algorithms
            WHERE name = $1 AND is_active = true
        """)

        algorithm_config = await stmt.fetchrow(algorithm)

        if not algorithm_config:
            raise ValueError(f"Algorithm {algorithm} not found")

        # Execute algorithm with optimized parameters
        result = await execute_algorithm(
            algorithm_config['algorithm_function'],
            data,
            algorithm_config['parameters']
        )

        # Store result asynchronously
        asyncio.create_task(store_detection_result(result))

        return result

    finally:
        await db_manager.release_connection(conn)
```

### Database Optimization

```python
# Database performance optimization
class DatabaseOptimizer:
    def __init__(self, pool):
        self.pool = pool

    async def optimize_queries(self):
        """Run database optimization tasks"""
        conn = await self.pool.acquire()
        try:
            # Update table statistics
            await conn.execute("ANALYZE;")

            # Vacuum tables periodically
            await conn.execute("VACUUM (ANALYZE, VERBOSE);")

            # Check for missing indexes
            missing_indexes = await self.check_missing_indexes(conn)

            return {
                "optimizations_applied": True,
                "missing_indexes": missing_indexes,
                "timestamp": time.time()
            }
        finally:
            await self.pool.release(conn)

    async def check_missing_indexes(self, conn):
        """Identify potentially missing indexes"""
        query = """
        SELECT schemaname, tablename, attname, n_distinct, correlation
        FROM pg_stats
        WHERE schemaname = 'public'
        AND n_distinct > 100
        AND abs(correlation) < 0.1
        ORDER BY n_distinct DESC;
        """

        results = await conn.fetch(query)
        return [dict(row) for row in results]

    async def get_slow_queries(self, conn):
        """Get slow queries for optimization"""
        query = """
        SELECT query, mean_time, calls, total_time
        FROM pg_stat_statements
        WHERE mean_time > 100
        ORDER BY mean_time DESC
        LIMIT 10;
        """

        results = await conn.fetch(query)
        return [dict(row) for row in results]

# Connection pooling optimization
class OptimizedConnectionPool:
    def __init__(self):
        self.pool = None
        self.connection_metrics = {
            "active_connections": 0,
            "total_requests": 0,
            "average_query_time": 0
        }

    async def init_pool(self):
        self.pool = await asyncpg.create_pool(
            dsn="postgresql://user:pass@localhost/db",
            min_size=5,
            max_size=50,
            max_queries=50000,
            max_inactive_connection_lifetime=300,
            command_timeout=30,
            server_settings={
                'application_name': 'pynomaly_api',
                'tcp_keepalives_idle': '600',
                'tcp_keepalives_interval': '30',
                'tcp_keepalives_count': '3',
            }
        )

    async def execute_with_metrics(self, query, *args):
        start_time = time.time()

        async with self.pool.acquire() as conn:
            self.connection_metrics["active_connections"] += 1
            try:
                result = await conn.fetch(query, *args)

                query_time = time.time() - start_time
                self.connection_metrics["total_requests"] += 1

                # Update average query time
                current_avg = self.connection_metrics["average_query_time"]
                total_requests = self.connection_metrics["total_requests"]

                self.connection_metrics["average_query_time"] = (
                    (current_avg * (total_requests - 1)) + query_time
                ) / total_requests

                return result

            finally:
                self.connection_metrics["active_connections"] -= 1

    def get_pool_status(self):
        return {
            "pool_size": self.pool.get_size(),
            "pool_idle": self.pool.get_idle_size(),
            "metrics": self.connection_metrics
        }
```

## ğŸ“Š **Bundle Analysis**

### Webpack Bundle Optimization

```javascript
// Advanced webpack configuration for performance
const path = require('path');
const { BundleAnalyzerPlugin } = require('webpack-bundle-analyzer');
const CompressionPlugin = require('compression-webpack-plugin');
const TerserPlugin = require('terser-webpack-plugin');

module.exports = {
  mode: 'production',
  entry: {
    main: './src/main.js',
    vendor: ['d3', 'echarts'],
    worker: './src/workers/anomaly-detection.js'
  },

  output: {
    path: path.resolve(__dirname, 'dist'),
    filename: '[name].[contenthash:8].js',
    chunkFilename: '[name].[contenthash:8].chunk.js',
    assetModuleFilename: 'assets/[name].[contenthash:8][ext]'
  },

  optimization: {
    minimize: true,
    minimizer: [
      new TerserPlugin({
        terserOptions: {
          compress: {
            drop_console: true,
            drop_debugger: true,
            pure_funcs: ['console.log']
          },
          mangle: {
            safari10: true
          },
          format: {
            comments: false
          }
        },
        extractComments: false
      })
    ],

    splitChunks: {
      chunks: 'all',
      minSize: 20000,
      maxSize: 244000,
      cacheGroups: {
        vendor: {
          test: /[\\/]node_modules[\\/]/,
          name: 'vendors',
          chunks: 'all',
          priority: 10
        },
        common: {
          name: 'common',
          minChunks: 2,
          chunks: 'all',
          priority: 5,
          reuseExistingChunk: true
        },
        charts: {
          test: /[\\/]node_modules[\\/](d3|echarts|chart\.js)[\\/]/,
          name: 'charts',
          chunks: 'all',
          priority: 15
        }
      }
    },

    runtimeChunk: {
      name: 'runtime'
    }
  },

  module: {
    rules: [
      {
        test: /\.js$/,
        exclude: /node_modules/,
        use: {
          loader: 'babel-loader',
          options: {
            presets: [
              ['@babel/preset-env', {
                targets: {
                  browsers: ['> 1%', 'last 2 versions', 'not ie <= 8']
                },
                modules: false,
                useBuiltIns: 'usage',
                corejs: 3
              }]
            ],
            plugins: [
              '@babel/plugin-syntax-dynamic-import',
              '@babel/plugin-proposal-class-properties'
            ]
          }
        }
      },
      {
        test: /\.css$/,
        use: [
          'style-loader',
          {
            loader: 'css-loader',
            options: {
              importLoaders: 1,
              modules: {
                localIdentName: '[name]__[local]___[hash:base64:5]'
              }
            }
          },
          'postcss-loader'
        ]
      },
      {
        test: /\.(png|jpg|jpeg|gif|svg|webp)$/i,
        type: 'asset',
        parser: {
          dataUrlCondition: {
            maxSize: 8 * 1024 // 8kb
          }
        },
        generator: {
          filename: 'images/[name].[contenthash:8][ext]'
        }
      },
      {
        test: /\.(woff|woff2|eot|ttf|otf)$/i,
        type: 'asset/resource',
        generator: {
          filename: 'fonts/[name].[contenthash:8][ext]'
        }
      }
    ]
  },

  plugins: [
    new CompressionPlugin({
      algorithm: 'gzip',
      test: /\.(js|css|html|svg)$/,
      threshold: 8192,
      minRatio: 0.8
    }),

    new BundleAnalyzerPlugin({
      analyzerMode: process.env.ANALYZE ? 'server' : 'disabled',
      openAnalyzer: false,
      reportFilename: 'bundle-report.html'
    })
  ],

  resolve: {
    alias: {
      '@': path.resolve(__dirname, 'src'),
      '@components': path.resolve(__dirname, 'src/components'),
      '@utils': path.resolve(__dirname, 'src/utils')
    },
    extensions: ['.js', '.jsx', '.ts', '.tsx']
  }
};
```

### Bundle Analysis Scripts

```javascript
// Bundle analysis automation
const { execSync } = require('child_process');
const fs = require('fs').promises;
const path = require('path');

class BundleAnalyzer {
  constructor(buildDir = 'dist') {
    this.buildDir = buildDir;
    this.previousReport = null;
  }

  async analyzeBundles() {
    const bundles = await this.getBundleFiles();
    const analysis = {
      timestamp: new Date().toISOString(),
      bundles: [],
      totalSize: 0,
      gzippedSize: 0,
      recommendations: []
    };

    for (const bundle of bundles) {
      const bundleInfo = await this.analyzeSingleBundle(bundle);
      analysis.bundles.push(bundleInfo);
      analysis.totalSize += bundleInfo.size;
      analysis.gzippedSize += bundleInfo.gzippedSize;
    }

    analysis.recommendations = this.generateRecommendations(analysis);

    // Save report
    await this.saveReport(analysis);

    // Compare with previous build
    if (this.previousReport) {
      analysis.comparison = this.compareReports(this.previousReport, analysis);
    }

    this.previousReport = analysis;
    return analysis;
  }

  async getBundleFiles() {
    const files = await fs.readdir(this.buildDir);
    return files.filter(file =>
      file.endsWith('.js') &&
      !file.includes('.map') &&
      !file.includes('runtime')
    );
  }

  async analyzeSingleBundle(filename) {
    const filepath = path.join(this.buildDir, filename);
    const stats = await fs.stat(filepath);
    const content = await fs.readFile(filepath, 'utf8');

    // Calculate gzipped size
    const gzipped = require('zlib').gzipSync(content);

    // Analyze content
    const analysis = {
      filename,
      size: stats.size,
      gzippedSize: gzipped.length,
      modules: this.extractModules(content),
      duplicates: this.findDuplicates(content),
      unusedExports: this.findUnusedExports(content)
    };

    return analysis;
  }

  extractModules(content) {
    // Extract webpack modules from bundle
    const moduleRegex = /\/\*\* webpack\/bootstrap \*\*\//;
    const modules = [];

    // Simple module extraction (in real implementation, use AST parsing)
    const lines = content.split('\n');
    let inModule = false;
    let currentModule = '';

    for (const line of lines) {
      if (line.includes('__webpack_require__')) {
        inModule = true;
        currentModule = line;
      } else if (inModule && line.includes('module.exports')) {
        modules.push(currentModule);
        inModule = false;
        currentModule = '';
      }
    }

    return modules;
  }

  findDuplicates(content) {
    // Find duplicate code patterns
    const duplicates = [];
    const codeBlocks = content.match(/function\s+\w+\([^)]*\)\s*{[^}]+}/g) || [];

    const blockMap = new Map();

    codeBlocks.forEach((block, index) => {
      const normalized = block.replace(/\s+/g, ' ').trim();
      if (blockMap.has(normalized)) {
        duplicates.push({
          original: blockMap.get(normalized),
          duplicate: index,
          content: block.substring(0, 100) + '...'
        });
      } else {
        blockMap.set(normalized, index);
      }
    });

    return duplicates;
  }

  findUnusedExports(content) {
    // Find potentially unused exports
    const exports = content.match(/exports\.\w+/g) || [];
    const imports = content.match(/require\([^)]+\)/g) || [];

    const unusedExports = exports.filter(exp => {
      const exportName = exp.split('.')[1];
      return !imports.some(imp => imp.includes(exportName));
    });

    return unusedExports;
  }

  generateRecommendations(analysis) {
    const recommendations = [];

    // Check bundle sizes
    analysis.bundles.forEach(bundle => {
      if (bundle.size > 500000) { // 500KB
        recommendations.push({
          type: 'size',
          severity: 'high',
          message: `Bundle ${bundle.filename} is large (${Math.round(bundle.size / 1024)}KB). Consider code splitting.`,
          bundle: bundle.filename
        });
      }

      if (bundle.duplicates.length > 0) {
        recommendations.push({
          type: 'duplication',
          severity: 'medium',
          message: `Found ${bundle.duplicates.length} duplicate code blocks in ${bundle.filename}`,
          bundle: bundle.filename
        });
      }

      if (bundle.unusedExports.length > 0) {
        recommendations.push({
          type: 'unused',
          severity: 'low',
          message: `Found ${bundle.unusedExports.length} potentially unused exports in ${bundle.filename}`,
          bundle: bundle.filename
        });
      }
    });

    // Check total size
    if (analysis.totalSize > 2000000) { // 2MB
      recommendations.push({
        type: 'total-size',
        severity: 'critical',
        message: `Total bundle size is ${Math.round(analysis.totalSize / 1024)}KB. Consider aggressive optimization.`
      });
    }

    return recommendations;
  }

  compareReports(previous, current) {
    const comparison = {
      sizeDiff: current.totalSize - previous.totalSize,
      gzippedDiff: current.gzippedSize - previous.gzippedSize,
      bundleChanges: []
    };

    current.bundles.forEach(currentBundle => {
      const previousBundle = previous.bundles.find(b => b.filename === currentBundle.filename);

      if (previousBundle) {
        const sizeDiff = currentBundle.size - previousBundle.size;
        if (Math.abs(sizeDiff) > 1024) { // 1KB threshold
          comparison.bundleChanges.push({
            filename: currentBundle.filename,
            sizeDiff,
            percentage: (sizeDiff / previousBundle.size) * 100
          });
        }
      } else {
        comparison.bundleChanges.push({
          filename: currentBundle.filename,
          status: 'new',
          size: currentBundle.size
        });
      }
    });

    return comparison;
  }

  async saveReport(analysis) {
    const reportPath = path.join(this.buildDir, 'bundle-analysis.json');
    await fs.writeFile(reportPath, JSON.stringify(analysis, null, 2));

    // Generate HTML report
    const htmlReport = this.generateHTMLReport(analysis);
    const htmlPath = path.join(this.buildDir, 'bundle-analysis.html');
    await fs.writeFile(htmlPath, htmlReport);
  }

  generateHTMLReport(analysis) {
    return `
<!DOCTYPE html>
<html>
<head>
    <title>Bundle Analysis Report</title>
    <style>
        body { font-family: system-ui, sans-serif; margin: 20px; }
        .bundle { margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }
        .size { font-weight: bold; color: #0066cc; }
        .recommendation { padding: 10px; margin: 5px 0; border-radius: 3px; }
        .high { background: #ffebee; border-left: 4px solid #f44336; }
        .medium { background: #fff3e0; border-left: 4px solid #ff9800; }
        .low { background: #e8f5e8; border-left: 4px solid #4caf50; }
        .chart { width: 100%; height: 300px; margin: 20px 0; }
    </style>
</head>
<body>
    <h1>Bundle Analysis Report</h1>
    <p>Generated: ${analysis.timestamp}</p>

    <h2>Summary</h2>
    <p>Total Size: <span class="size">${Math.round(analysis.totalSize / 1024)}KB</span></p>
    <p>Gzipped Size: <span class="size">${Math.round(analysis.gzippedSize / 1024)}KB</span></p>

    <h2>Bundles</h2>
    ${analysis.bundles.map(bundle => `
        <div class="bundle">
            <h3>${bundle.filename}</h3>
            <p>Size: ${Math.round(bundle.size / 1024)}KB (${Math.round(bundle.gzippedSize / 1024)}KB gzipped)</p>
            <p>Modules: ${bundle.modules.length}</p>
            <p>Duplicates: ${bundle.duplicates.length}</p>
        </div>
    `).join('')}

    <h2>Recommendations</h2>
    ${analysis.recommendations.map(rec => `
        <div class="recommendation ${rec.severity}">
            <strong>${rec.type.toUpperCase()}:</strong> ${rec.message}
        </div>
    `).join('')}
</body>
</html>`;
  }
}

// Usage
const analyzer = new BundleAnalyzer('dist');
analyzer.analyzeBundles().then(report => {
  console.log('Bundle analysis complete');
  console.log(`Total size: ${Math.round(report.totalSize / 1024)}KB`);
  console.log(`Recommendations: ${report.recommendations.length}`);
});
```

## ğŸ—„ï¸ **Caching Strategies**

### Multi-Level Caching Architecture

```javascript
// Comprehensive caching strategy
class CacheManager {
  constructor() {
    this.memoryCache = new Map();
    this.sessionCache = sessionStorage;
    this.persistentCache = localStorage;
    this.serviceWorkerCache = null;
    this.maxMemorySize = 50; // MB
    this.currentMemorySize = 0;
  }

  async init() {
    // Initialize service worker cache
    if ('serviceWorker' in navigator && 'caches' in window) {
      try {
        this.serviceWorkerCache = await caches.open('pynomaly-cache-v1');
      } catch (error) {
        console.warn('Service Worker cache unavailable:', error);
      }
    }

    // Set up cache cleanup
    this.setupCacheCleanup();
  }

  // Level 1: Memory Cache (fastest, smallest)
  setMemoryCache(key, data, ttl = 300000) { // 5 minutes default
    const item = {
      data,
      timestamp: Date.now(),
      ttl,
      size: this.estimateSize(data)
    };

    // Check if we need to free memory
    if (this.currentMemorySize + item.size > this.maxMemorySize * 1024 * 1024) {
      this.evictLRU();
    }

    this.memoryCache.set(key, item);
    this.currentMemorySize += item.size;
  }

  getMemoryCache(key) {
    const item = this.memoryCache.get(key);
    if (!item) return null;

    // Check TTL
    if (Date.now() - item.timestamp > item.ttl) {
      this.memoryCache.delete(key);
      this.currentMemorySize -= item.size;
      return null;
    }

    // Update access time for LRU
    item.lastAccessed = Date.now();
    return item.data;
  }

  // Level 2: Session Storage (medium speed, session lifetime)
  setSessionCache(key, data) {
    try {
      const item = {
        data,
        timestamp: Date.now()
      };
      this.sessionCache.setItem(key, JSON.stringify(item));
    } catch (error) {
      // Handle quota exceeded
      this.clearOldestSessionData();
      try {
        this.sessionCache.setItem(key, JSON.stringify(item));
      } catch (retryError) {
        console.warn('Session storage unavailable:', retryError);
      }
    }
  }

  getSessionCache(key) {
    try {
      const item = JSON.parse(this.sessionCache.getItem(key));
      return item ? item.data : null;
    } catch (error) {
      return null;
    }
  }

  // Level 3: Local Storage (persistent, larger capacity)
  setPersistentCache(key, data, ttl = 86400000) { // 24 hours default
    try {
      const item = {
        data,
        timestamp: Date.now(),
        ttl
      };
      this.persistentCache.setItem(key, JSON.stringify(item));
    } catch (error) {
      // Handle quota exceeded
      this.clearExpiredPersistentData();
      try {
        this.persistentCache.setItem(key, JSON.stringify(item));
      } catch (retryError) {
        console.warn('Local storage unavailable:', retryError);
      }
    }
  }

  getPersistentCache(key) {
    try {
      const item = JSON.parse(this.persistentCache.getItem(key));
      if (!item) return null;

      // Check TTL
      if (Date.now() - item.timestamp > item.ttl) {
        this.persistentCache.removeItem(key);
        return null;
      }

      return item.data;
    } catch (error) {
      return null;
    }
  }

  // Level 4: Service Worker Cache (network resources)
  async setNetworkCache(request, response) {
    if (!this.serviceWorkerCache) return;

    try {
      await this.serviceWorkerCache.put(request, response.clone());
    } catch (error) {
      console.warn('Network cache failed:', error);
    }
  }

  async getNetworkCache(request) {
    if (!this.serviceWorkerCache) return null;

    try {
      return await this.serviceWorkerCache.match(request);
    } catch (error) {
      console.warn('Network cache retrieval failed:', error);
      return null;
    }
  }

  // Intelligent cache selection
  async set(key, data, options = {}) {
    const {
      level = 'auto',
      ttl = 300000,
      priority = 'normal'
    } = options;

    if (level === 'auto') {
      const size = this.estimateSize(data);

      if (size < 100 * 1024 && priority === 'high') { // < 100KB, high priority
        this.setMemoryCache(key, data, ttl);
      } else if (size < 5 * 1024 * 1024) { // < 5MB
        this.setSessionCache(key, data);
      } else {
        this.setPersistentCache(key, data, ttl);
      }
    } else {
      switch (level) {
        case 'memory':
          this.setMemoryCache(key, data, ttl);
          break;
        case 'session':
          this.setSessionCache(key, data);
          break;
        case 'persistent':
          this.setPersistentCache(key, data, ttl);
          break;
      }
    }
  }

  async get(key) {
    // Try memory cache first
    let data = this.getMemoryCache(key);
    if (data) return data;

    // Try session cache
    data = this.getSessionCache(key);
    if (data) {
      // Promote to memory cache if small enough
      if (this.estimateSize(data) < 1024 * 1024) { // < 1MB
        this.setMemoryCache(key, data);
      }
      return data;
    }

    // Try persistent cache
    data = this.getPersistentCache(key);
    if (data) {
      // Promote to session cache
      this.setSessionCache(key, data);
      return data;
    }

    return null;
  }

  // Cache maintenance
  evictLRU() {
    let oldestTime = Date.now();
    let oldestKey = null;

    for (const [key, item] of this.memoryCache) {
      const accessTime = item.lastAccessed || item.timestamp;
      if (accessTime < oldestTime) {
        oldestTime = accessTime;
        oldestKey = key;
      }
    }

    if (oldestKey) {
      const item = this.memoryCache.get(oldestKey);
      this.memoryCache.delete(oldestKey);
      this.currentMemorySize -= item.size;
    }
  }

  clearOldestSessionData() {
    const items = [];
    for (let i = 0; i < this.sessionCache.length; i++) {
      const key = this.sessionCache.key(i);
      try {
        const item = JSON.parse(this.sessionCache.getItem(key));
        items.push({ key, timestamp: item.timestamp });
      } catch (error) {
        // Remove invalid items
        this.sessionCache.removeItem(key);
      }
    }

    // Sort by timestamp and remove oldest
    items.sort((a, b) => a.timestamp - b.timestamp);
    const toRemove = Math.ceil(items.length * 0.2); // Remove 20%

    for (let i = 0; i < toRemove; i++) {
      this.sessionCache.removeItem(items[i].key);
    }
  }

  clearExpiredPersistentData() {
    const now = Date.now();
    const toRemove = [];

    for (let i = 0; i < this.persistentCache.length; i++) {
      const key = this.persistentCache.key(i);
      try {
        const item = JSON.parse(this.persistentCache.getItem(key));
        if (now - item.timestamp > item.ttl) {
          toRemove.push(key);
        }
      } catch (error) {
        toRemove.push(key);
      }
    }

    toRemove.forEach(key => this.persistentCache.removeItem(key));
  }

  setupCacheCleanup() {
    // Clean up expired items every 5 minutes
    setInterval(() => {
      this.clearExpiredPersistentData();

      // Clean memory cache
      const now = Date.now();
      for (const [key, item] of this.memoryCache) {
        if (now - item.timestamp > item.ttl) {
          this.memoryCache.delete(key);
          this.currentMemorySize -= item.size;
        }
      }
    }, 300000);
  }

  estimateSize(obj) {
    return new Blob([JSON.stringify(obj)]).size;
  }

  getCacheStats() {
    return {
      memory: {
        size: this.currentMemorySize,
        items: this.memoryCache.size,
        maxSize: this.maxMemorySize * 1024 * 1024
      },
      session: {
        used: this.getStorageSize(this.sessionCache),
        items: this.sessionCache.length
      },
      persistent: {
        used: this.getStorageSize(this.persistentCache),
        items: this.persistentCache.length
      }
    };
  }

  getStorageSize(storage) {
    let total = 0;
    for (let key in storage) {
      if (storage.hasOwnProperty(key)) {
        total += storage[key].length + key.length;
      }
    }
    return total;
  }
}

// Usage example
const cacheManager = new CacheManager();
await cacheManager.init();

// Cache API responses
async function fetchWithCache(url, options = {}) {
  const cacheKey = `api:${url}:${JSON.stringify(options)}`;

  // Try cache first
  let data = await cacheManager.get(cacheKey);
  if (data) {
    return data;
  }

  // Fetch from network
  try {
    const response = await fetch(url, options);
    data = await response.json();

    // Cache based on response type
    const cacheOptions = {
      ttl: response.headers.get('cache-control')?.includes('no-cache') ? 0 : 300000,
      priority: url.includes('/critical/') ? 'high' : 'normal'
    };

    await cacheManager.set(cacheKey, data, cacheOptions);
    return data;

  } catch (error) {
    console.error('Fetch failed:', error);
    throw error;
  }
}
```

This comprehensive performance best practices guide covers all major aspects of optimization for the Pynomaly platform. The guide continues with sections on mobile performance, monitoring, tools, and troubleshooting to provide a complete reference for maintaining optimal performance across the entire system.

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[{"content": "Complete documentation maintenance - Update TODO.md current status, archive completed Phase 5.1 work, and synchronize with recent achievements", "status": "completed", "priority": "high", "id": "documentation_maintenance"}, {"content": "Implement Storybook component explorer - Interactive documentation for UI component library with accessibility and design system guidelines", "status": "completed", "priority": "medium", "id": "storybook_component_explorer"}, {"content": "Create comprehensive design system documentation - Color palettes, typography, spacing, component specifications, and usage guidelines", "status": "completed", "priority": "medium", "id": "design_system_documentation"}, {"content": "Implement comprehensive cross-browser compatibility testing - Extend Playwright configuration for Chrome, Firefox, Safari, Edge testing with responsive design validation", "status": "completed", "priority": "high", "id": "cross_browser_testing"}, {"content": "Create device compatibility framework - Mobile and tablet testing with responsive design validation and touch interaction testing", "status": "completed", "priority": "medium", "id": "device_compatibility_framework"}, {"content": "Develop performance best practices guide - Core Web Vitals optimization, bundle analysis, caching strategies, and monitoring recommendations", "status": "completed", "priority": "medium", "id": "performance_best_practices_guide"}, {"content": "Create accessibility guidelines documentation - WCAG compliance checklist, testing procedures, and implementation standards", "status": "in_progress", "priority": "medium", "id": "accessibility_guidelines_documentation"}]
