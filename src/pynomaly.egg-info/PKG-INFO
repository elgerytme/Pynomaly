Metadata-Version: 2.4
Name: pynomaly
Version: 0.1.0
Summary: State-of-the-art Python anomaly detection package with clean architecture
Home-page: https://github.com/pynomaly/pynomaly
Author: Pynomaly Team
Author-email: team@pynomaly.io
License: MIT
Project-URL: Bug Tracker, https://github.com/pynomaly/pynomaly/issues
Project-URL: Documentation, https://pynomaly.readthedocs.io
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.11
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pyod>=2.0.5
Requires-Dist: scikit-learn>=1.5.0
Requires-Dist: numpy>=1.26.0
Requires-Dist: pandas>=2.2.0
Requires-Dist: scipy>=1.11.0
Requires-Dist: pydantic>=2.5.0
Requires-Dist: pydantic-settings>=2.1.0
Requires-Dist: structlog>=24.1.0
Requires-Dist: dependency-injector>=4.41.0
Requires-Dist: fastapi>=0.109.0
Requires-Dist: typer[all]>=0.9.0
Requires-Dist: uvicorn[standard]>=0.27.0
Requires-Dist: httpx>=0.26.0
Requires-Dist: rich>=13.7.0
Requires-Dist: python-multipart>=0.0.6
Requires-Dist: jinja2>=3.1.0
Requires-Dist: aiofiles>=23.2.0
Requires-Dist: pyarrow>=14.0.0
Requires-Dist: opentelemetry-api>=1.22.0
Requires-Dist: opentelemetry-sdk>=1.22.0
Requires-Dist: opentelemetry-instrumentation-fastapi>=0.43b0
Requires-Dist: prometheus-client>=0.19.0
Requires-Dist: prometheus-fastapi-instrumentator>=5.9.1
Provides-Extra: torch
Requires-Dist: torch>=2.1.0; extra == "torch"
Provides-Extra: tensorflow
Requires-Dist: tensorflow>=2.15.0; extra == "tensorflow"
Provides-Extra: jax
Requires-Dist: jax>=0.4.23; extra == "jax"
Requires-Dist: jaxlib>=0.4.23; extra == "jax"
Provides-Extra: graph
Requires-Dist: pygod>=1.1.0; extra == "graph"
Provides-Extra: timeseries
Requires-Dist: tods>=1.0.0; extra == "timeseries"
Provides-Extra: distributed
Requires-Dist: dask>=2024.1.0; extra == "distributed"
Provides-Extra: dev
Requires-Dist: pytest>=8.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.1.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.23.0; extra == "dev"
Requires-Dist: mypy>=1.8.0; extra == "dev"
Requires-Dist: black>=23.12.0; extra == "dev"
Requires-Dist: isort>=5.13.0; extra == "dev"
Requires-Dist: flake8>=7.0.0; extra == "dev"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license
Dynamic: license-file
Dynamic: project-url
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# Pynomaly üîç

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)
[![Type checked: mypy](https://www.mypy-lang.org/static/mypy_badge.svg)](https://mypy-lang.org/)

State-of-the-art Python anomaly detection package targeting Python 3.11+ with clean architecture principles, integrating multiple ML libraries (PyOD, TODS, PyGOD, scikit-learn, PyTorch, TensorFlow, JAX) through a unified, production-ready interface.

## Features

- üèóÔ∏è **Clean Architecture**: Domain-driven design with hexagonal architecture (Ports & Adapters)
- üîå **Multi-Library Integration**: Unified interface for PyOD, TODS, PyGOD, scikit-learn, PyTorch, TensorFlow, JAX
- üöÄ **Production Ready**: Async/await, OpenTelemetry observability, Prometheus metrics, circuit breakers
- üñ•Ô∏è **Multiple Interfaces**: FastAPI REST API, Typer CLI, and Progressive Web App (PWA)
- üìä **Modern Web UI**: HTMX + Tailwind CSS + D3.js + Apache ECharts with offline PWA capabilities
- üß™ **Advanced Features**: AutoML, SHAP/LIME explainability, drift detection, active learning
- ‚ö° **Multi-Modal Support**: Time-series, tabular, graph, and text anomaly detection
- üõ°Ô∏è **Type Safe**: 100% type coverage with mypy --strict, Pydantic validation
- üîÑ **Streaming & Batch**: Real-time processing with backpressure and large dataset support
- üß∞ **Extensible**: Plugin architecture with algorithm registry and custom adapters

## Installation

### Quick Setup (Python + pip only)

If you want to run Pynomaly without Poetry, Docker, or Make:

```bash
# Run the setup script
python setup_simple.py

# Or manually:
python -m venv .venv
.venv\Scripts\activate  # Windows (or source .venv/bin/activate on Linux/Mac)
pip install -r requirements.txt
pip install -e .
```

Then run the app:
```bash
python cli.py --help
python cli.py server start
```

See [README_SIMPLE_SETUP.md](README_SIMPLE_SETUP.md) for detailed instructions.

### Full Setup (with Poetry)

```bash
# Install with Poetry
poetry install

# Or install with extras for specific ML frameworks
poetry install -E torch      # PyTorch deep learning support
poetry install -E tensorflow # TensorFlow neural networks
poetry install -E jax        # JAX high-performance computing
poetry install -E graph      # PyGOD graph anomaly detection
poetry install -E timeseries # Advanced time-series detection
poetry install -E web        # Progressive Web App dependencies
poetry install -E all        # All optional dependencies
```

## Quick Start

### CLI Usage

```bash
# List available algorithms
pynomaly detector algorithms

# Create a detector
pynomaly detector create --name "My Detector" --algorithm IsolationForest

# Load a dataset
pynomaly dataset load data.csv --name "My Data"

# Train and detect
pynomaly detect train <detector_id> <dataset_id>
pynomaly detect run <detector_id> <dataset_id>

# Start web UI
pynomaly server start
```

### Python API

```python
from pynomaly.infrastructure.config import create_container
from pynomaly.domain.entities import Detector, Dataset
from pynomaly.application.use_cases import DetectAnomalies, TrainDetector
import pandas as pd
import asyncio

async def main():
    # Initialize dependency injection container
    container = create_container()
    
    # Create detector with algorithm-specific parameters
    detector = Detector(
        name="Isolation Forest Detector",
        algorithm="IsolationForest",
        parameters={
            "contamination": 0.1,
            "n_estimators": 100,
            "random_state": 42
        }
    )
    
    # Load and prepare dataset
    data = pd.read_csv("data.csv")
    dataset = Dataset(
        name="Sensor Data",
        data=data,
        target_column="anomaly_label"  # Optional for supervised learning
    )
    
    # Use clean architecture use cases
    train_use_case = container.train_detector_use_case()
    detect_use_case = container.detect_anomalies_use_case()
    
    # Train detector
    training_result = await train_use_case.execute(detector, dataset)
    print(f"Training completed: {training_result.metrics}")
    
    # Detect anomalies
    detection_result = await detect_use_case.execute(detector.id, dataset)
    print(f"Found {len(detection_result.anomalies)} anomalies")
    
    # Get explanations (if supported by algorithm)
    explainer = container.explanation_service()
    explanations = await explainer.explain_anomalies(
        detector.id, detection_result.anomalies[:5]  # Top 5 anomalies
    )

# Run async code
asyncio.run(main())
```

### Web Interface

Access the Progressive Web App at http://localhost:8000 after starting the server:

- **Real-time Dashboard**: Live anomaly detection with WebSocket updates
- **Interactive Visualizations**: D3.js custom charts and Apache ECharts statistical plots
- **Offline Capability**: Service worker enables offline operation and data caching
- **Installable PWA**: Install on desktop and mobile devices like a native app
- **HTMX Simplicity**: Server-side rendering with minimal JavaScript complexity
- **Modern UI**: Tailwind CSS for responsive, accessible design
- **Experiment Tracking**: Compare models, track performance metrics, A/B testing
- **Dataset Analysis**: Data quality reports, drift detection, feature importance

## Business Intelligence Integrations üìä

Export anomaly detection results to major business intelligence and spreadsheet platforms:

### Supported Platforms

- **Excel**: Advanced formatting, charts, multiple worksheets
- **Power BI**: Real-time streaming, automated reports, Azure AD integration
- **Google Sheets**: Collaborative editing, real-time updates, sharing
- **Smartsheet**: Project tracking, workflow automation, team collaboration

### Installation

```bash
# Install all BI integrations
pip install pynomaly[bi-integrations]

# Or install specific platforms
pip install pynomaly[excel]      # Excel support
pip install pynomaly[powerbi]    # Power BI support  
pip install pynomaly[gsheets]    # Google Sheets support
pip install pynomaly[smartsheet] # Smartsheet support
```

### CLI Usage

```bash
# List available export formats
pynomaly export list-formats

# Export to Excel with charts and formatting
pynomaly export excel results.json report.xlsx --include-charts

# Export to Power BI workspace
pynomaly export powerbi results.json \
    --workspace-id "your-workspace-id" \
    --dataset-name "Anomaly Detection"

# Export to Google Sheets with sharing
pynomaly export gsheets results.json \
    --credentials-file creds.json \
    --share-emails user@company.com

# Export to multiple formats
pynomaly export multi results.json \
    --formats excel powerbi gsheets
```

### Python API

```python
from pynomaly.application.services.export_service import ExportService
from pynomaly.application.dto.export_options import ExportOptions

# Initialize export service
export_service = ExportService()

# Export to Excel with advanced features
excel_options = ExportOptions().for_excel()
excel_options.include_charts = True
excel_options.highlight_anomalies = True

result = export_service.export_results(
    detection_results,
    "anomaly_report.xlsx",
    excel_options
)

# Export to Power BI streaming dataset  
powerbi_options = ExportOptions().for_powerbi(
    workspace_id="workspace-123",
    dataset_name="Live Anomaly Feed"
)
powerbi_options.streaming_dataset = True

result = export_service.export_results(
    detection_results,
    "",  # No file path for cloud services
    powerbi_options
)

# Multi-platform export
results = export_service.export_multiple_formats(
    detection_results,
    base_path="anomaly_analysis",
    formats=[ExportFormat.EXCEL, ExportFormat.GSHEETS]
)
```

### Features

- **Real-time Collaboration**: Google Sheets and Smartsheet live updates
- **Advanced Visualizations**: Charts, conditional formatting, dashboards
- **Secure Authentication**: Azure AD, OAuth2, API tokens
- **Batch Processing**: Efficient handling of large datasets
- **Error Recovery**: Robust retry logic and validation
- **Template Support**: Pre-configured layouts and workflows

See [examples/bi_integrations_example.py](examples/bi_integrations_example.py) for detailed usage examples.

## Architecture

Pynomaly follows **Clean Architecture**, **Domain-Driven Design (DDD)**, and **Hexagonal Architecture (Ports & Adapters)**:

```
src/pynomaly/
‚îú‚îÄ‚îÄ domain/          # Pure business logic (no external dependencies)
‚îÇ   ‚îú‚îÄ‚îÄ entities/    # Anomaly, Detector, Dataset, Score, DetectionResult
‚îÇ   ‚îú‚îÄ‚îÄ value_objects/ # ContaminationRate, ConfidenceInterval, AnomalyScore
‚îÇ   ‚îú‚îÄ‚îÄ services/    # Core detection logic, scoring algorithms
‚îÇ   ‚îî‚îÄ‚îÄ exceptions/  # Domain-specific exception hierarchy
‚îú‚îÄ‚îÄ application/     # Orchestrate use cases without implementation details
‚îÇ   ‚îú‚îÄ‚îÄ use_cases/   # DetectAnomalies, TrainDetector, EvaluateModel, ExplainAnomaly
‚îÇ   ‚îú‚îÄ‚îÄ services/    # DetectionService, EnsembleService, ModelPersistenceService
‚îÇ   ‚îî‚îÄ‚îÄ dto/         # Data transfer objects and request/response models
‚îú‚îÄ‚îÄ infrastructure/  # All external integrations and adapters
‚îÇ   ‚îú‚îÄ‚îÄ adapters/    # PyODAdapter, TODSAdapter, PyGODAdapter, SklearnAdapter
‚îÇ   ‚îú‚îÄ‚îÄ persistence/ # ModelRepository, ResultRepository, data sources
‚îÇ   ‚îú‚îÄ‚îÄ config/      # Dependency injection container, settings
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/  # OpenTelemetry, Prometheus metrics, observability
‚îî‚îÄ‚îÄ presentation/    # User interfaces and external APIs
    ‚îú‚îÄ‚îÄ api/         # FastAPI REST endpoints with async support
    ‚îú‚îÄ‚îÄ cli/         # Typer CLI with rich formatting
    ‚îî‚îÄ‚îÄ web/         # Progressive Web App
        ‚îú‚îÄ‚îÄ static/  # CSS, JS, PWA assets (Tailwind, D3.js, ECharts)
        ‚îú‚îÄ‚îÄ templates/ # HTMX server-rendered templates
        ‚îî‚îÄ‚îÄ assets/  # PWA manifest, service worker, icons
```

### Design Patterns

- **Repository Pattern**: Clean data access abstraction
- **Factory Pattern**: Algorithm instantiation and configuration
- **Strategy Pattern**: Pluggable detection algorithms
- **Observer Pattern**: Real-time detection notifications
- **Decorator Pattern**: Feature engineering pipeline
- **Chain of Responsibility**: Data preprocessing and validation

## Supported Algorithm Libraries

### PyOD (Python Outlier Detection)
- **Statistical**: Isolation Forest, Local Outlier Factor, One-Class SVM, MCD, PCA
- **Probabilistic**: GMM, COPOD, ECOD, Histogram-based, Sampling
- **Linear**: PCA, Kernel PCA, Robust Covariance, Feature Bagging
- **Proximity**: k-NN, Radius-based, Connectivity-based (COF), CBLOF
- **Neural Networks**: AutoEncoder, VAE, Deep SVDD, SO-GAAL, MO-GAAL

### TODS (Time-series Outlier Detection System)
- **Univariate**: Statistical tests, decomposition-based, prediction-based
- **Multivariate**: Matrix profile, tensor decomposition, deep learning
- **Streaming**: Online algorithms, change point detection, concept drift

### PyGOD (Python Graph Outlier Detection)
- **Node-level**: Anomalous node detection in graphs
- **Edge-level**: Anomalous edge and subgraph detection  
- **Graph-level**: Anomalous graph classification
- **Deep Learning**: Graph neural networks, graph autoencoders

### Scikit-learn Integration
- **Ensemble**: Isolation Forest, One-Class SVM
- **Neighbors**: Local Outlier Factor, Novelty detection
- **Clustering**: DBSCAN outliers, Gaussian Mixture
- **Covariance**: Elliptic Envelope, Robust Covariance

### Deep Learning Frameworks
- **PyTorch**: Custom neural architectures, GPU acceleration
- **TensorFlow**: Distributed training, TensorBoard integration
- **JAX**: High-performance computing, automatic differentiation

### Multi-Modal Detection
- **Tabular Data**: Traditional ML and statistical methods
- **Time Series**: Seasonal decomposition, LSTM, Transformers  
- **Graph Data**: GNN-based detection, network analysis
- **Text Data**: NLP-based anomaly detection, embedding methods

Run `pynomaly detector algorithms` to see all available algorithms with their parameters and performance characteristics.

## Development

### Environment Setup
```bash
# Install development dependencies
poetry install --with dev,test

# Activate virtual environment
poetry shell

# Install pre-commit hooks (optional)
pre-commit install
```

### Code Quality
```bash
# Run full test suite with coverage
poetry run pytest --cov=pynomaly --cov-report=html

# Type checking with strict mode
poetry run mypy --strict src/

# Code formatting
poetry run black src/ tests/
poetry run isort src/ tests/

# Linting
poetry run flake8 src/ tests/
poetry run bandit -r src/  # Security linting
```

### Testing
```bash
# Unit tests only
poetry run pytest tests/unit/

# Integration tests
poetry run pytest tests/integration/

# Property-based testing
poetry run pytest tests/property/

# Performance benchmarks
poetry run pytest benchmarks/
```

### Development Commands
```bash
# Start development server with auto-reload
poetry run uvicorn pynomaly.presentation.api:app --reload

# Build frontend assets
npm run build-css  # Tailwind CSS compilation
npm run watch-css  # Development with file watching

# Run CLI in development
poetry run python -m pynomaly.presentation.cli
```

## Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
