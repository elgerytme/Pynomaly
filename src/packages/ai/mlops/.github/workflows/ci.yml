name: MLOps CI/CD

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'src/packages/ai/mlops/**'
      - '.github/workflows/**'
      - '.github/actions/**'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'src/packages/ai/mlops/**'
      - '.github/workflows/**'
      - '.github/actions/**'
  workflow_dispatch:
    inputs:
      run_performance_tests:
        description: 'Run performance benchmarks'
        required: false
        default: true
        type: boolean
      run_integration_tests:
        description: 'Run integration tests with external services'
        required: false
        default: true
        type: boolean
      python_version:
        description: 'Python version to use'
        required: false
        default: '3.11'
        type: string

env:
  PACKAGE_NAME: anomaly_detection-mlops
  PACKAGE_PATH: src/packages/ai/mlops

jobs:
  # Use the reusable workflow for comprehensive CI/CD
  ci-cd:
    uses: ./.github/workflows/_reusable-python-ci.yml
    with:
      package-name: anomaly_detection-mlops
      package-path: src/packages/ai/mlops
      python-version: ${{ github.event.inputs.python_version || '3.11' }}
      python-versions: '["3.9", "3.10", "3.11"]'
      os-matrix: '["ubuntu-latest", "macos-latest"]'
      coverage-threshold: 80
      run-performance-tests: ${{ github.event.inputs.run_performance_tests == 'true' || github.event_name == 'schedule' }}
      run-security-scan: true
      publish-to-pypi: ${{ github.event_name == 'release' }}
      run-integration-tests: ${{ github.event.inputs.run_integration_tests != 'false' }}
    secrets:
      PYPI_API_TOKEN: ${{ secrets.PYPI_API_TOKEN }}
      CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
      SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

  # MLOps-specific tests and validations
  mlops-specific-tests:
    name: MLOps Specific Tests
    runs-on: ubuntu-latest
    timeout-minutes: 60
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: mlops_test
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_pass
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      minio:
        image: minio/minio:latest
        ports:
          - 9000:9000
          - 9001:9001
        env:
          MINIO_ROOT_USER: minioadmin
          MINIO_ROOT_PASSWORD: minioadmin
        options: >-
          --health-cmd "curl -f http://localhost:9000/minio/health/live"
          --health-interval 30s
          --health-timeout 20s
          --health-retries 3
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python for package
        uses: ./.github/actions/setup-python-package
        with:
          python-version: '3.11'
          package-path: ${{ env.PACKAGE_PATH }}
          dependency-groups: 'dev,test,monitoring,cloud'

      - name: Wait for services
        run: |
          timeout 60 bash -c 'until nc -z localhost 5432; do sleep 1; done'
          timeout 60 bash -c 'until nc -z localhost 6379; do sleep 1; done'
          timeout 60 bash -c 'until nc -z localhost 9000; do sleep 1; done'

      - name: Test model lifecycle management
        working-directory: ${{ env.PACKAGE_PATH }}
        env:
          DATABASE_URL: postgresql://test_user:test_pass@localhost:5432/mlops_test
          REDIS_URL: redis://localhost:6379/0
          MINIO_ENDPOINT: localhost:9000
          MINIO_ACCESS_KEY: minioadmin
          MINIO_SECRET_KEY: minioadmin
        run: |
          pytest tests/ -k "test_model_lifecycle" \
            --verbose \
            --tb=short \
            --durations=10

      - name: Test experiment tracking
        working-directory: ${{ env.PACKAGE_PATH }}
        env:
          DATABASE_URL: postgresql://test_user:test_pass@localhost:5432/mlops_test
          REDIS_URL: redis://localhost:6379/0
        run: |
          pytest tests/ -k "test_experiment" \
            --verbose \
            --tb=short

      - name: Test model deployment pipelines
        working-directory: ${{ env.PACKAGE_PATH }}
        env:
          DATABASE_URL: postgresql://test_user:test_pass@localhost:5432/mlops_test
          REDIS_URL: redis://localhost:6379/0
        run: |
          pytest tests/ -k "test_deployment" \
            --verbose \
            --tb=short

      - name: Test monitoring and alerting
        working-directory: ${{ env.PACKAGE_PATH }}
        env:
          DATABASE_URL: postgresql://test_user:test_pass@localhost:5432/mlops_test
          REDIS_URL: redis://localhost:6379/0
        run: |
          pytest tests/ -k "test_monitoring" \
            --verbose \
            --tb=short

      - name: Test data drift detection
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          pytest tests/ -k "test_data_drift" \
            --verbose \
            --tb=short

      - name: Test AutoML pipeline integration
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          pytest tests/ -k "test_automl" \
            --verbose \
            --tb=short

  # Cloud provider integration tests
  cloud-integration-tests:
    name: Cloud Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: github.event.inputs.run_integration_tests != 'false'
    strategy:
      matrix:
        cloud_provider: [aws, azure, gcp]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python for package
        uses: ./.github/actions/setup-python-package
        with:
          python-version: '3.11'
          package-path: ${{ env.PACKAGE_PATH }}
          dependency-groups: 'cloud,test'

      - name: Test ${{ matrix.cloud_provider }} integration
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          # Run mock tests for cloud providers (no real cloud resources)
          pytest tests/ -k "test_${{ matrix.cloud_provider }}" \
            --verbose \
            --tb=short \
            -m "not requires_credentials"

      - name: Validate ${{ matrix.cloud_provider }} configuration
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          python -c "
          import sys
          sys.path.insert(0, 'src')
          
          # Test cloud provider configuration
          try:
              from anomaly_detection_mlops.infrastructure.cloud import ${{ matrix.cloud_provider }}_adapter
              print(f'✅ ${{ matrix.cloud_provider }} adapter loaded successfully')
          except ImportError as e:
              print(f'⚠️ ${{ matrix.cloud_provider }} adapter not available: {e}')
          except Exception as e:
              print(f'❌ Error loading ${{ matrix.cloud_provider }} adapter: {e}')
              sys.exit(1)
          "

  # API and service tests
  api-service-tests:
    name: API & Service Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python for package
        uses: ./.github/actions/setup-python-package
        with:
          python-version: '3.11'
          package-path: ${{ env.PACKAGE_PATH }}
          dependency-groups: 'dev,test'

      - name: Test FastAPI application
        working-directory: ${{ env.PACKAGE_PATH }}
        env:
          REDIS_URL: redis://localhost:6379/0
        run: |
          pytest tests/ -k "test_api" \
            --verbose \
            --tb=short

      - name: Test API endpoints
        working-directory: ${{ env.PACKAGE_PATH }}
        env:
          REDIS_URL: redis://localhost:6379/0
        run: |
          # Start the API server in background
          python -m uvicorn anomaly_detection_mlops.api.main:app --host 0.0.0.0 --port 8000 &
          API_PID=$!
          
          # Wait for API to start
          sleep 10
          
          # Test API endpoints
          pytest tests/ -k "test_endpoint" \
            --verbose \
            --tb=short || FAILED=true
          
          # Cleanup
          kill $API_PID 2>/dev/null || true
          
          if [ "$FAILED" = "true" ]; then
            exit 1
          fi

      - name: Test CLI commands
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          # Test CLI functionality
          python -m anomaly_detection_mlops.cli --help
          python -m anomaly_detection_mlops.cli version
          python -c "
          import subprocess
          import sys
          
          # Test basic CLI commands
          commands = [
              ['python', '-m', 'anomaly_detection_mlops.cli', '--help'],
              ['python', '-m', 'anomaly_detection_mlops.cli', 'version'],
          ]
          
          for cmd in commands:
              try:
                  result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
                  if result.returncode == 0:
                      print(f'✅ Command succeeded: {\" \".join(cmd)}')
                  else:
                      print(f'❌ Command failed: {\" \".join(cmd)}')
                      print(f'Error: {result.stderr}')
              except Exception as e:
                  print(f'❌ Exception running {\" \".join(cmd)}: {e}')
          "

  # Performance and load tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: github.event.inputs.run_performance_tests == 'true' || github.event_name == 'schedule'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python for package
        uses: ./.github/actions/setup-python-package
        with:
          python-version: '3.11'
          package-path: ${{ env.PACKAGE_PATH }}
          dependency-groups: 'test,monitoring'

      - name: Run performance benchmarks
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          pytest tests/ -k "benchmark or performance" \
            --benchmark-only \
            --benchmark-json=mlops-performance.json \
            --benchmark-sort=mean \
            --benchmark-min-rounds=5

      - name: Run load tests
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          # Install locust for load testing
          pip install locust
          
          # Run load tests if locustfile exists
          if [ -f tests/load_test.py ]; then
            locust -f tests/load_test.py --headless \
              --users 10 --spawn-rate 2 --run-time 60s \
              --host http://localhost:8000 \
              --html load-test-report.html
          else
            echo "No load test file found, skipping load tests"
          fi

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        with:
          name: mlops-performance-results
          path: |
            ${{ env.PACKAGE_PATH }}/mlops-performance.json
            ${{ env.PACKAGE_PATH }}/load-test-report.html

  # Container and deployment tests
  container-tests:
    name: Container Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          # Create a simple Dockerfile if it doesn't exist
          if [ ! -f Dockerfile ]; then
            cat > Dockerfile << EOF
          FROM python:3.11-slim
          
          WORKDIR /app
          
          COPY pyproject.toml .
          COPY src/ ./src/
          
          RUN pip install -e .
          
          EXPOSE 8000
          
          CMD ["python", "-m", "uvicorn", "anomaly_detection_mlops.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
          EOF
          fi
          
          docker build -t ${{ env.PACKAGE_NAME }}:test .

      - name: Test Docker container
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          # Run container in background
          docker run -d --name mlops-test -p 8000:8000 ${{ env.PACKAGE_NAME }}:test
          
          # Wait for container to start
          sleep 15
          
          # Test container health
          docker ps | grep mlops-test || {
            echo "❌ Container failed to start"
            docker logs mlops-test
            exit 1
          }
          
          # Test API endpoint
          curl -f http://localhost:8000/health || {
            echo "❌ Health endpoint failed"
            docker logs mlops-test
            exit 1
          }
          
          echo "✅ Container tests passed"
          
          # Cleanup
          docker stop mlops-test
          docker rm mlops-test

  # Security scan specific to MLOps
  mlops-security-scan:
    name: MLOps Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python for package
        uses: ./.github/actions/setup-python-package
        with:
          python-version: '3.11'
          package-path: ${{ env.PACKAGE_PATH }}
          dependency-groups: 'dev,test'

      - name: Run comprehensive security scan
        uses: ./.github/actions/security-scan
        with:
          package-path: ${{ env.PACKAGE_PATH }}
          package-name: ${{ env.PACKAGE_NAME }}
          fail-on-high: true
          fail-on-medium: false
          upload-sarif: true

      - name: Additional MLOps security checks
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          # Check for hardcoded secrets
          echo "🔍 Scanning for hardcoded secrets..."
          
          # Install truffleHog for secret detection
          pip install truffleHog3
          
          # Scan for secrets
          trufflehog3 . --format json --output secrets-scan.json || true
          
          # Check for sensitive patterns
          python -c "
          import os
          import re
          
          sensitive_patterns = [
              r'password\s*=\s*['\"\'][^'\"\']+['\"\']',
              r'api[_-]?key\s*=\s*['\"\'][^'\"\']+['\"\']',
              r'secret\s*=\s*['\"\'][^'\"\']+['\"\']',
              r'token\s*=\s*['\"\'][^'\"\']+['\"\']'
          ]
          
          issues = []
          for root, dirs, files in os.walk('.'):
              # Skip hidden directories and __pycache__
              dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']
              
              for file in files:
                  if file.endswith('.py'):
                      filepath = os.path.join(root, file)
                      try:
                          with open(filepath, 'r', encoding='utf-8') as f:
                              content = f.read()
                              
                          for pattern in sensitive_patterns:
                              matches = re.finditer(pattern, content, re.IGNORECASE)
                              for match in matches:
                                  issues.append(f'{filepath}: {match.group()}')
                      except:
                          pass
          
          if issues:
              print('⚠️ Potential sensitive data found:')
              for issue in issues[:10]:  # Show first 10
                  print(f'  - {issue}')
          else:
              print('✅ No obvious sensitive data patterns found')
          "

  # Documentation and examples validation
  documentation-validation:
    name: Documentation Validation
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python for package
        uses: ./.github/actions/setup-python-package
        with:
          python-version: '3.11'
          package-path: ${{ env.PACKAGE_PATH }}
          dependency-groups: 'docs,test'

      - name: Build documentation
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          # Install documentation tools
          pip install mkdocs mkdocs-material mkdocstrings[python]
          
          # Build documentation if mkdocs.yml exists
          if [ -f mkdocs.yml ]; then
            mkdocs build --strict
            echo "✅ Documentation built successfully"
          else
            echo "📝 No mkdocs.yml found, skipping documentation build"
          fi

      - name: Validate API documentation
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          # Generate OpenAPI schema
          python -c "
          import sys
          sys.path.insert(0, 'src')
          
          try:
              from anomaly_detection_mlops.api.main import app
              import json
              
              # Get OpenAPI schema
              schema = app.openapi()
              
              # Save schema
              with open('openapi-schema.json', 'w') as f:
                  json.dump(schema, f, indent=2)
              
              print('✅ OpenAPI schema generated successfully')
              print(f'📊 Found {len(schema.get(\"paths\", {}))} API endpoints')
              
              # Validate required fields
              required_fields = ['info', 'paths', 'components']
              for field in required_fields:
                  if field not in schema:
                      raise ValueError(f'Missing required OpenAPI field: {field}')
              
              print('✅ OpenAPI schema validation passed')
              
          except Exception as e:
              print(f'❌ Error generating OpenAPI schema: {e}')
              sys.exit(1)
          "

      - name: Upload documentation artifacts
        uses: actions/upload-artifact@v4
        with:
          name: mlops-documentation
          path: |
            ${{ env.PACKAGE_PATH }}/site/
            ${{ env.PACKAGE_PATH }}/openapi-schema.json

  # Deployment readiness check
  deployment-readiness:
    name: Deployment Readiness
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [ci-cd, mlops-specific-tests, api-service-tests, container-tests]
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python for package
        uses: ./.github/actions/setup-python-package
        with:
          python-version: '3.11'
          package-path: ${{ env.PACKAGE_PATH }}
          dependency-groups: 'all'

      - name: Validate MLOps configuration
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          python -c "
          import tomllib
          import sys
          sys.path.insert(0, 'src')
          
          # Validate package configuration
          with open('pyproject.toml', 'rb') as f:
              config = tomllib.load(f)
          
          project = config['project']
          print(f'📦 Package: {project[\"name\"]} v{project[\"version\"]}')
          print(f'📝 Description: {project[\"description\"]}')
          
          # Check MLOps-specific dependencies
          deps = project.get('dependencies', [])
          mlops_deps = [
              'fastapi', 'uvicorn', 'sqlalchemy', 'alembic', 
              'mlflow', 'prefect', 'redis', 'celery'
          ]
          
          missing_deps = []
          for dep in mlops_deps:
              if not any(d.startswith(dep) for d in deps):
                  missing_deps.append(dep)
          
          if missing_deps:
              print(f'⚠️ Missing recommended MLOps dependencies: {missing_deps}')
          else:
              print('✅ All recommended MLOps dependencies present')
          
          # Validate entry points
          scripts = project.get('scripts', {})
          if 'anomaly_detection-mlops' in scripts:
              print('✅ CLI entry point configured')
          else:
              print('⚠️ CLI entry point not found')
          
          print('✅ MLOps configuration validation passed')
          "

      - name: Test production readiness
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          # Test that all critical components can be imported
          python -c "
          import sys
          sys.path.insert(0, 'src')
          
          critical_modules = [
              'anomaly_detection_mlops.api.main',
              'anomaly_detection_mlops.core.model_manager',
              'anomaly_detection_mlops.core.experiment_tracker',
              'anomaly_detection_mlops.infrastructure.database',
              'anomaly_detection_mlops.infrastructure.storage'
          ]
          
          for module in critical_modules:
              try:
                  __import__(module)
                  print(f'✅ {module} imports successfully')
              except ImportError as e:
                  print(f'⚠️ {module} import failed: {e}')
              except Exception as e:
                  print(f'❌ {module} import error: {e}')
          "

      - name: Generate deployment summary
        run: |
          echo "## 🚀 MLOps Deployment Readiness Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "✅ **Package**: ${{ env.PACKAGE_NAME }}" >> $GITHUB_STEP_SUMMARY
          echo "✅ **CI/CD Pipeline**: All checks passed" >> $GITHUB_STEP_SUMMARY
          echo "✅ **MLOps Components**: Validated" >> $GITHUB_STEP_SUMMARY
          echo "✅ **API Services**: Tested" >> $GITHUB_STEP_SUMMARY
          echo "✅ **Container**: Built and tested" >> $GITHUB_STEP_SUMMARY
          echo "✅ **Security Scan**: Completed" >> $GITHUB_STEP_SUMMARY
          echo "✅ **Documentation**: Generated" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "📋 **Ready for MLOps deployment!**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🔧 Deployment Checklist" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Configure production database" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Set up Redis cluster" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Configure object storage" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Set up monitoring and alerting" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Configure CI/CD secrets" >> $GITHUB_STEP_SUMMARY