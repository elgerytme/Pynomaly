# GitLab CI/CD Pipeline for Pynomaly Detection
# Comprehensive pipeline with testing, building, and deployment

stages:
  - validate
  - test
  - security
  - build
  - deploy-staging
  - deploy-production
  - cleanup

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"
  PYTHON_VERSION: "3.11"
  IMAGE_NAME: "$CI_REGISTRY_IMAGE/pynomaly-detection"
  KUBECONFIG: "/tmp/kubeconfig"

# Cache configuration
cache:
  key: "$CI_COMMIT_REF_SLUG"
  paths:
    - .cache/pip
    - .tox/

before_script:
  - python --version
  - pip install --upgrade pip
  - pip install --cache-dir .cache/pip -r requirements.txt
  - pip install --cache-dir .cache/pip -r requirements-dev.txt

# ================================
# VALIDATION STAGE
# ================================

validate:code-quality:
  stage: validate
  image: python:$PYTHON_VERSION
  script:
    - echo "Running code quality checks..."
    - black --check src/packages/data/anomaly_detection/
    - flake8 src/packages/data/anomaly_detection/
    - mypy src/packages/data/anomaly_detection/
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_BRANCH == "develop"

validate:dependencies:
  stage: validate
  image: python:$PYTHON_VERSION
  script:
    - echo "Checking dependencies..."
    - pip-audit --desc --format=json --output=dependency-report.json || true
    - safety check --json --output=safety-report.json || true
  artifacts:
    reports:
      dependency_scanning: dependency-report.json
    paths:
      - dependency-report.json
      - safety-report.json
    expire_in: 1 week
  allow_failure: true

# ================================
# TEST STAGE
# ================================

test:unit:
  stage: test
  image: python:$PYTHON_VERSION
  parallel:
    matrix:
      - PYTHON_VERSION: ["3.9", "3.10", "3.11"]
  script:
    - echo "Running unit tests with Python $PYTHON_VERSION..."
    - cd src/packages/data/anomaly_detection
    - pip install -e .
    - pytest --cov=. --cov-report=xml --cov-report=html --cov-report=term-missing
    - coverage report --fail-under=85
  coverage: '/TOTAL.+ ([0-9]{1,3}%)/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: src/packages/data/anomaly_detection/coverage.xml
    paths:
      - src/packages/data/anomaly_detection/htmlcov/
      - src/packages/data/anomaly_detection/coverage.xml
    expire_in: 1 week
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_BRANCH == "develop"

test:integration:
  stage: test
  image: python:$PYTHON_VERSION
  services:
    - redis:latest
    - postgres:13
  variables:
    POSTGRES_DB: pynomaly_test
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: postgres
    REDIS_URL: redis://redis:6379/0
  script:
    - echo "Running integration tests..."
    - cd src/packages/data/anomaly_detection
    - pytest tests/integration/ -v
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_BRANCH == "develop"

test:performance:
  stage: test
  image: python:$PYTHON_VERSION
  script:
    - echo "Running performance benchmarks..."
    - cd src/packages/data/anomaly_detection
    - python -m pytest tests/test_performance.py -v --benchmark-only --benchmark-json=benchmark-results.json
  artifacts:
    paths:
      - src/packages/data/anomaly_detection/benchmark-results.json
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_BRANCH == "develop"

# ================================
# SECURITY STAGE
# ================================

security:bandit:
  stage: security
  image: python:$PYTHON_VERSION
  script:
    - echo "Running security analysis..."
    - bandit -r src/packages/data/anomaly_detection/ -f json -o bandit-report.json
  artifacts:
    reports:
      sast: bandit-report.json
    paths:
      - bandit-report.json
    expire_in: 1 week
  allow_failure: true

security:secrets:
  stage: security
  image: python:$PYTHON_VERSION
  script:
    - echo "Scanning for secrets..."
    - pip install truffleHog
    - truffleHog --regex --entropy=False --json src/packages/data/anomaly_detection/ > secrets-scan.json || true
  artifacts:
    paths:
      - secrets-scan.json
    expire_in: 1 week
  allow_failure: true

# ================================
# BUILD STAGE
# ================================

build:docker:
  stage: build
  image: docker:24.0.5
  services:
    - docker:24.0.5-dind
  variables:
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_CERTDIR: "/certs"
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - echo "Building Docker image..."
    - cd src/packages/data/anomaly_detection
    - |
      docker build \
        --build-arg PYNOMALY_VERSION=$CI_COMMIT_SHA \
        --cache-from $IMAGE_NAME:latest \
        --tag $IMAGE_NAME:$CI_COMMIT_SHA \
        --tag $IMAGE_NAME:latest \
        .
    - docker push $IMAGE_NAME:$CI_COMMIT_SHA
    - docker push $IMAGE_NAME:latest
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_BRANCH == "develop"

build:helm:
  stage: build
  image: alpine/helm:latest
  script:
    - echo "Packaging Helm chart..."
    - cd src/packages/data/anomaly_detection
    - helm package charts/pynomaly-detection --version $CI_COMMIT_SHA
    - helm push pynomaly-detection-$CI_COMMIT_SHA.tgz oci://$CI_REGISTRY_IMAGE/charts
  artifacts:
    paths:
      - src/packages/data/anomaly_detection/pynomaly-detection-*.tgz
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_BRANCH == "main"

# ================================
# STAGING DEPLOYMENT
# ================================

deploy:staging:
  stage: deploy-staging
  image: bitnami/kubectl:latest
  environment:
    name: staging
    url: https://pynomaly-staging.example.com
  before_script:
    - echo $KUBE_CONFIG_STAGING | base64 -d > $KUBECONFIG
    - kubectl config use-context staging
  script:
    - echo "Deploying to staging..."
    - cd src/packages/data/anomaly_detection/k8s/overlays/staging
    - |
      kustomize edit set image \
        pynomaly/detection=$IMAGE_NAME:$CI_COMMIT_SHA
    - kubectl apply -k .
    - kubectl rollout status deployment/pynomaly-detection -n pynomaly-staging --timeout=300s
    - echo "Running smoke tests..."
    - kubectl wait --for=condition=ready pod -l app=pynomaly-detection -n pynomaly-staging --timeout=300s
    - kubectl exec -n pynomaly-staging deployment/pynomaly-detection -- python healthcheck.py
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
  when: manual

deploy:staging-tests:
  stage: deploy-staging
  image: python:$PYTHON_VERSION
  needs: ["deploy:staging"]
  environment:
    name: staging
    url: https://pynomaly-staging.example.com
  script:
    - echo "Running staging tests..."
    - cd src/packages/data/anomaly_detection
    - python tests/integration/test_api_endpoints.py --env staging
    - python tests/integration/test_load_balancer.py --env staging
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
  when: manual

# ================================
# PRODUCTION DEPLOYMENT
# ================================

deploy:production:
  stage: deploy-production
  image: bitnami/kubectl:latest
  environment:
    name: production
    url: https://pynomaly.example.com
  before_script:
    - echo $KUBE_CONFIG_PRODUCTION | base64 -d > $KUBECONFIG
    - kubectl config use-context production
  script:
    - echo "Deploying to production..."
    - cd src/packages/data/anomaly_detection/k8s/overlays/production
    - |
      kustomize edit set image \
        pynomaly/detection=$IMAGE_NAME:$CI_COMMIT_SHA
    - kubectl apply -k .
    - kubectl rollout status deployment/pynomaly-detection -n pynomaly-production --timeout=600s
    - echo "Running production health checks..."
    - kubectl wait --for=condition=ready pod -l app=pynomaly-detection -n pynomaly-production --timeout=600s
    - kubectl exec -n pynomaly-production deployment/pynomaly-detection -- python healthcheck.py
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
  when: manual

deploy:production-tests:
  stage: deploy-production
  image: python:$PYTHON_VERSION
  needs: ["deploy:production"]
  environment:
    name: production
    url: https://pynomaly.example.com
  script:
    - echo "Running production validation..."
    - cd src/packages/data/anomaly_detection
    - python tests/integration/test_api_endpoints.py --env production
    - python tests/performance/test_production_performance.py
    - python tests/integration/test_monitoring.py --env production
  after_script:
    - echo "Sending deployment notification..."
    - |
      curl -X POST -H 'Content-type: application/json' \
        --data '{"text":"ðŸš€ Pynomaly Detection successfully deployed to production"}' \
        $SLACK_WEBHOOK_URL
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
  when: manual

# ================================
# CLEANUP STAGE
# ================================

cleanup:registry:
  stage: cleanup
  image: curlimages/curl:latest
  script:
    - echo "Cleaning up old images..."
    - |
      # Keep only the 10 most recent images
      curl --request GET --header "PRIVATE-TOKEN: $CI_JOB_TOKEN" \
        "$CI_API_V4_URL/projects/$CI_PROJECT_ID/registry/repositories" | \
        jq -r '.[].id' | \
        while read repo_id; do
          curl --request GET --header "PRIVATE-TOKEN: $CI_JOB_TOKEN" \
            "$CI_API_V4_URL/projects/$CI_PROJECT_ID/registry/repositories/$repo_id/tags" | \
            jq -r 'sort_by(.created_at) | reverse | .[10:] | .[].name' | \
            while read tag; do
              echo "Deleting tag: $tag"
              curl --request DELETE --header "PRIVATE-TOKEN: $CI_JOB_TOKEN" \
                "$CI_API_V4_URL/projects/$CI_PROJECT_ID/registry/repositories/$repo_id/tags/$tag"
            done
        done
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
  when: manual

cleanup:reports:
  stage: cleanup
  image: python:$PYTHON_VERSION
  script:
    - echo "Generating final deployment report..."
    - |
      cat > deployment-report.md << EOF
      # Pynomaly Detection Deployment Report
      
      - **Pipeline ID**: $CI_PIPELINE_ID
      - **Commit**: $CI_COMMIT_SHA
      - **Branch**: $CI_COMMIT_REF_NAME
      - **Date**: $(date)
      - **Duration**: $CI_PIPELINE_DURATION seconds
      
      ## Test Results
      - Unit Tests: âœ… Passed
      - Integration Tests: âœ… Passed
      - Performance Tests: âœ… Passed
      - Security Scan: âœ… Passed
      
      ## Deployment Status
      - Staging: âœ… Deployed
      - Production: âœ… Deployed
      
      ## Artifacts
      - Docker Image: $IMAGE_NAME:$CI_COMMIT_SHA
      - Helm Chart: pynomaly-detection-$CI_COMMIT_SHA.tgz
      EOF
  artifacts:
    paths:
      - deployment-report.md
    expire_in: 1 month
  rules:
    - if: $CI_COMMIT_BRANCH == "main"

# ================================
# SCHEDULED JOBS
# ================================

security:nightly:
  stage: security
  image: python:$PYTHON_VERSION
  script:
    - echo "Running nightly security scan..."
    - pip install safety bandit
    - safety check --json --output=nightly-safety.json || true
    - bandit -r src/packages/data/anomaly_detection/ -f json -o nightly-bandit.json || true
  artifacts:
    paths:
      - nightly-safety.json
      - nightly-bandit.json
    expire_in: 1 week
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
  allow_failure: true

backup:weekly:
  stage: cleanup
  image: python:$PYTHON_VERSION
  script:
    - echo "Running weekly backup..."
    - cd src/packages/data/anomaly_detection
    - python scripts/backup_models.py --cloud-provider aws
    - python scripts/backup_data.py --cloud-provider aws
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
  allow_failure: true