{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ Ensemble Methods Deep Dive\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-org/anomaly-detection/blob/main/docs/notebooks/06_ensemble_methods_deep_dive.ipynb)\n",
    "\n",
    "**Difficulty**: Advanced | **Time**: 55 minutes\n",
    "\n",
    "Master advanced ensemble techniques for anomaly detection. Learn how to combine multiple detectors using voting, stacking, and hierarchical methods to achieve superior detection performance.\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "- Understand ensemble learning principles for anomaly detection\n",
    "- Implement voting, averaging, and stacking ensembles\n",
    "- Build hierarchical and dynamic ensemble architectures\n",
    "- Optimize ensemble performance and interpretability\n",
    "- Deploy ensemble models in production systems\n",
    "\n",
    "## üì¶ Prerequisites\n",
    "\n",
    "- Complete [Algorithm Comparison Tutorial](02_algorithm_comparison_tutorial.ipynb)\n",
    "- Understanding of multiple anomaly detection algorithms\n",
    "- Basic knowledge of machine learning ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Interactive widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, classification_report\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üî¨ Ready for ensemble methods deep dive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Building Individual Anomaly Detectors\n",
    "\n",
    "First, let's create a comprehensive suite of individual detectors that we'll combine into ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndividualDetector:\n",
    "    \"\"\"Base class for individual anomaly detectors.\"\"\"\n",
    "    \n",
    "    def __init__(self, name, detector, scaler=None):\n",
    "        self.name = name\n",
    "        self.detector = detector\n",
    "        self.scaler = scaler or StandardScaler()\n",
    "        self.is_fitted = False\n",
    "        self.training_time = 0\n",
    "        self.prediction_time = 0\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit the detector to training data.\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Scale the data\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Fit the detector\n",
    "        self.detector.fit(X_scaled)\n",
    "        \n",
    "        self.training_time = time.time() - start_time\n",
    "        self.is_fitted = True\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict anomalies.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(f\"Detector {self.name} is not fitted yet.\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Scale the data\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = self.detector.predict(X_scaled)\n",
    "        \n",
    "        self.prediction_time = time.time() - start_time\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Get anomaly scores.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(f\"Detector {self.name} is not fitted yet.\")\n",
    "        \n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # Get decision scores\n",
    "        if hasattr(self.detector, 'decision_function'):\n",
    "            return self.detector.decision_function(X_scaled)\n",
    "        elif hasattr(self.detector, 'score_samples'):\n",
    "            return self.detector.score_samples(X_scaled)\n",
    "        else:\n",
    "            # Fallback to predictions converted to scores\n",
    "            preds = self.detector.predict(X_scaled)\n",
    "            return preds.astype(float)\n",
    "\n",
    "\n",
    "class DetectorSuite:\n",
    "    \"\"\"Collection of diverse anomaly detectors.\"\"\"\n",
    "    \n",
    "    def __init__(self, contamination=0.1):\n",
    "        self.contamination = contamination\n",
    "        self.detectors = self._create_detector_suite()\n",
    "    \n",
    "    def _create_detector_suite(self):\n",
    "        \"\"\"Create a diverse suite of anomaly detectors.\"\"\"\n",
    "        detectors = []\n",
    "        \n",
    "        # 1. Isolation Forest variants\n",
    "        detectors.append(IndividualDetector(\n",
    "            \"IsolationForest_Default\",\n",
    "            IsolationForest(\n",
    "                contamination=self.contamination,\n",
    "                random_state=42,\n",
    "                n_estimators=100\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        detectors.append(IndividualDetector(\n",
    "            \"IsolationForest_HighTrees\",\n",
    "            IsolationForest(\n",
    "                contamination=self.contamination,\n",
    "                random_state=43,\n",
    "                n_estimators=200,\n",
    "                max_samples=0.8\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        detectors.append(IndividualDetector(\n",
    "            \"IsolationForest_LowSample\",\n",
    "            IsolationForest(\n",
    "                contamination=self.contamination,\n",
    "                random_state=44,\n",
    "                n_estimators=50,\n",
    "                max_samples=0.5\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        # 2. Local Outlier Factor variants\n",
    "        detectors.append(IndividualDetector(\n",
    "            \"LOF_Small_Neighborhood\",\n",
    "            LocalOutlierFactor(\n",
    "                contamination=self.contamination,\n",
    "                n_neighbors=5,\n",
    "                novelty=True\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        detectors.append(IndividualDetector(\n",
    "            \"LOF_Large_Neighborhood\",\n",
    "            LocalOutlierFactor(\n",
    "                contamination=self.contamination,\n",
    "                n_neighbors=20,\n",
    "                novelty=True\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        # 3. One-Class SVM variants\n",
    "        detectors.append(IndividualDetector(\n",
    "            \"OneClassSVM_RBF\",\n",
    "            OneClassSVM(\n",
    "                kernel='rbf',\n",
    "                gamma='scale',\n",
    "                nu=self.contamination\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        detectors.append(IndividualDetector(\n",
    "            \"OneClassSVM_Linear\",\n",
    "            OneClassSVM(\n",
    "                kernel='linear',\n",
    "                nu=self.contamination\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        detectors.append(IndividualDetector(\n",
    "            \"OneClassSVM_Poly\",\n",
    "            OneClassSVM(\n",
    "                kernel='poly',\n",
    "                degree=3,\n",
    "                nu=self.contamination\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        return detectors\n",
    "    \n",
    "    def fit_all(self, X, y=None, verbose=True):\n",
    "        \"\"\"Fit all detectors in the suite.\"\"\"\n",
    "        if verbose:\n",
    "            print(f\"üîß Fitting {len(self.detectors)} detectors...\")\n",
    "        \n",
    "        for i, detector in enumerate(self.detectors):\n",
    "            if verbose:\n",
    "                print(f\"   [{i+1}/{len(self.detectors)}] Fitting {detector.name}...\")\n",
    "            \n",
    "            try:\n",
    "                detector.fit(X, y)\n",
    "                if verbose:\n",
    "                    print(f\"      ‚úÖ Completed in {detector.training_time:.3f}s\")\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"      ‚ùå Failed: {e}\")\n",
    "        \n",
    "        fitted_count = sum(1 for d in self.detectors if d.is_fitted)\n",
    "        if verbose:\n",
    "            print(f\"\\n‚úÖ Successfully fitted {fitted_count}/{len(self.detectors)} detectors\")\n",
    "    \n",
    "    def predict_all(self, X, return_scores=False):\n",
    "        \"\"\"Get predictions from all fitted detectors.\"\"\"\n",
    "        predictions = {}\n",
    "        scores = {}\n",
    "        \n",
    "        for detector in self.detectors:\n",
    "            if detector.is_fitted:\n",
    "                try:\n",
    "                    predictions[detector.name] = detector.predict(X)\n",
    "                    if return_scores:\n",
    "                        scores[detector.name] = detector.decision_function(X)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Prediction failed for {detector.name}: {e}\")\n",
    "        \n",
    "        if return_scores:\n",
    "            return predictions, scores\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate_individual_performance(self, X, y_true):\n",
    "        \"\"\"Evaluate performance of individual detectors.\"\"\"\n",
    "        predictions = self.predict_all(X)\n",
    "        results = {}\n",
    "        \n",
    "        for name, y_pred in predictions.items():\n",
    "            # Convert predictions to binary (1 for normal, -1 for anomaly)\n",
    "            y_pred_binary = (y_pred == -1).astype(int)\n",
    "            y_true_binary = (y_true == -1).astype(int)\n",
    "            \n",
    "            results[name] = {\n",
    "                'precision': precision_score(y_true_binary, y_pred_binary, zero_division=0),\n",
    "                'recall': recall_score(y_true_binary, y_pred_binary, zero_division=0),\n",
    "                'f1_score': f1_score(y_true_binary, y_pred_binary, zero_division=0),\n",
    "                'accuracy': np.mean(y_pred_binary == y_true_binary)\n",
    "            }\n",
    "        \n",
    "        return results\n",
    "\n",
    "print(\"‚úÖ Individual detector classes created!\")\n",
    "print(\"üîß Ready to build detector suites!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Ensemble Methods Implementation\n",
    "\n",
    "Now let's implement various ensemble techniques to combine our individual detectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingEnsemble:\n",
    "    \"\"\"Voting-based ensemble for anomaly detection.\"\"\"\n",
    "    \n",
    "    def __init__(self, detectors, voting_strategy='majority', weights=None):\n",
    "        self.detectors = detectors\n",
    "        self.voting_strategy = voting_strategy\n",
    "        self.weights = weights\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit all base detectors.\"\"\"\n",
    "        for detector in self.detectors:\n",
    "            if not detector.is_fitted:\n",
    "                detector.fit(X, y)\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make ensemble predictions using voting.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Ensemble must be fitted before prediction.\")\n",
    "        \n",
    "        # Get predictions from all detectors\n",
    "        all_predictions = []\n",
    "        for detector in self.detectors:\n",
    "            if detector.is_fitted:\n",
    "                predictions = detector.predict(X)\n",
    "                all_predictions.append(predictions)\n",
    "        \n",
    "        if not all_predictions:\n",
    "            raise ValueError(\"No fitted detectors available for prediction.\")\n",
    "        \n",
    "        # Convert to numpy array for easier manipulation\n",
    "        predictions_array = np.array(all_predictions)  # Shape: (n_detectors, n_samples)\n",
    "        \n",
    "        if self.voting_strategy == 'majority':\n",
    "            # Majority voting: predict anomaly if majority says anomaly\n",
    "            anomaly_votes = np.sum(predictions_array == -1, axis=0)\n",
    "            ensemble_predictions = np.where(\n",
    "                anomaly_votes > len(all_predictions) / 2, -1, 1\n",
    "            )\n",
    "        \n",
    "        elif self.voting_strategy == 'unanimous':\n",
    "            # Unanimous voting: predict anomaly only if all agree\n",
    "            ensemble_predictions = np.where(\n",
    "                np.all(predictions_array == -1, axis=0), -1, 1\n",
    "            )\n",
    "        \n",
    "        elif self.voting_strategy == 'any':\n",
    "            # Any voting: predict anomaly if any detector says anomaly\n",
    "            ensemble_predictions = np.where(\n",
    "                np.any(predictions_array == -1, axis=0), -1, 1\n",
    "            )\n",
    "        \n",
    "        elif self.voting_strategy == 'weighted':\n",
    "            # Weighted voting using provided weights\n",
    "            if self.weights is None:\n",
    "                raise ValueError(\"Weights must be provided for weighted voting.\")\n",
    "            \n",
    "            weighted_votes = np.zeros(X.shape[0])\n",
    "            total_weight = 0\n",
    "            \n",
    "            for i, (predictions, weight) in enumerate(zip(all_predictions, self.weights)):\n",
    "                weighted_votes += (predictions == -1).astype(float) * weight\n",
    "                total_weight += weight\n",
    "            \n",
    "            ensemble_predictions = np.where(\n",
    "                weighted_votes > total_weight / 2, -1, 1\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown voting strategy: {self.voting_strategy}\")\n",
    "        \n",
    "        return ensemble_predictions\n",
    "    \n",
    "    def get_voting_details(self, X):\n",
    "        \"\"\"Get detailed voting information for each sample.\"\"\"\n",
    "        all_predictions = []\n",
    "        detector_names = []\n",
    "        \n",
    "        for detector in self.detectors:\n",
    "            if detector.is_fitted:\n",
    "                predictions = detector.predict(X)\n",
    "                all_predictions.append(predictions)\n",
    "                detector_names.append(detector.name)\n",
    "        \n",
    "        predictions_df = pd.DataFrame(\n",
    "            np.array(all_predictions).T,\n",
    "            columns=detector_names\n",
    "        )\n",
    "        \n",
    "        # Add voting statistics\n",
    "        predictions_df['anomaly_votes'] = (predictions_df == -1).sum(axis=1)\n",
    "        predictions_df['normal_votes'] = (predictions_df == 1).sum(axis=1)\n",
    "        predictions_df['ensemble_prediction'] = self.predict(X)\n",
    "        \n",
    "        return predictions_df\n",
    "\n",
    "\n",
    "class AveragingEnsemble:\n",
    "    \"\"\"Score averaging ensemble for anomaly detection.\"\"\"\n",
    "    \n",
    "    def __init__(self, detectors, averaging_strategy='mean', weights=None):\n",
    "        self.detectors = detectors\n",
    "        self.averaging_strategy = averaging_strategy\n",
    "        self.weights = weights\n",
    "        self.threshold = None\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def fit(self, X, y=None, contamination=0.1):\n",
    "        \"\"\"Fit all base detectors and determine threshold.\"\"\"\n",
    "        # Fit base detectors\n",
    "        for detector in self.detectors:\n",
    "            if not detector.is_fitted:\n",
    "                detector.fit(X, y)\n",
    "        \n",
    "        # Determine threshold based on training data\n",
    "        training_scores = self.decision_function(X)\n",
    "        self.threshold = np.percentile(training_scores, (1 - contamination) * 100)\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Get ensemble anomaly scores.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            # Allow decision function during fitting\n",
    "            fitted_detectors = [d for d in self.detectors if d.is_fitted]\n",
    "            if not fitted_detectors:\n",
    "                raise ValueError(\"No fitted detectors available.\")\n",
    "        else:\n",
    "            fitted_detectors = [d for d in self.detectors if d.is_fitted]\n",
    "        \n",
    "        # Get scores from all fitted detectors\n",
    "        all_scores = []\n",
    "        for detector in fitted_detectors:\n",
    "            try:\n",
    "                scores = detector.decision_function(X)\n",
    "                all_scores.append(scores)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Skipping {detector.name}: {e}\")\n",
    "        \n",
    "        if not all_scores:\n",
    "            raise ValueError(\"No valid scores obtained from detectors.\")\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        scores_array = np.array(all_scores)  # Shape: (n_detectors, n_samples)\n",
    "        \n",
    "        # Apply averaging strategy\n",
    "        if self.averaging_strategy == 'mean':\n",
    "            ensemble_scores = np.mean(scores_array, axis=0)\n",
    "        \n",
    "        elif self.averaging_strategy == 'median':\n",
    "            ensemble_scores = np.median(scores_array, axis=0)\n",
    "        \n",
    "        elif self.averaging_strategy == 'weighted':\n",
    "            if self.weights is None:\n",
    "                raise ValueError(\"Weights must be provided for weighted averaging.\")\n",
    "            \n",
    "            weighted_scores = np.zeros(X.shape[0])\n",
    "            total_weight = 0\n",
    "            \n",
    "            for scores, weight in zip(all_scores, self.weights):\n",
    "                weighted_scores += scores * weight\n",
    "                total_weight += weight\n",
    "            \n",
    "            ensemble_scores = weighted_scores / total_weight\n",
    "        \n",
    "        elif self.averaging_strategy == 'max':\n",
    "            # Take maximum (most anomalous) score\n",
    "            ensemble_scores = np.max(scores_array, axis=0)\n",
    "        \n",
    "        elif self.averaging_strategy == 'min':\n",
    "            # Take minimum (least anomalous) score\n",
    "            ensemble_scores = np.min(scores_array, axis=0)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown averaging strategy: {self.averaging_strategy}\")\n",
    "        \n",
    "        return ensemble_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions based on averaged scores.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Ensemble must be fitted before prediction.\")\n",
    "        \n",
    "        scores = self.decision_function(X)\n",
    "        predictions = np.where(scores > self.threshold, -1, 1)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "class StackingEnsemble:\n",
    "    \"\"\"Stacking ensemble using a meta-learner.\"\"\"\n",
    "    \n",
    "    def __init__(self, detectors, meta_learner=None):\n",
    "        self.detectors = detectors\n",
    "        self.meta_learner = meta_learner or LogisticRegression(random_state=42)\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit base detectors and meta-learner.\"\"\"\n",
    "        # Fit base detectors\n",
    "        for detector in self.detectors:\n",
    "            if not detector.is_fitted:\n",
    "                detector.fit(X)\n",
    "        \n",
    "        # Generate meta-features using base detector predictions\n",
    "        meta_features = self._generate_meta_features(X)\n",
    "        \n",
    "        # Convert labels to binary format for meta-learner\n",
    "        y_binary = (y == -1).astype(int)\n",
    "        \n",
    "        # Fit meta-learner\n",
    "        self.meta_learner.fit(meta_features, y_binary)\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def _generate_meta_features(self, X):\n",
    "        \"\"\"Generate meta-features from base detector outputs.\"\"\"\n",
    "        meta_features = []\n",
    "        \n",
    "        for detector in self.detectors:\n",
    "            if detector.is_fitted:\n",
    "                # Get both predictions and scores as features\n",
    "                predictions = detector.predict(X)\n",
    "                scores = detector.decision_function(X)\n",
    "                \n",
    "                meta_features.append(predictions)\n",
    "                meta_features.append(scores)\n",
    "        \n",
    "        return np.column_stack(meta_features)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make ensemble predictions using meta-learner.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Ensemble must be fitted before prediction.\")\n",
    "        \n",
    "        meta_features = self._generate_meta_features(X)\n",
    "        meta_predictions = self.meta_learner.predict(meta_features)\n",
    "        \n",
    "        # Convert back to anomaly detection format\n",
    "        return np.where(meta_predictions == 1, -1, 1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Get prediction probabilities from meta-learner.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Ensemble must be fitted before prediction.\")\n",
    "        \n",
    "        meta_features = self._generate_meta_features(X)\n",
    "        return self.meta_learner.predict_proba(meta_features)\n",
    "\n",
    "print(\"‚úÖ Ensemble method classes created!\")\n",
    "print(\"üéØ Ready to build powerful ensemble detectors!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Interactive Ensemble Comparison\n",
    "\n",
    "Let's create an interactive tool to compare different ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleComparator:\n",
    "    \"\"\"Interactive tool for comparing ensemble methods.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.labels = None\n",
    "        self.detector_suite = None\n",
    "        self.ensembles = {}\n",
    "        self.results = {}\n",
    "        self.create_widgets()\n",
    "    \n",
    "    def create_widgets(self):\n",
    "        \"\"\"Create interactive widgets.\"\"\"\n",
    "        # Data generation widgets\n",
    "        self.n_samples_slider = widgets.IntSlider(\n",
    "            value=1000, min=500, max=5000, step=500,\n",
    "            description='Samples:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.n_features_slider = widgets.IntSlider(\n",
    "            value=5, min=2, max=15, step=1,\n",
    "            description='Features:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.contamination_slider = widgets.FloatSlider(\n",
    "            value=0.1, min=0.05, max=0.3, step=0.05,\n",
    "            description='Contamination:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Ensemble selection widgets\n",
    "        self.ensemble_methods = widgets.SelectMultiple(\n",
    "            options=[\n",
    "                'Majority Voting',\n",
    "                'Unanimous Voting',\n",
    "                'Any Voting',\n",
    "                'Mean Averaging',\n",
    "                'Median Averaging',\n",
    "                'Max Averaging',\n",
    "                'Stacking'\n",
    "            ],\n",
    "            value=['Majority Voting', 'Mean Averaging', 'Stacking'],\n",
    "            description='Ensemble Methods:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout={'height': '150px'}\n",
    "        )\n",
    "        \n",
    "        # Control buttons\n",
    "        self.generate_button = widgets.Button(\n",
    "            description='Generate Data',\n",
    "            button_style='primary',\n",
    "            icon='database'\n",
    "        )\n",
    "        \n",
    "        self.compare_button = widgets.Button(\n",
    "            description='Compare Ensembles',\n",
    "            button_style='success',\n",
    "            icon='chart-bar',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        # Output widgets\n",
    "        self.status_output = widgets.Output()\n",
    "        self.results_output = widgets.Output()\n",
    "        self.plot_output = widgets.Output()\n",
    "        \n",
    "        # Event handlers\n",
    "        self.generate_button.on_click(self.generate_data)\n",
    "        self.compare_button.on_click(self.compare_ensembles)\n",
    "    \n",
    "    def display_interface(self):\n",
    "        \"\"\"Display the complete interface.\"\"\"\n",
    "        # Configuration panel\n",
    "        config_panel = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>üîß Configuration</h3>\"),\n",
    "            widgets.HBox([self.n_samples_slider, self.n_features_slider]),\n",
    "            self.contamination_slider,\n",
    "            self.ensemble_methods,\n",
    "            widgets.HBox([self.generate_button, self.compare_button])\n",
    "        ])\n",
    "        \n",
    "        # Results panel\n",
    "        results_panel = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>üìä Results</h3>\"),\n",
    "            self.results_output\n",
    "        ])\n",
    "        \n",
    "        # Main interface\n",
    "        interface = widgets.VBox([\n",
    "            widgets.HTML(\"<h2>üî¨ Ensemble Methods Comparison</h2>\"),\n",
    "            widgets.HBox([config_panel, results_panel]),\n",
    "            self.plot_output,\n",
    "            self.status_output\n",
    "        ])\n",
    "        \n",
    "        display(interface)\n",
    "    \n",
    "    def generate_data(self, button):\n",
    "        \"\"\"Generate synthetic dataset for comparison.\"\"\"\n",
    "        with self.status_output:\n",
    "            clear_output(wait=True)\n",
    "            print(\"üîÑ Generating synthetic dataset...\")\n",
    "        \n",
    "        try:\n",
    "            n_samples = self.n_samples_slider.value\n",
    "            n_features = self.n_features_slider.value\n",
    "            contamination = self.contamination_slider.value\n",
    "            \n",
    "            # Generate normal data\n",
    "            np.random.seed(42)\n",
    "            normal_data = np.random.multivariate_normal(\n",
    "                mean=np.zeros(n_features),\n",
    "                cov=np.eye(n_features),\n",
    "                size=int(n_samples * (1 - contamination))\n",
    "            )\n",
    "            \n",
    "            # Generate anomalous data\n",
    "            n_anomalies = int(n_samples * contamination)\n",
    "            anomaly_data = np.random.uniform(\n",
    "                low=-4, high=4,\n",
    "                size=(n_anomalies, n_features)\n",
    "            )\n",
    "            \n",
    "            # Combine data\n",
    "            self.data = np.vstack([normal_data, anomaly_data])\n",
    "            self.labels = np.hstack([\n",
    "                np.ones(len(normal_data)),\n",
    "                -np.ones(len(anomaly_data))\n",
    "            ])\n",
    "            \n",
    "            # Shuffle\n",
    "            indices = np.random.permutation(len(self.data))\n",
    "            self.data = self.data[indices]\n",
    "            self.labels = self.labels[indices]\n",
    "            \n",
    "            # Create detector suite\n",
    "            self.detector_suite = DetectorSuite(contamination=contamination)\n",
    "            \n",
    "            with self.status_output:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"‚úÖ Generated dataset: {n_samples} samples, {n_features} features\")\n",
    "                print(f\"üìä Contamination: {contamination:.1%} ({n_anomalies} anomalies)\")\n",
    "            \n",
    "            # Enable comparison button\n",
    "            self.compare_button.disabled = False\n",
    "        \n",
    "        except Exception as e:\n",
    "            with self.status_output:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"‚ùå Error generating data: {e}\")\n",
    "    \n",
    "    def compare_ensembles(self, button):\n",
    "        \"\"\"Compare selected ensemble methods.\"\"\"\n",
    "        if self.data is None:\n",
    "            with self.status_output:\n",
    "                clear_output(wait=True)\n",
    "                print(\"‚ö†Ô∏è Please generate data first!\")\n",
    "            return\n",
    "        \n",
    "        with self.status_output:\n",
    "            clear_output(wait=True)\n",
    "            print(\"üîÑ Training detectors and building ensembles...\")\n",
    "        \n",
    "        try:\n",
    "            # Fit individual detectors\n",
    "            self.detector_suite.fit_all(self.data, verbose=False)\n",
    "            \n",
    "            # Split data for stacking (need labels for meta-learner)\n",
    "            split_idx = int(0.7 * len(self.data))\n",
    "            train_X, test_X = self.data[:split_idx], self.data[split_idx:]\n",
    "            train_y, test_y = self.labels[:split_idx], self.labels[split_idx:]\n",
    "            \n",
    "            # Build selected ensembles\n",
    "            self.ensembles = {}\n",
    "            selected_methods = self.ensemble_methods.value\n",
    "            \n",
    "            if 'Majority Voting' in selected_methods:\n",
    "                self.ensembles['Majority Voting'] = VotingEnsemble(\n",
    "                    self.detector_suite.detectors, 'majority'\n",
    "                )\n",
    "            \n",
    "            if 'Unanimous Voting' in selected_methods:\n",
    "                self.ensembles['Unanimous Voting'] = VotingEnsemble(\n",
    "                    self.detector_suite.detectors, 'unanimous'\n",
    "                )\n",
    "            \n",
    "            if 'Any Voting' in selected_methods:\n",
    "                self.ensembles['Any Voting'] = VotingEnsemble(\n",
    "                    self.detector_suite.detectors, 'any'\n",
    "                )\n",
    "            \n",
    "            if 'Mean Averaging' in selected_methods:\n",
    "                self.ensembles['Mean Averaging'] = AveragingEnsemble(\n",
    "                    self.detector_suite.detectors, 'mean'\n",
    "                )\n",
    "            \n",
    "            if 'Median Averaging' in selected_methods:\n",
    "                self.ensembles['Median Averaging'] = AveragingEnsemble(\n",
    "                    self.detector_suite.detectors, 'median'\n",
    "                )\n",
    "            \n",
    "            if 'Max Averaging' in selected_methods:\n",
    "                self.ensembles['Max Averaging'] = AveragingEnsemble(\n",
    "                    self.detector_suite.detectors, 'max'\n",
    "                )\n",
    "            \n",
    "            if 'Stacking' in selected_methods:\n",
    "                self.ensembles['Stacking'] = StackingEnsemble(\n",
    "                    self.detector_suite.detectors\n",
    "                )\n",
    "            \n",
    "            # Fit and evaluate ensembles\n",
    "            self.results = {}\n",
    "            \n",
    "            for name, ensemble in self.ensembles.items():\n",
    "                with self.status_output:\n",
    "                    print(f\"   üîß Training {name}...\")\n",
    "                \n",
    "                start_time = time.time()\n",
    "                \n",
    "                if name == 'Stacking':\n",
    "                    # Stacking needs labels for training\n",
    "                    ensemble.fit(train_X, train_y)\n",
    "                    predictions = ensemble.predict(test_X)\n",
    "                    eval_labels = test_y\n",
    "                else:\n",
    "                    # Other ensembles don't need labels\n",
    "                    ensemble.fit(self.data)\n",
    "                    predictions = ensemble.predict(self.data)\n",
    "                    eval_labels = self.labels\n",
    "                \n",
    "                training_time = time.time() - start_time\n",
    "                \n",
    "                # Evaluate performance\n",
    "                y_pred_binary = (predictions == -1).astype(int)\n",
    "                y_true_binary = (eval_labels == -1).astype(int)\n",
    "                \n",
    "                self.results[name] = {\n",
    "                    'precision': precision_score(y_true_binary, y_pred_binary, zero_division=0),\n",
    "                    'recall': recall_score(y_true_binary, y_pred_binary, zero_division=0),\n",
    "                    'f1_score': f1_score(y_true_binary, y_pred_binary, zero_division=0),\n",
    "                    'accuracy': np.mean(y_pred_binary == y_true_binary),\n",
    "                    'training_time': training_time,\n",
    "                    'predictions': predictions\n",
    "                }\n",
    "            \n",
    "            # Display results\n",
    "            self.display_results()\n",
    "            self.create_comparison_plots()\n",
    "            \n",
    "            with self.status_output:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"‚úÖ Comparison completed for {len(self.ensembles)} ensemble methods!\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            with self.status_output:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"‚ùå Error during comparison: {e}\")\n",
    "    \n",
    "    def display_results(self):\n",
    "        \"\"\"Display comparison results in a table.\"\"\"\n",
    "        with self.results_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if not self.results:\n",
    "                print(\"No results to display.\")\n",
    "                return\n",
    "            \n",
    "            # Create results DataFrame\n",
    "            results_df = pd.DataFrame(self.results).T\n",
    "            results_df = results_df[['precision', 'recall', 'f1_score', 'accuracy', 'training_time']]\n",
    "            \n",
    "            # Format the results\n",
    "            html_table = \"<div style='max-height: 300px; overflow-y: auto;'>\"\n",
    "            html_table += \"<table style='width: 100%; border-collapse: collapse;'>\"\n",
    "            html_table += \"<tr style='background-color: #f0f0f0;'>\"\n",
    "            html_table += \"<th style='padding: 8px; border: 1px solid #ddd;'>Method</th>\"\n",
    "            html_table += \"<th style='padding: 8px; border: 1px solid #ddd;'>Precision</th>\"\n",
    "            html_table += \"<th style='padding: 8px; border: 1px solid #ddd;'>Recall</th>\"\n",
    "            html_table += \"<th style='padding: 8px; border: 1px solid #ddd;'>F1-Score</th>\"\n",
    "            html_table += \"<th style='padding: 8px; border: 1px solid #ddd;'>Accuracy</th>\"\n",
    "            html_table += \"<th style='padding: 8px; border: 1px solid #ddd;'>Time (s)</th>\"\n",
    "            html_table += \"</tr>\"\n",
    "            \n",
    "            # Find best performer for each metric\n",
    "            best_precision = results_df['precision'].idxmax()\n",
    "            best_recall = results_df['recall'].idxmax()\n",
    "            best_f1 = results_df['f1_score'].idxmax()\n",
    "            best_accuracy = results_df['accuracy'].idxmax()\n",
    "            fastest = results_df['training_time'].idxmin()\n",
    "            \n",
    "            for method, row in results_df.iterrows():\n",
    "                html_table += \"<tr>\"\n",
    "                html_table += f\"<td style='padding: 8px; border: 1px solid #ddd; font-weight: bold;'>{method}</td>\"\n",
    "                \n",
    "                # Highlight best values\n",
    "                precision_style = \"background-color: #90EE90;\" if method == best_precision else \"\"\n",
    "                recall_style = \"background-color: #90EE90;\" if method == best_recall else \"\"\n",
    "                f1_style = \"background-color: #90EE90;\" if method == best_f1 else \"\"\n",
    "                accuracy_style = \"background-color: #90EE90;\" if method == best_accuracy else \"\"\n",
    "                time_style = \"background-color: #87CEEB;\" if method == fastest else \"\"\n",
    "                \n",
    "                html_table += f\"<td style='padding: 8px; border: 1px solid #ddd; {precision_style}'>{row['precision']:.3f}</td>\"\n",
    "                html_table += f\"<td style='padding: 8px; border: 1px solid #ddd; {recall_style}'>{row['recall']:.3f}</td>\"\n",
    "                html_table += f\"<td style='padding: 8px; border: 1px solid #ddd; {f1_style}'>{row['f1_score']:.3f}</td>\"\n",
    "                html_table += f\"<td style='padding: 8px; border: 1px solid #ddd; {accuracy_style}'>{row['accuracy']:.3f}</td>\"\n",
    "                html_table += f\"<td style='padding: 8px; border: 1px solid #ddd; {time_style}'>{row['training_time']:.3f}</td>\"\n",
    "                html_table += \"</tr>\"\n",
    "            \n",
    "            html_table += \"</table>\"\n",
    "            html_table += \"<p style='font-size: 12px; color: #666;'>üí° Green: Best performance | Blue: Fastest training</p>\"\n",
    "            html_table += \"</div>\"\n",
    "            \n",
    "            display(HTML(html_table))\n",
    "    \n",
    "    def create_comparison_plots(self):\n",
    "        \"\"\"Create visualization comparing ensemble methods.\"\"\"\n",
    "        with self.plot_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if not self.results:\n",
    "                return\n",
    "            \n",
    "            # Create subplots\n",
    "            fig = make_subplots(\n",
    "                rows=2, cols=2,\n",
    "                subplot_titles=('Performance Metrics', 'Training Time',\n",
    "                               'Precision vs Recall', 'Method Comparison'),\n",
    "                specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "                       [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "            )\n",
    "            \n",
    "            methods = list(self.results.keys())\n",
    "            \n",
    "            # 1. Performance metrics bar chart\n",
    "            metrics = ['precision', 'recall', 'f1_score', 'accuracy']\n",
    "            colors = ['blue', 'green', 'red', 'orange']\n",
    "            \n",
    "            for i, (metric, color) in enumerate(zip(metrics, colors)):\n",
    "                values = [self.results[method][metric] for method in methods]\n",
    "                fig.add_trace(\n",
    "                    go.Bar(\n",
    "                        name=metric.replace('_', ' ').title(),\n",
    "                        x=methods,\n",
    "                        y=values,\n",
    "                        marker_color=color,\n",
    "                        opacity=0.7\n",
    "                    ),\n",
    "                    row=1, col=1\n",
    "                )\n",
    "            \n",
    "            # 2. Training time\n",
    "            training_times = [self.results[method]['training_time'] for method in methods]\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=methods,\n",
    "                    y=training_times,\n",
    "                    name='Training Time',\n",
    "                    marker_color='purple',\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "            \n",
    "            # 3. Precision vs Recall scatter\n",
    "            precisions = [self.results[method]['precision'] for method in methods]\n",
    "            recalls = [self.results[method]['recall'] for method in methods]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=recalls,\n",
    "                    y=precisions,\n",
    "                    mode='markers+text',\n",
    "                    text=methods,\n",
    "                    textposition=\"top center\",\n",
    "                    marker=dict(size=12, color='darkblue'),\n",
    "                    name='Methods',\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "            \n",
    "            # 4. Radar chart for method comparison\n",
    "            # Use F1-scores for the radar chart\n",
    "            f1_scores = [self.results[method]['f1_score'] for method in methods]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=methods,\n",
    "                    y=f1_scores,\n",
    "                    name='F1-Score',\n",
    "                    marker_color='gold',\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=2\n",
    "            )\n",
    "            \n",
    "            # Update layout\n",
    "            fig.update_layout(\n",
    "                height=800,\n",
    "                title_text=\"Ensemble Methods Comparison Dashboard\",\n",
    "                showlegend=True\n",
    "            )\n",
    "            \n",
    "            # Update axes labels\n",
    "            fig.update_xaxes(title_text=\"Method\", row=1, col=1)\n",
    "            fig.update_yaxes(title_text=\"Score\", row=1, col=1)\n",
    "            fig.update_xaxes(title_text=\"Method\", row=1, col=2)\n",
    "            fig.update_yaxes(title_text=\"Time (seconds)\", row=1, col=2)\n",
    "            fig.update_xaxes(title_text=\"Recall\", row=2, col=1)\n",
    "            fig.update_yaxes(title_text=\"Precision\", row=2, col=1)\n",
    "            fig.update_xaxes(title_text=\"Method\", row=2, col=2)\n",
    "            fig.update_yaxes(title_text=\"F1-Score\", row=2, col=2)\n",
    "            \n",
    "            fig.show()\n",
    "\n",
    "print(\"‚úÖ EnsembleComparator created!\")\n",
    "print(\"üéõÔ∏è Ready to launch interactive ensemble comparison!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Launch Interactive Ensemble Comparison\n",
    "\n",
    "Use the interactive tool below to compare different ensemble methods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display the ensemble comparator\n",
    "comparator = EnsembleComparator()\n",
    "comparator.display_interface()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî¨ ENSEMBLE COMPARISON INSTRUCTIONS:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. üéõÔ∏è Configure dataset parameters (samples, features, contamination)\")\n",
    "print(\"2. üéØ Select ensemble methods to compare\")\n",
    "print(\"3. üìä Click 'Generate Data' to create synthetic dataset\")\n",
    "print(\"4. üöÄ Click 'Compare Ensembles' to run the comparison\")\n",
    "print(\"5. üìà Analyze results in the table and visualizations\")\n",
    "print(\"=\"*60)\n",
    "print(\"üí° Available Ensemble Methods:\")\n",
    "print(\"   ‚Ä¢ Majority Voting: Predict anomaly if majority agrees\")\n",
    "print(\"   ‚Ä¢ Unanimous Voting: Predict anomaly only if all agree\")\n",
    "print(\"   ‚Ä¢ Any Voting: Predict anomaly if any detector agrees\")\n",
    "print(\"   ‚Ä¢ Mean Averaging: Average anomaly scores\")\n",
    "print(\"   ‚Ä¢ Median Averaging: Use median of anomaly scores\")\n",
    "print(\"   ‚Ä¢ Max Averaging: Use maximum anomaly score\")\n",
    "print(\"   ‚Ä¢ Stacking: Use meta-learner on base detector outputs\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Advanced Ensemble Architectures\n",
    "\n",
    "Let's explore more sophisticated ensemble architectures for complex scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalEnsemble:\n",
    "    \"\"\"Hierarchical ensemble with multiple levels of combination.\"\"\"\n",
    "    \n",
    "    def __init__(self, detector_groups, combination_strategy='voting'):\n",
    "        self.detector_groups = detector_groups  # List of detector groups\n",
    "        self.combination_strategy = combination_strategy\n",
    "        self.group_ensembles = []\n",
    "        self.meta_ensemble = None\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit hierarchical ensemble.\"\"\"\n",
    "        # Step 1: Create ensembles for each group\n",
    "        self.group_ensembles = []\n",
    "        \n",
    "        for i, detector_group in enumerate(self.detector_groups):\n",
    "            print(f\"üîß Training group {i+1} ensemble...\")\n",
    "            \n",
    "            # Fit individual detectors in the group\n",
    "            for detector in detector_group:\n",
    "                if not detector.is_fitted:\n",
    "                    detector.fit(X)\n",
    "            \n",
    "            # Create group ensemble\n",
    "            if self.combination_strategy == 'voting':\n",
    "                group_ensemble = VotingEnsemble(detector_group, 'majority')\n",
    "            else:\n",
    "                group_ensemble = AveragingEnsemble(detector_group, 'mean')\n",
    "            \n",
    "            group_ensemble.fit(X)\n",
    "            self.group_ensembles.append(group_ensemble)\n",
    "        \n",
    "        # Step 2: Create meta-ensemble from group ensembles\n",
    "        print(\"üîß Training meta-ensemble...\")\n",
    "        if self.combination_strategy == 'voting':\n",
    "            self.meta_ensemble = VotingEnsemble(self.group_ensembles, 'majority')\n",
    "        else:\n",
    "            self.meta_ensemble = AveragingEnsemble(self.group_ensembles, 'mean')\n",
    "        \n",
    "        # Meta-ensemble doesn't need fitting as sub-ensembles are already fitted\n",
    "        self.meta_ensemble.is_fitted = True\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make hierarchical predictions.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Hierarchical ensemble must be fitted first.\")\n",
    "        \n",
    "        return self.meta_ensemble.predict(X)\n",
    "    \n",
    "    def get_group_predictions(self, X):\n",
    "        \"\"\"Get predictions from each group ensemble.\"\"\"\n",
    "        group_predictions = {}\n",
    "        \n",
    "        for i, group_ensemble in enumerate(self.group_ensembles):\n",
    "            group_predictions[f'Group_{i+1}'] = group_ensemble.predict(X)\n",
    "        \n",
    "        return group_predictions\n",
    "\n",
    "\n",
    "class DynamicEnsemble:\n",
    "    \"\"\"Dynamic ensemble that adapts based on data characteristics.\"\"\"\n",
    "    \n",
    "    def __init__(self, detectors, adaptation_strategy='confidence'):\n",
    "        self.detectors = detectors\n",
    "        self.adaptation_strategy = adaptation_strategy\n",
    "        self.detector_weights = None\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit detectors and calculate adaptive weights.\"\"\"\n",
    "        # Fit all detectors\n",
    "        for detector in self.detectors:\n",
    "            if not detector.is_fitted:\n",
    "                detector.fit(X)\n",
    "        \n",
    "        # Calculate weights based on adaptation strategy\n",
    "        if self.adaptation_strategy == 'confidence':\n",
    "            self.detector_weights = self._calculate_confidence_weights(X)\n",
    "        elif self.adaptation_strategy == 'diversity':\n",
    "            self.detector_weights = self._calculate_diversity_weights(X)\n",
    "        elif self.adaptation_strategy == 'performance':\n",
    "            if y is not None:\n",
    "                self.detector_weights = self._calculate_performance_weights(X, y)\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Performance-based weighting requires labels, using equal weights\")\n",
    "                self.detector_weights = np.ones(len(self.detectors)) / len(self.detectors)\n",
    "        else:\n",
    "            # Equal weights\n",
    "            self.detector_weights = np.ones(len(self.detectors)) / len(self.detectors)\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def _calculate_confidence_weights(self, X):\n",
    "        \"\"\"Calculate weights based on prediction confidence.\"\"\"\n",
    "        weights = []\n",
    "        \n",
    "        for detector in self.detectors:\n",
    "            if detector.is_fitted:\n",
    "                try:\n",
    "                    scores = detector.decision_function(X)\n",
    "                    # Use standard deviation of scores as confidence measure\n",
    "                    confidence = np.std(scores)\n",
    "                    weights.append(confidence)\n",
    "                except:\n",
    "                    weights.append(1.0)  # Default weight\n",
    "            else:\n",
    "                weights.append(0.0)\n",
    "        \n",
    "        # Normalize weights\n",
    "        weights = np.array(weights)\n",
    "        return weights / np.sum(weights) if np.sum(weights) > 0 else weights\n",
    "    \n",
    "    def _calculate_diversity_weights(self, X):\n",
    "        \"\"\"Calculate weights based on prediction diversity.\"\"\"\n",
    "        # Get predictions from all detectors\n",
    "        all_predictions = []\n",
    "        for detector in self.detectors:\n",
    "            if detector.is_fitted:\n",
    "                predictions = detector.predict(X)\n",
    "                all_predictions.append(predictions)\n",
    "        \n",
    "        if len(all_predictions) < 2:\n",
    "            return np.ones(len(self.detectors)) / len(self.detectors)\n",
    "        \n",
    "        # Calculate diversity for each detector\n",
    "        weights = []\n",
    "        predictions_array = np.array(all_predictions)\n",
    "        \n",
    "        for i in range(len(all_predictions)):\n",
    "            # Calculate disagreement with other detectors\n",
    "            diversity = 0\n",
    "            for j in range(len(all_predictions)):\n",
    "                if i != j:\n",
    "                    diversity += np.mean(predictions_array[i] != predictions_array[j])\n",
    "            \n",
    "            weights.append(diversity / (len(all_predictions) - 1))\n",
    "        \n",
    "        # Normalize weights\n",
    "        weights = np.array(weights)\n",
    "        return weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(weights)) / len(weights)\n",
    "    \n",
    "    def _calculate_performance_weights(self, X, y):\n",
    "        \"\"\"Calculate weights based on individual performance.\"\"\"\n",
    "        weights = []\n",
    "        \n",
    "        for detector in self.detectors:\n",
    "            if detector.is_fitted:\n",
    "                predictions = detector.predict(X)\n",
    "                \n",
    "                # Calculate F1-score as performance measure\n",
    "                y_pred_binary = (predictions == -1).astype(int)\n",
    "                y_true_binary = (y == -1).astype(int)\n",
    "                \n",
    "                f1 = f1_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "                weights.append(f1)\n",
    "            else:\n",
    "                weights.append(0.0)\n",
    "        \n",
    "        # Normalize weights\n",
    "        weights = np.array(weights)\n",
    "        return weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(weights)) / len(weights)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make dynamic weighted predictions.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Dynamic ensemble must be fitted first.\")\n",
    "        \n",
    "        # Get predictions from all detectors\n",
    "        all_predictions = []\n",
    "        valid_weights = []\n",
    "        \n",
    "        for i, detector in enumerate(self.detectors):\n",
    "            if detector.is_fitted:\n",
    "                predictions = detector.predict(X)\n",
    "                all_predictions.append(predictions)\n",
    "                valid_weights.append(self.detector_weights[i])\n",
    "        \n",
    "        if not all_predictions:\n",
    "            raise ValueError(\"No fitted detectors available.\")\n",
    "        \n",
    "        # Weighted voting\n",
    "        predictions_array = np.array(all_predictions)  # Shape: (n_detectors, n_samples)\n",
    "        valid_weights = np.array(valid_weights)\n",
    "        \n",
    "        # Calculate weighted anomaly votes\n",
    "        anomaly_weights = np.zeros(X.shape[0])\n",
    "        \n",
    "        for i, (predictions, weight) in enumerate(zip(all_predictions, valid_weights)):\n",
    "            anomaly_weights += (predictions == -1).astype(float) * weight\n",
    "        \n",
    "        # Make final predictions\n",
    "        ensemble_predictions = np.where(anomaly_weights > 0.5, -1, 1)\n",
    "        \n",
    "        return ensemble_predictions\n",
    "    \n",
    "    def get_detector_weights(self):\n",
    "        \"\"\"Get current detector weights.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            return None\n",
    "        \n",
    "        return dict(zip(\n",
    "            [d.name for d in self.detectors],\n",
    "            self.detector_weights\n",
    "        ))\n",
    "\n",
    "print(\"‚úÖ Advanced ensemble architectures created!\")\n",
    "print(\"üèóÔ∏è Ready for hierarchical and dynamic ensembles!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Advanced Ensemble Demo\n",
    "\n",
    "Let's demonstrate the advanced ensemble architectures with a comprehensive example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate demonstration dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 2000\n",
    "n_features = 8\n",
    "contamination = 0.12\n",
    "\n",
    "print(\"üîÑ Generating comprehensive demonstration dataset...\")\n",
    "\n",
    "# Generate normal data with multiple clusters\n",
    "cluster1 = np.random.multivariate_normal([0, 0] + [0] * (n_features-2), np.eye(n_features), size=800)\n",
    "cluster2 = np.random.multivariate_normal([3, 3] + [0] * (n_features-2), np.eye(n_features) * 0.5, size=600)\n",
    "cluster3 = np.random.multivariate_normal([-2, 2] + [0] * (n_features-2), np.eye(n_features) * 0.8, size=360)\n",
    "\n",
    "normal_data = np.vstack([cluster1, cluster2, cluster3])\n",
    "\n",
    "# Generate diverse types of anomalies\n",
    "n_anomalies = int(n_samples * contamination)\n",
    "anomaly1 = np.random.uniform(-6, 6, size=(n_anomalies//3, n_features))  # Scattered outliers\n",
    "anomaly2 = np.random.multivariate_normal([8, -8] + [0] * (n_features-2), np.eye(n_features) * 0.2, size=n_anomalies//3)  # Distant cluster\n",
    "anomaly3 = np.random.exponential(2, size=(n_anomalies - 2*(n_anomalies//3), n_features))  # Different distribution\n",
    "\n",
    "anomaly_data = np.vstack([anomaly1, anomaly2, anomaly3])\n",
    "\n",
    "# Combine and shuffle\n",
    "demo_data = np.vstack([normal_data, anomaly_data])\n",
    "demo_labels = np.hstack([np.ones(len(normal_data)), -np.ones(len(anomaly_data))])\n",
    "\n",
    "indices = np.random.permutation(len(demo_data))\n",
    "demo_data = demo_data[indices]\n",
    "demo_labels = demo_labels[indices]\n",
    "\n",
    "print(f\"‚úÖ Dataset created: {len(demo_data)} samples, {n_features} features\")\n",
    "print(f\"üìä Normal samples: {np.sum(demo_labels == 1)}, Anomalies: {np.sum(demo_labels == -1)}\")\n",
    "\n",
    "# Create detector groups for hierarchical ensemble\n",
    "detector_suite = DetectorSuite(contamination=contamination)\n",
    "detector_suite.fit_all(demo_data, verbose=False)\n",
    "\n",
    "# Group detectors by type\n",
    "isolation_group = [d for d in detector_suite.detectors if 'IsolationForest' in d.name and d.is_fitted]\n",
    "lof_group = [d for d in detector_suite.detectors if 'LOF' in d.name and d.is_fitted]\n",
    "svm_group = [d for d in detector_suite.detectors if 'SVM' in d.name and d.is_fitted]\n",
    "\n",
    "print(f\"\\nüîß Detector groups:\")\n",
    "print(f\"   Isolation Forest group: {len(isolation_group)} detectors\")\n",
    "print(f\"   LOF group: {len(lof_group)} detectors\")\n",
    "print(f\"   SVM group: {len(svm_group)} detectors\")\n",
    "\n",
    "# Test hierarchical ensemble\n",
    "print(\"\\nüèóÔ∏è Testing Hierarchical Ensemble...\")\n",
    "hierarchical = HierarchicalEnsemble(\n",
    "    detector_groups=[isolation_group, lof_group, svm_group],\n",
    "    combination_strategy='voting'\n",
    ")\n",
    "hierarchical.fit(demo_data)\n",
    "hierarchical_predictions = hierarchical.predict(demo_data)\n",
    "\n",
    "# Test dynamic ensemble with different strategies\n",
    "print(\"\\n‚ö° Testing Dynamic Ensembles...\")\n",
    "fitted_detectors = [d for d in detector_suite.detectors if d.is_fitted]\n",
    "\n",
    "dynamic_confidence = DynamicEnsemble(fitted_detectors, 'confidence')\n",
    "dynamic_confidence.fit(demo_data)\n",
    "confidence_predictions = dynamic_confidence.predict(demo_data)\n",
    "\n",
    "dynamic_diversity = DynamicEnsemble(fitted_detectors, 'diversity')\n",
    "dynamic_diversity.fit(demo_data)\n",
    "diversity_predictions = dynamic_diversity.predict(demo_data)\n",
    "\n",
    "dynamic_performance = DynamicEnsemble(fitted_detectors, 'performance')\n",
    "dynamic_performance.fit(demo_data, demo_labels)\n",
    "performance_predictions = dynamic_performance.predict(demo_data)\n",
    "\n",
    "# Evaluate all ensembles\n",
    "print(\"\\nüìä ADVANCED ENSEMBLE EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ensembles = {\n",
    "    'Hierarchical Voting': hierarchical_predictions,\n",
    "    'Dynamic (Confidence)': confidence_predictions,\n",
    "    'Dynamic (Diversity)': diversity_predictions,\n",
    "    'Dynamic (Performance)': performance_predictions\n",
    "}\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for name, predictions in ensembles.items():\n",
    "    y_pred_binary = (predictions == -1).astype(int)\n",
    "    y_true_binary = (demo_labels == -1).astype(int)\n",
    "    \n",
    "    precision = precision_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    recall = recall_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    f1 = f1_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    accuracy = np.mean(y_pred_binary == y_true_binary)\n",
    "    \n",
    "    results_summary.append({\n",
    "        'Method': name,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "    \n",
    "    print(f\"{name:25} | P: {precision:.3f} | R: {recall:.3f} | F1: {f1:.3f} | Acc: {accuracy:.3f}\")\n",
    "\n",
    "# Display dynamic ensemble weights\n",
    "print(\"\\nüîç DYNAMIC ENSEMBLE WEIGHTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìä Confidence-based weights:\")\n",
    "confidence_weights = dynamic_confidence.get_detector_weights()\n",
    "for detector, weight in confidence_weights.items():\n",
    "    print(f\"   {detector:30} {weight:.3f}\")\n",
    "\n",
    "print(\"\\nüéØ Diversity-based weights:\")\n",
    "diversity_weights = dynamic_diversity.get_detector_weights()\n",
    "for detector, weight in diversity_weights.items():\n",
    "    print(f\"   {detector:30} {weight:.3f}\")\n",
    "\n",
    "print(\"\\nüèÜ Performance-based weights:\")\n",
    "performance_weights = dynamic_performance.get_detector_weights()\n",
    "for detector, weight in performance_weights.items():\n",
    "    print(f\"   {detector:30} {weight:.3f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Advanced ensemble demonstration completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Ensemble Performance Visualization\n",
    "\n",
    "Let's create comprehensive visualizations to understand ensemble behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive ensemble performance visualization\n",
    "def create_ensemble_analysis_plots():\n",
    "    \"\"\"Create detailed analysis plots for ensemble methods.\"\"\"\n",
    "    \n",
    "    # Create master subplot figure\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Performance Comparison', 'Detector Weight Distribution',\n",
    "            'Prediction Agreement Matrix', 'ROC Comparison',\n",
    "            'Data Distribution (2D Projection)', 'Ensemble Decision Boundaries'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "            [{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "            [{\"secondary_y\": False}, {\"secondary_y\": False}]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 1. Performance comparison bar chart\n",
    "    methods = [r['Method'] for r in results_summary]\n",
    "    f1_scores = [r['F1-Score'] for r in results_summary]\n",
    "    precisions = [r['Precision'] for r in results_summary]\n",
    "    recalls = [r['Recall'] for r in results_summary]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(name='F1-Score', x=methods, y=f1_scores, marker_color='gold'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(name='Precision', x=methods, y=precisions, marker_color='lightblue'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(name='Recall', x=methods, y=recalls, marker_color='lightcoral'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Detector weight distribution (performance-based)\n",
    "    detector_names = list(performance_weights.keys())\n",
    "    weights = list(performance_weights.values())\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(x=detector_names, y=weights, marker_color='purple', name='Weights'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Prediction agreement matrix\n",
    "    ensemble_names = list(ensembles.keys())\n",
    "    agreement_matrix = np.zeros((len(ensemble_names), len(ensemble_names)))\n",
    "    \n",
    "    for i, (name1, pred1) in enumerate(ensembles.items()):\n",
    "        for j, (name2, pred2) in enumerate(ensembles.items()):\n",
    "            agreement = np.mean(pred1 == pred2)\n",
    "            agreement_matrix[i, j] = agreement\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=agreement_matrix,\n",
    "            x=ensemble_names,\n",
    "            y=ensemble_names,\n",
    "            colorscale='Viridis',\n",
    "            name='Agreement'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Individual detector performance\n",
    "    individual_results = detector_suite.evaluate_individual_performance(demo_data, demo_labels)\n",
    "    individual_names = list(individual_results.keys())\n",
    "    individual_f1s = [individual_results[name]['f1_score'] for name in individual_names]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(x=individual_names, y=individual_f1s, marker_color='orange', name='Individual F1'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # 5. Data distribution (2D projection of first two features)\n",
    "    normal_mask = demo_labels == 1\n",
    "    anomaly_mask = demo_labels == -1\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=demo_data[normal_mask, 0],\n",
    "            y=demo_data[normal_mask, 1],\n",
    "            mode='markers',\n",
    "            name='Normal',\n",
    "            marker=dict(color='blue', size=4, opacity=0.6)\n",
    "        ),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=demo_data[anomaly_mask, 0],\n",
    "            y=demo_data[anomaly_mask, 1],\n",
    "            mode='markers',\n",
    "            name='Anomaly',\n",
    "            marker=dict(color='red', size=6, opacity=0.8)\n",
    "        ),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    \n",
    "    # 6. Ensemble prediction comparison (scatter)\n",
    "    colors = ['gold', 'lightblue', 'lightgreen', 'orange']\n",
    "    for i, (name, predictions) in enumerate(ensembles.items()):\n",
    "        pred_anomalies = predictions == -1\n",
    "        if np.any(pred_anomalies):\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=demo_data[pred_anomalies, 0],\n",
    "                    y=demo_data[pred_anomalies, 1],\n",
    "                    mode='markers',\n",
    "                    name=f'{name} Predictions',\n",
    "                    marker=dict(color=colors[i], size=8, opacity=0.7,\n",
    "                               symbol='x' if i % 2 == 0 else 'circle')\n",
    "                ),\n",
    "                row=3, col=2\n",
    "            )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=1200,\n",
    "        title_text=\"Comprehensive Ensemble Analysis Dashboard\",\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Update individual subplot properties\n",
    "    fig.update_xaxes(title_text=\"Method\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Score\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Detector\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Weight\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Feature 1\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"Feature 2\", row=3, col=1)\n",
    "    fig.update_xaxes(title_text=\"Feature 1\", row=3, col=2)\n",
    "    fig.update_yaxes(title_text=\"Feature 2\", row=3, col=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display the comprehensive analysis\n",
    "print(\"üé® Creating comprehensive ensemble analysis visualization...\")\n",
    "analysis_fig = create_ensemble_analysis_plots()\n",
    "analysis_fig.show()\n",
    "\n",
    "# Create summary insights\n",
    "print(\"\\nüí° ENSEMBLE INSIGHTS AND RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Find best performing method\n",
    "best_method = max(results_summary, key=lambda x: x['F1-Score'])\n",
    "print(f\"üèÜ Best Overall Method: {best_method['Method']} (F1: {best_method['F1-Score']:.3f})\")\n",
    "\n",
    "# Analyze weight distributions\n",
    "top_weighted_detector = max(performance_weights.items(), key=lambda x: x[1])\n",
    "print(f\"üéØ Most Important Detector: {top_weighted_detector[0]} (Weight: {top_weighted_detector[1]:.3f})\")\n",
    "\n",
    "# Method recommendations\n",
    "print(\"\\nüìã Method Recommendations:\")\n",
    "print(\"   üöÄ High Accuracy: Use performance-weighted dynamic ensemble\")\n",
    "print(\"   ‚ö° Fast Inference: Use majority voting ensemble\")\n",
    "print(\"   üéõÔ∏è Adaptability: Use hierarchical ensemble with diverse groups\")\n",
    "print(\"   üîç Interpretability: Use confidence-weighted dynamic ensemble\")\n",
    "\n",
    "print(\"\\n‚úÖ Comprehensive ensemble analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Production Ensemble System\n",
    "\n",
    "Let's create a production-ready ensemble system with all the advanced features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionEnsembleSystem:\n",
    "    \"\"\"Production-ready ensemble anomaly detection system.\"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        self.config = config or self._get_default_config()\n",
    "        self.detector_suite = None\n",
    "        self.ensembles = {}\n",
    "        self.model_registry = {}\n",
    "        self.performance_metrics = {}\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def _get_default_config(self):\n",
    "        \"\"\"Get default production configuration.\"\"\"\n",
    "        return {\n",
    "            'contamination': 0.1,\n",
    "            'ensemble_methods': [\n",
    "                'majority_voting',\n",
    "                'mean_averaging', \n",
    "                'performance_weighted',\n",
    "                'hierarchical'\n",
    "            ],\n",
    "            'enable_model_selection': True,\n",
    "            'enable_monitoring': True,\n",
    "            'enable_fallback': True,\n",
    "            'performance_threshold': 0.7,\n",
    "            'model_update_strategy': 'periodic',\n",
    "            'backup_models': 2\n",
    "        }\n",
    "    \n",
    "    def fit(self, X, y=None, validation_split=0.2):\n",
    "        \"\"\"Fit the production ensemble system.\"\"\"\n",
    "        print(\"üè≠ Initializing Production Ensemble System...\")\n",
    "        \n",
    "        # Split data for validation\n",
    "        if validation_split > 0:\n",
    "            split_idx = int((1 - validation_split) * len(X))\n",
    "            train_X, val_X = X[:split_idx], X[split_idx:]\n",
    "            if y is not None:\n",
    "                train_y, val_y = y[:split_idx], y[split_idx:]\n",
    "            else:\n",
    "                train_y, val_y = None, None\n",
    "        else:\n",
    "            train_X, val_X = X, X\n",
    "            train_y, val_y = y, y\n",
    "        \n",
    "        # Create and fit detector suite\n",
    "        print(\"üîß Building detector suite...\")\n",
    "        self.detector_suite = DetectorSuite(self.config['contamination'])\n",
    "        self.detector_suite.fit_all(train_X, verbose=False)\n",
    "        \n",
    "        # Build ensemble methods\n",
    "        print(\"üéØ Creating ensemble methods...\")\n",
    "        self._build_ensembles(train_X, train_y)\n",
    "        \n",
    "        # Validate and select best models\n",
    "        if self.config['enable_model_selection'] and val_y is not None:\n",
    "            print(\"üìä Validating and selecting best models...\")\n",
    "            self._validate_and_select_models(val_X, val_y)\n",
    "        \n",
    "        # Create fallback models\n",
    "        if self.config['enable_fallback']:\n",
    "            print(\"üõ°Ô∏è Creating fallback models...\")\n",
    "            self._create_fallback_models(train_X, train_y)\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        print(\"‚úÖ Production ensemble system ready!\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _build_ensembles(self, X, y):\n",
    "        \"\"\"Build all configured ensemble methods.\"\"\"\n",
    "        fitted_detectors = [d for d in self.detector_suite.detectors if d.is_fitted]\n",
    "        \n",
    "        if 'majority_voting' in self.config['ensemble_methods']:\n",
    "            self.ensembles['majority_voting'] = VotingEnsemble(\n",
    "                fitted_detectors, 'majority'\n",
    "            )\n",
    "            self.ensembles['majority_voting'].fit(X)\n",
    "        \n",
    "        if 'mean_averaging' in self.config['ensemble_methods']:\n",
    "            self.ensembles['mean_averaging'] = AveragingEnsemble(\n",
    "                fitted_detectors, 'mean'\n",
    "            )\n",
    "            self.ensembles['mean_averaging'].fit(X, contamination=self.config['contamination'])\n",
    "        \n",
    "        if 'performance_weighted' in self.config['ensemble_methods'] and y is not None:\n",
    "            self.ensembles['performance_weighted'] = DynamicEnsemble(\n",
    "                fitted_detectors, 'performance'\n",
    "            )\n",
    "            self.ensembles['performance_weighted'].fit(X, y)\n",
    "        \n",
    "        if 'hierarchical' in self.config['ensemble_methods']:\n",
    "            # Group detectors by type\n",
    "            groups = self._group_detectors_by_type(fitted_detectors)\n",
    "            if len(groups) > 1:\n",
    "                self.ensembles['hierarchical'] = HierarchicalEnsemble(groups)\n",
    "                self.ensembles['hierarchical'].fit(X)\n",
    "    \n",
    "    def _group_detectors_by_type(self, detectors):\n",
    "        \"\"\"Group detectors by algorithm type.\"\"\"\n",
    "        groups = defaultdict(list)\n",
    "        \n",
    "        for detector in detectors:\n",
    "            if 'IsolationForest' in detector.name:\n",
    "                groups['isolation'].append(detector)\n",
    "            elif 'LOF' in detector.name:\n",
    "                groups['lof'].append(detector)\n",
    "            elif 'SVM' in detector.name:\n",
    "                groups['svm'].append(detector)\n",
    "            else:\n",
    "                groups['other'].append(detector)\n",
    "        \n",
    "        # Return non-empty groups\n",
    "        return [group for group in groups.values() if len(group) > 0]\n",
    "    \n",
    "    def _validate_and_select_models(self, val_X, val_y):\n",
    "        \"\"\"Validate ensembles and select best performing ones.\"\"\"\n",
    "        validation_results = {}\n",
    "        \n",
    "        for name, ensemble in self.ensembles.items():\n",
    "            try:\n",
    "                predictions = ensemble.predict(val_X)\n",
    "                \n",
    "                y_pred_binary = (predictions == -1).astype(int)\n",
    "                y_true_binary = (val_y == -1).astype(int)\n",
    "                \n",
    "                f1 = f1_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "                precision = precision_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "                recall = recall_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "                \n",
    "                validation_results[name] = {\n",
    "                    'f1_score': f1,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'status': 'good' if f1 >= self.config['performance_threshold'] else 'poor'\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                validation_results[name] = {\n",
    "                    'f1_score': 0.0,\n",
    "                    'precision': 0.0,\n",
    "                    'recall': 0.0,\n",
    "                    'status': 'failed',\n",
    "                    'error': str(e)\n",
    "                }\n",
    "        \n",
    "        self.performance_metrics = validation_results\n",
    "        \n",
    "        # Select top performing models\n",
    "        good_models = {name: metrics for name, metrics in validation_results.items() \n",
    "                      if metrics['status'] == 'good'}\n",
    "        \n",
    "        if good_models:\n",
    "            # Keep top performers\n",
    "            top_models = sorted(good_models.items(), \n",
    "                              key=lambda x: x[1]['f1_score'], \n",
    "                              reverse=True)[:self.config['backup_models'] + 1]\n",
    "            \n",
    "            self.model_registry = {name: self.ensembles[name] for name, _ in top_models}\n",
    "            print(f\"üéØ Selected {len(self.model_registry)} top performing models\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No models met performance threshold, keeping all models\")\n",
    "            self.model_registry = self.ensembles.copy()\n",
    "    \n",
    "    def _create_fallback_models(self, X, y):\n",
    "        \"\"\"Create simple fallback models for robustness.\"\"\"\n",
    "        # Simple Isolation Forest fallback\n",
    "        fallback_detector = IndividualDetector(\n",
    "            \"Fallback_IsolationForest\",\n",
    "            IsolationForest(\n",
    "                contamination=self.config['contamination'],\n",
    "                random_state=42,\n",
    "                n_estimators=50\n",
    "            )\n",
    "        )\n",
    "        fallback_detector.fit(X)\n",
    "        \n",
    "        self.model_registry['fallback'] = fallback_detector\n",
    "    \n",
    "    def predict(self, X, method='best', enable_consensus=True):\n",
    "        \"\"\"Make production predictions with fallback handling.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"System must be fitted before prediction.\")\n",
    "        \n",
    "        try:\n",
    "            if method == 'best':\n",
    "                # Use best performing model\n",
    "                if self.performance_metrics:\n",
    "                    best_model = max(self.performance_metrics.items(), \n",
    "                                   key=lambda x: x[1]['f1_score'])[0]\n",
    "                    if best_model in self.model_registry:\n",
    "                        return self.model_registry[best_model].predict(X)\n",
    "                \n",
    "                # Fallback to first available model\n",
    "                return next(iter(self.model_registry.values())).predict(X)\n",
    "            \n",
    "            elif method == 'consensus' and enable_consensus:\n",
    "                # Consensus prediction from multiple models\n",
    "                all_predictions = []\n",
    "                \n",
    "                for name, model in self.model_registry.items():\n",
    "                    if name != 'fallback':  # Skip fallback for consensus\n",
    "                        try:\n",
    "                            pred = model.predict(X)\n",
    "                            all_predictions.append(pred)\n",
    "                        except Exception as e:\n",
    "                            print(f\"‚ö†Ô∏è Model {name} failed: {e}\")\n",
    "                \n",
    "                if all_predictions:\n",
    "                    # Majority voting\n",
    "                    predictions_array = np.array(all_predictions)\n",
    "                    anomaly_votes = np.sum(predictions_array == -1, axis=0)\n",
    "                    return np.where(anomaly_votes > len(all_predictions) / 2, -1, 1)\n",
    "            \n",
    "            elif method in self.model_registry:\n",
    "                return self.model_registry[method].predict(X)\n",
    "            \n",
    "            else:\n",
    "                raise ValueError(f\"Unknown method: {method}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Prediction failed, using fallback: {e}\")\n",
    "            if 'fallback' in self.model_registry:\n",
    "                return self.model_registry['fallback'].predict(X)\n",
    "            else:\n",
    "                raise RuntimeError(\"No fallback model available\")\n",
    "    \n",
    "    def get_system_status(self):\n",
    "        \"\"\"Get comprehensive system status.\"\"\"\n",
    "        return {\n",
    "            'is_fitted': self.is_fitted,\n",
    "            'available_methods': list(self.model_registry.keys()),\n",
    "            'performance_metrics': self.performance_metrics,\n",
    "            'configuration': self.config,\n",
    "            'detector_count': len(self.detector_suite.detectors) if self.detector_suite else 0,\n",
    "            'ensemble_count': len(self.ensembles)\n",
    "        }\n",
    "    \n",
    "    def get_prediction_explanation(self, X, sample_idx=0):\n",
    "        \"\"\"Get explanation for a specific prediction.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"System must be fitted before explanation.\")\n",
    "        \n",
    "        sample = X[sample_idx:sample_idx+1]\n",
    "        explanations = {}\n",
    "        \n",
    "        for name, model in self.model_registry.items():\n",
    "            if name != 'fallback':\n",
    "                try:\n",
    "                    prediction = model.predict(sample)[0]\n",
    "                    explanations[name] = {\n",
    "                        'prediction': 'Anomaly' if prediction == -1 else 'Normal',\n",
    "                        'confidence': 'High' if name in self.performance_metrics and \n",
    "                                     self.performance_metrics[name]['f1_score'] > 0.8 else 'Medium'\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    explanations[name] = {'error': str(e)}\n",
    "        \n",
    "        return explanations\n",
    "\n",
    "print(\"‚úÖ ProductionEnsembleSystem created!\")\n",
    "print(\"üè≠ Ready for enterprise-grade ensemble anomaly detection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Production System Demo\n",
    "\n",
    "Let's demonstrate the complete production ensemble system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and test production system\n",
    "print(\"üè≠ PRODUCTION ENSEMBLE SYSTEM DEMO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Custom configuration\n",
    "production_config = {\n",
    "    'contamination': 0.12,\n",
    "    'ensemble_methods': [\n",
    "        'majority_voting',\n",
    "        'mean_averaging',\n",
    "        'performance_weighted',\n",
    "        'hierarchical'\n",
    "    ],\n",
    "    'enable_model_selection': True,\n",
    "    'enable_monitoring': True,\n",
    "    'enable_fallback': True,\n",
    "    'performance_threshold': 0.6,\n",
    "    'model_update_strategy': 'periodic',\n",
    "    'backup_models': 3\n",
    "}\n",
    "\n",
    "# Initialize system\n",
    "production_system = ProductionEnsembleSystem(production_config)\n",
    "\n",
    "# Fit system with validation\n",
    "production_system.fit(demo_data, demo_labels, validation_split=0.3)\n",
    "\n",
    "# Test different prediction methods\n",
    "print(\"\\nüéØ Testing prediction methods...\")\n",
    "\n",
    "test_sample = demo_data[:100]  # Use first 100 samples for testing\n",
    "test_labels = demo_labels[:100]\n",
    "\n",
    "# Best model prediction\n",
    "best_predictions = production_system.predict(test_sample, method='best')\n",
    "best_f1 = f1_score(\n",
    "    (test_labels == -1).astype(int),\n",
    "    (best_predictions == -1).astype(int),\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "# Consensus prediction\n",
    "consensus_predictions = production_system.predict(test_sample, method='consensus')\n",
    "consensus_f1 = f1_score(\n",
    "    (test_labels == -1).astype(int),\n",
    "    (consensus_predictions == -1).astype(int),\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "print(f\"   Best Model F1-Score: {best_f1:.3f}\")\n",
    "print(f\"   Consensus F1-Score: {consensus_f1:.3f}\")\n",
    "\n",
    "# Get system status\n",
    "status = production_system.get_system_status()\n",
    "\n",
    "print(\"\\nüìä SYSTEM STATUS REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üîÑ System Status: {'Ready' if status['is_fitted'] else 'Not Ready'}\")\n",
    "print(f\"üéØ Available Methods: {', '.join(status['available_methods'])}\")\n",
    "print(f\"üîß Total Detectors: {status['detector_count']}\")\n",
    "print(f\"üé™ Ensemble Count: {status['ensemble_count']}\")\n",
    "\n",
    "print(\"\\nüìà Performance Metrics:\")\n",
    "for method, metrics in status['performance_metrics'].items():\n",
    "    if 'error' not in metrics:\n",
    "        print(f\"   {method:20} | F1: {metrics['f1_score']:.3f} | Status: {metrics['status']}\")\n",
    "    else:\n",
    "        print(f\"   {method:20} | Status: {metrics['status']} | Error: {metrics['error']}\")\n",
    "\n",
    "# Test prediction explanation\n",
    "print(\"\\nüîç PREDICTION EXPLANATION (Sample 0)\")\n",
    "print(\"=\"*60)\n",
    "explanation = production_system.get_prediction_explanation(test_sample, sample_idx=0)\n",
    "\n",
    "for method, details in explanation.items():\n",
    "    if 'error' not in details:\n",
    "        print(f\"   {method:20} | Prediction: {details['prediction']:8} | Confidence: {details['confidence']}\")\n",
    "    else:\n",
    "        print(f\"   {method:20} | Error: {details['error']}\")\n",
    "\n",
    "# Performance comparison\n",
    "print(\"\\nüèÜ PRODUCTION VS INDIVIDUAL METHODS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compare with individual detector performance\n",
    "individual_performance = detector_suite.evaluate_individual_performance(test_sample, test_labels)\n",
    "avg_individual_f1 = np.mean([perf['f1_score'] for perf in individual_performance.values()])\n",
    "\n",
    "print(f\"   Average Individual F1: {avg_individual_f1:.3f}\")\n",
    "print(f\"   Best Ensemble F1:      {best_f1:.3f}\")\n",
    "print(f\"   Consensus Ensemble F1: {consensus_f1:.3f}\")\n",
    "print(f\"   Improvement Factor:     {best_f1/avg_individual_f1:.2f}x\")\n",
    "\n",
    "print(\"\\n‚úÖ Production ensemble system demo completed successfully!\")\n",
    "print(\"üéâ System is ready for enterprise deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways and Best Practices\n",
    "\n",
    "### üî¨ Ensemble Learning Principles\n",
    "- **Diversity is key**: Combine different algorithm types for better performance\n",
    "- **Weighted combinations**: Use performance-based weighting for optimal results\n",
    "- **Hierarchical architectures**: Group similar detectors before final combination\n",
    "- **Dynamic adaptation**: Adjust ensemble weights based on data characteristics\n",
    "\n",
    "### üéØ Ensemble Method Selection\n",
    "- **Voting methods**: Simple and robust, good for diverse detector outputs\n",
    "- **Averaging methods**: Better for similar detectors with score outputs\n",
    "- **Stacking**: Most powerful but requires labeled data for training\n",
    "- **Dynamic ensembles**: Adapt to changing data patterns automatically\n",
    "\n",
    "### üè≠ Production Considerations\n",
    "- **Model validation**: Always validate ensemble performance on held-out data\n",
    "- **Fallback strategies**: Include simple, robust models as fallbacks\n",
    "- **Monitoring systems**: Track ensemble performance over time\n",
    "- **Interpretability**: Provide explanations for ensemble decisions\n",
    "\n",
    "### ‚ö° Performance Optimization\n",
    "- **Selective ensembles**: Use only high-performing base detectors\n",
    "- **Efficient voting**: Pre-compute weights and use vectorized operations\n",
    "- **Parallel prediction**: Run base detectors in parallel when possible\n",
    "- **Resource management**: Balance accuracy vs computational efficiency\n",
    "\n",
    "## üîó Next Steps\n",
    "\n",
    "Continue your learning journey with:\n",
    "- [Real-Time Streaming Detection](07_real_time_streaming_detection.ipynb)\n",
    "- [Production Deployment Guide](09_production_deployment_guide.ipynb)\n",
    "- [Model Explainability Tutorial](08_model_explainability_tutorial.ipynb)\n",
    "\n",
    "## üÜò Getting Help\n",
    "\n",
    "Having trouble with ensemble methods? Check out:\n",
    "- [API Documentation](../api.md) for detailed function references\n",
    "- [Algorithm Guide](../algorithms.md) for understanding base detectors\n",
    "- [Performance Guide](../performance.md) for optimization strategies\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations!** You've mastered advanced ensemble methods for anomaly detection. You can now build sophisticated, production-ready ensemble systems that significantly outperform individual detectors while maintaining robustness and interpretability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}