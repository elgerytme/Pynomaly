"""
Data Observability Background Worker

Provides background worker for automated data observability tasks including
quality monitoring, lineage discovery, and health checks.
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List
from uuid import UUID
import schedule
import time

from .application.facades.observability_facade import DataObservabilityFacade
from .infrastructure.di.container import DataObservabilityContainer

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DataObservabilityWorker:
    """Background worker for data observability tasks."""
    
    def __init__(self):
        """Initialize the worker."""
        self.container = DataObservabilityContainer()
        self.container.wire(modules=[__name__])
        self.facade = self.container.observability_facade()
        self.running = False
        
    def start(self) -> None:
        """Start the background worker."""
        logger.info("Starting Data Observability Worker...")
        
        # Schedule periodic tasks
        schedule.every(5).minutes.do(self._check_pipeline_health)
        schedule.every(10).minutes.do(self._monitor_data_quality)
        schedule.every(30).minutes.do(self._discover_lineage)
        schedule.every(1).hour.do(self._generate_health_reports)
        schedule.every(6).hours.do(self._cleanup_old_alerts)
        schedule.every(1).day.do(self._update_usage_analytics)
        
        self.running = True
        
        try:
            while self.running:
                schedule.run_pending()
                time.sleep(30)  # Check every 30 seconds
        except KeyboardInterrupt:
            logger.info("Received shutdown signal")
        finally:
            self.stop()
    
    def stop(self) -> None:
        """Stop the background worker."""
        logger.info("Stopping Data Observability Worker...")
        self.running = False
        
    def _check_pipeline_health(self) -> None:
        """Check health of all monitored pipelines."""
        logger.info("üîç Checking pipeline health...")
        
        try:
            # Get all pipelines from health service
            all_pipelines = self.facade.health_service.get_all_pipelines()
            
            unhealthy_count = 0
            for pipeline in all_pipelines:
                if pipeline.get_health_score() < 0.7:  # Unhealthy threshold
                    unhealthy_count += 1
                    logger.warning(
                        f"Pipeline {pipeline.pipeline_id} is unhealthy: "
                        f"score={pipeline.get_health_score():.2f}"
                    )
            
            logger.info(
                f"Pipeline health check complete: "
                f"{len(all_pipelines)} total, {unhealthy_count} unhealthy"
            )
            
        except Exception as e:
            logger.error(f"Pipeline health check failed: {e}")
    
    def _monitor_data_quality(self) -> None:
        """Monitor data quality across all assets."""
        logger.info("‚ú® Monitoring data quality...")
        
        try:
            # Get active quality alerts
            alerts = self.facade.quality_service.get_active_alerts()
            
            critical_alerts = [a for a in alerts if a.severity == "critical"]
            high_alerts = [a for a in alerts if a.severity == "high"]
            
            if critical_alerts:
                logger.error(f"üö® {len(critical_alerts)} critical quality alerts!")
                for alert in critical_alerts[:5]:  # Log first 5
                    logger.error(f"   Asset {alert.asset_id}: {alert.alert_type}")
            
            if high_alerts:
                logger.warning(f"‚ö†Ô∏è  {len(high_alerts)} high priority quality alerts")
            
            logger.info(
                f"Quality monitoring complete: "
                f"{len(alerts)} total alerts, "
                f"{len(critical_alerts)} critical, "
                f"{len(high_alerts)} high priority"
            )
            
        except Exception as e:
            logger.error(f"Data quality monitoring failed: {e}")
    
    def _discover_lineage(self) -> None:
        """Discover and update data lineage automatically."""
        logger.info("üîó Discovering data lineage...")
        
        try:
            # Get lineage statistics - simplified since method doesn't exist
            all_lineages = self.facade.lineage_service.list_lineages()
            lineage_stats = {
                'total_lineages': len(all_lineages),
                'total_nodes': sum(len(l.nodes) for l in all_lineages),
                'total_edges': sum(len(l.edges) for l in all_lineages)
            }
            
            logger.info(
                f"Lineage discovery complete: "
                f"{lineage_stats.get('total_nodes', 0)} nodes, "
                f"{lineage_stats.get('total_edges', 0)} edges"
            )
            
            # Check for circular dependencies
            if lineage_stats.get('circular_dependencies', 0) > 0:
                logger.warning(
                    f"‚ö†Ô∏è  Found {lineage_stats['circular_dependencies']} "
                    "circular dependencies"
                )
            
        except Exception as e:
            logger.error(f"Lineage discovery failed: {e}")
    
    def _generate_health_reports(self) -> None:
        """Generate periodic health reports."""
        logger.info("üìä Generating health reports...")
        
        try:
            dashboard = self.facade.get_data_health_dashboard()
            
            # Log summary statistics
            catalog = dashboard.get('catalog', {})
            pipeline_health = dashboard.get('pipeline_health', {})
            quality = dashboard.get('quality_predictions', {})
            
            logger.info("üìã Health Report Summary:")
            logger.info(f"   üìö Assets: {catalog.get('total_assets', 0)}")
            logger.info(f"   ‚ö° Pipelines: {pipeline_health.get('total_pipelines', 0)}")
            logger.info(f"      - Healthy: {pipeline_health.get('healthy_pipelines', 0)}")
            logger.info(f"      - Degraded: {pipeline_health.get('degraded_pipelines', 0)}")
            logger.info(f"      - Unhealthy: {pipeline_health.get('unhealthy_pipelines', 0)}")
            logger.info(f"   üö® Quality Alerts: {quality.get('total_active_alerts', 0)}")
            logger.info(f"      - Critical: {quality.get('critical_alerts', 0)}")
            logger.info(f"      - High Priority: {quality.get('high_priority_alerts', 0)}")
            
        except Exception as e:
            logger.error(f"Health report generation failed: {e}")
    
    def _cleanup_old_alerts(self) -> None:
        """Clean up old resolved alerts."""
        logger.info("üßπ Cleaning up old alerts...")
        
        try:
            # This would typically involve calling cleanup methods
            # on the various services
            cutoff_date = datetime.utcnow() - timedelta(days=30)
            
            # Cleanup would be implemented in the actual services
            logger.info("Old alerts cleanup completed")
            
        except Exception as e:
            logger.error(f"Alert cleanup failed: {e}")
    
    def _update_usage_analytics(self) -> None:
        """Update usage analytics for all assets."""
        logger.info("üìà Updating usage analytics...")
        
        try:
            # Get catalog statistics to understand current state
            catalog_stats = self.facade.catalog_service.get_catalog_statistics()
            
            logger.info(
                f"Usage analytics update completed: "
                f"{catalog_stats.get('total_assets', 0)} assets processed"
            )
            
        except Exception as e:
            logger.error(f"Usage analytics update failed: {e}")


def main():
    """Main entry point for the worker."""
    worker = DataObservabilityWorker()
    
    try:
        worker.start()
    except Exception as e:
        logger.error(f"Worker failed: {e}")
        raise


if __name__ == "__main__":
    main()