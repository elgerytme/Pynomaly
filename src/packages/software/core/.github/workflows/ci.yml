name: Core Software CI/CD

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'src/packages/software/core/**'
      - '.github/workflows/**'
      - '.github/actions/**'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'src/packages/software/core/**'
      - '.github/workflows/**'
      - '.github/actions/**'
  workflow_dispatch:
    inputs:
      run_performance_tests:
        description: 'Run performance benchmarks'
        required: false
        default: true
        type: boolean
      python_version:
        description: 'Python version to use'
        required: false
        default: '3.11'
        type: string

env:
  PACKAGE_NAME: pynomaly-core
  PACKAGE_PATH: src/packages/software/core

jobs:
  # Use the reusable workflow for comprehensive CI/CD
  ci-cd:
    uses: ./.github/workflows/_reusable-python-ci.yml
    with:
      package-name: pynomaly-core
      package-path: src/packages/software/core
      python-version: ${{ github.event.inputs.python_version || '3.11' }}
      python-versions: '["3.9", "3.10", "3.11", "3.12"]'
      os-matrix: '["ubuntu-latest", "windows-latest", "macos-latest"]'
      coverage-threshold: 90
      run-performance-tests: ${{ github.event.inputs.run_performance_tests == 'true' || github.event_name == 'schedule' }}
      run-security-scan: true
      publish-to-pypi: ${{ github.event_name == 'release' }}
      run-integration-tests: true
    secrets:
      PYPI_API_TOKEN: ${{ secrets.PYPI_API_TOKEN }}
      CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
      SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

  # Core-specific tests
  core-specific-tests:
    name: Core Software Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python for package
        uses: ./.github/actions/setup-python-package
        with:
          python-version: '3.11'
          package-path: ${{ env.PACKAGE_PATH }}
          dependency-groups: 'test,all'

      - name: Test domain entities and value objects
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          pytest tests/ -k "test_domain or test_entity or test_value_object" \
            --verbose --tb=short

      - name: Test use cases and application layer
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          pytest tests/ -k "test_use_case or test_application" \
            --verbose --tb=short

      - name: Test DTOs and data structures
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          pytest tests/ -k "test_dto" \
            --verbose --tb=short

      - name: Test shared utilities and types
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          pytest tests/ -k "test_shared or test_util" \
            --verbose --tb=short

      - name: Validate clean architecture boundaries
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          python -c "
          import sys
          sys.path.insert(0, 'src')
          
          # Test clean architecture principles
          try:
              # Domain layer should not depend on application layer
              from pynomaly_core.domain import entities
              print('âœ… Domain entities loaded successfully')
              
              # Application layer can depend on domain
              from pynomaly_core.use_cases import automl_use_case
              print('âœ… Use cases loaded successfully')
              
              # DTOs should be clean data structures
              from pynomaly_core.dto import dataset_dto
              print('âœ… DTOs loaded successfully')
              
              print('âœ… Clean architecture boundaries maintained')
              
          except Exception as e:
              print(f'âŒ Architecture boundary violation: {e}')
              sys.exit(1)
          "

  # Performance and benchmarking
  performance-benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 30
    if: github.event.inputs.run_performance_tests == 'true' || github.event_name == 'schedule'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python for package
        uses: ./.github/actions/setup-python-package
        with:
          python-version: '3.11'
          package-path: ${{ env.PACKAGE_PATH }}
          dependency-groups: 'test,all'

      - name: Run core performance benchmarks
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          pytest tests/ -k "benchmark or performance" \
            --benchmark-only \
            --benchmark-json=core-performance.json \
            --benchmark-sort=mean

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        with:
          name: core-performance-results
          path: ${{ env.PACKAGE_PATH }}/core-performance.json

  # Security scan specific to core
  core-security-scan:
    name: Core Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python for package
        uses: ./.github/actions/setup-python-package
        with:
          python-version: '3.11'
          package-path: ${{ env.PACKAGE_PATH }}
          dependency-groups: 'dev,test'

      - name: Run comprehensive security scan
        uses: ./.github/actions/security-scan
        with:
          package-path: ${{ env.PACKAGE_PATH }}
          package-name: ${{ env.PACKAGE_NAME }}
          fail-on-high: true
          fail-on-medium: false
          upload-sarif: true

  # Deployment readiness
  deployment-readiness:
    name: Deployment Readiness
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [ci-cd, core-specific-tests]
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python for package
        uses: ./.github/actions/setup-python-package
        with:
          python-version: '3.11'
          package-path: ${{ env.PACKAGE_PATH }}
          dependency-groups: 'all'

      - name: Validate core package readiness
        working-directory: ${{ env.PACKAGE_PATH }}
        run: |
          python -c "
          import sys
          sys.path.insert(0, 'src')
          
          # Test all core modules can be imported
          modules = [
              'pynomaly_core.domain',
              'pynomaly_core.use_cases',
              'pynomaly_core.dto',
              'pynomaly_core.shared'
          ]
          
          for module in modules:
              try:
                  __import__(module)
                  print(f'âœ… {module} ready')
              except Exception as e:
                  print(f'âŒ {module} error: {e}')
                  sys.exit(1)
          
          print('âœ… Core package ready for deployment')
          "

      - name: Generate deployment summary
        run: |
          echo "## ðŸš€ Core Software Deployment Readiness" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… **Package**: ${{ env.PACKAGE_NAME }}" >> $GITHUB_STEP_SUMMARY
          echo "âœ… **Clean Architecture**: Validated" >> $GITHUB_STEP_SUMMARY
          echo "âœ… **Performance**: Benchmarked" >> $GITHUB_STEP_SUMMARY
          echo "âœ… **Security**: Scanned" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“‹ **Core package ready for deployment!**" >> $GITHUB_STEP_SUMMARY