# Default values for pynomaly-complete production deployment
# This is a comprehensive Helm values file for full production setup

# Global configuration
global:
  imageRegistry: ""
  imagePullSecrets: []
  storageClass: "fast-ssd"
  namespace: "pynomaly-production"

# Application configuration
app:
  name: pynomaly
  version: "1.0.0"
  environment: production
  
  # Image configuration
  image:
    registry: docker.io
    repository: pynomaly/api
    tag: "1.0.0"
    pullPolicy: IfNotPresent
    pullSecrets: []
  
  # Deployment configuration
  replicaCount: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  
  # Resource configuration
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "4Gi"
      cpu: "2000m"
  
  # Service configuration
  service:
    type: ClusterIP
    port: 8000
    targetPort: 8000
    annotations: {}
  
  # Health checks
  healthcheck:
    enabled: true
    path: "/health"
    port: 8000
    initialDelaySeconds: 60
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 3
  
  readinessProbe:
    enabled: true
    path: "/ready"
    port: 8000
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  
  # Environment variables
  env:
    - name: ENVIRONMENT
      value: "production"
    - name: LOG_LEVEL
      value: "INFO"
    - name: API_HOST
      value: "0.0.0.0"
    - name: API_PORT
      value: "8000"
    - name: PROMETHEUS_METRICS_PORT
      value: "9090"
  
  # Secret environment variables
  envSecrets:
    - name: DATABASE_URL
      secretName: pynomaly-secrets
      secretKey: database-url
    - name: REDIS_URL
      secretName: pynomaly-secrets
      secretKey: redis-url
    - name: JWT_SECRET_KEY
      secretName: pynomaly-secrets
      secretKey: jwt-secret
    - name: SECRET_KEY
      secretName: pynomaly-secrets
      secretKey: app-secret
  
  # Volumes
  volumes:
    storage:
      enabled: true
      size: 10Gi
      accessMode: ReadWriteOnce
      storageClass: fast-ssd
    logs:
      enabled: true
      size: 5Gi
      accessMode: ReadWriteOnce
      storageClass: standard
  
  # Annotations
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
    prometheus.io/path: "/metrics"

# Worker configuration
workers:
  training:
    enabled: true
    image:
      repository: pynomaly/worker
      tag: "1.0.0"
    replicaCount: 2
    resources:
      requests:
        memory: "2Gi"
        cpu: "1000m"
      limits:
        memory: "8Gi"
        cpu: "4000m"
    env:
      - name: WORKER_QUEUE
        value: "model_training,anomaly_detection"
      - name: WORKER_CONCURRENCY
        value: "4"
  
  drift:
    enabled: true
    image:
      repository: pynomaly/worker
      tag: "1.0.0"
    replicaCount: 1
    resources:
      requests:
        memory: "1Gi"
        cpu: "500m"
      limits:
        memory: "4Gi"
        cpu: "2000m"
    env:
      - name: WORKER_QUEUE
        value: "drift_monitoring,alert_processing"
      - name: WORKER_CONCURRENCY
        value: "2"
      - name: DRIFT_CHECK_INTERVAL
        value: "3600"
  
  scheduler:
    enabled: true
    image:
      repository: pynomaly/scheduler
      tag: "1.0.0"
    replicaCount: 1
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "1Gi"
        cpu: "500m"
  
  flower:
    enabled: true
    image:
      repository: pynomaly/flower
      tag: "1.0.0"
    replicaCount: 1
    service:
      type: ClusterIP
      port: 5555
    auth:
      username: admin
      password: flower_secret

# Autoscaling configuration
autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 25
          periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
        - type: Percent
          value: 100
          periodSeconds: 30

# Database configuration
postgresql:
  enabled: true
  auth:
    postgresPassword: "postgres_super_secret_2024"
    username: "pynomaly"
    password: "pynomaly_secret_2024"
    database: "pynomaly"
  primary:
    persistence:
      enabled: true
      storageClass: fast-ssd
      size: 20Gi
    resources:
      requests:
        memory: "512Mi"
        cpu: "250m"
      limits:
        memory: "2Gi"
        cpu: "1000m"
    configuration: |
      shared_preload_libraries = 'pg_stat_statements'
      pg_stat_statements.track = all
      log_statement = all
      log_destination = stderr
      logging_collector = on
      log_rotation_age = 1d
      log_rotation_size = 100MB
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true

# Redis configuration
redis:
  enabled: true
  auth:
    enabled: true
    password: "redis_secret_2024"
  master:
    persistence:
      enabled: true
      storageClass: fast-ssd
      size: 5Gi
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "1Gi"
        cpu: "500m"
    configuration: |
      appendonly yes
      appendfsync everysec
      auto-aof-rewrite-percentage 100
      auto-aof-rewrite-min-size 64mb
      save 900 1 300 10 60 10000
      maxmemory 512mb
      maxmemory-policy allkeys-lru
      tcp-keepalive 60
      timeout 300
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true

# Monitoring configuration
monitoring:
  prometheus:
    enabled: true
    server:
      persistentVolume:
        enabled: true
        size: 50Gi
        storageClass: fast-ssd
      resources:
        requests:
          memory: "2Gi"
          cpu: "500m"
        limits:
          memory: "8Gi"
          cpu: "2000m"
      retention: "30d"
      retentionSize: "10GB"
    nodeExporter:
      enabled: true
    kubeStateMetrics:
      enabled: true
    alertmanager:
      enabled: true
      persistentVolume:
        enabled: true
        size: 2Gi
        storageClass: fast-ssd
    serverFiles:
      prometheus.yml:
        scrape_configs:
          - job_name: 'pynomaly-api'
            static_configs:
              - targets: ['pynomaly-api:9090']
            scrape_interval: 15s
            metrics_path: /metrics
          - job_name: 'pynomaly-workers'
            static_configs:
              - targets: ['pynomaly-worker-training:9090', 'pynomaly-worker-drift:9090']
            scrape_interval: 30s
        rule_files:
          - "/etc/prometheus/pynomaly-alerts.yml"
  
  grafana:
    enabled: true
    persistence:
      enabled: true
      size: 10Gi
      storageClass: fast-ssd
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "1Gi"
        cpu: "500m"
    adminPassword: "grafana_admin_secret_2024"
    sidecar:
      dashboards:
        enabled: true
        searchNamespace: ALL
      datasources:
        enabled: true
        searchNamespace: ALL
    dashboardProviders:
      dashboardproviders.yaml:
        apiVersion: 1
        providers:
        - name: 'pynomaly-dashboards'
          orgId: 1
          folder: 'Pynomaly'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/pynomaly
    dashboards:
      pynomaly:
        pynomaly-overview:
          url: https://raw.githubusercontent.com/your-org/pynomaly/main/deploy/grafana/dashboards/overview.json
        pynomaly-performance:
          url: https://raw.githubusercontent.com/your-org/pynomaly/main/deploy/grafana/dashboards/performance.json
        pynomaly-security:
          url: https://raw.githubusercontent.com/your-org/pynomaly/main/deploy/grafana/dashboards/security.json

# Distributed tracing configuration
tracing:
  jaeger:
    enabled: true
    storage:
      type: badger
      badger:
        ephemeral: false
        persistence:
          enabled: true
          size: 30Gi
          storageClass: fast-ssd
    collector:
      resources:
        requests:
          memory: "256Mi"
          cpu: "100m"
        limits:
          memory: "1Gi"
          cpu: "500m"
    query:
      resources:
        requests:
          memory: "256Mi"
          cpu: "100m"
        limits:
          memory: "512Mi"
          cpu: "250m"
    agent:
      resources:
        requests:
          memory: "64Mi"
          cpu: "50m"
        limits:
          memory: "128Mi"
          cpu: "100m"
  
  otelCollector:
    enabled: true
    image:
      repository: otel/opentelemetry-collector-contrib
      tag: latest
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "1Gi"
        cpu: "500m"
    config: |
      receivers:
        otlp:
          protocols:
            grpc:
              endpoint: 0.0.0.0:4317
            http:
              endpoint: 0.0.0.0:4318
      processors:
        batch:
          timeout: 1s
          send_batch_size: 1024
        memory_limiter:
          limit_mib: 512
      exporters:
        jaeger:
          endpoint: jaeger-collector:14250
          tls:
            insecure: true
        prometheus:
          endpoint: "0.0.0.0:8889"
          namespace: "pynomaly"
      service:
        pipelines:
          traces:
            receivers: [otlp]
            processors: [memory_limiter, batch]
            exporters: [jaeger]
          metrics:
            receivers: [otlp]
            processors: [memory_limiter, batch]
            exporters: [prometheus]

# Logging configuration
logging:
  elasticsearch:
    enabled: true
    replicas: 1
    minimumMasterNodes: 1
    persistence:
      enabled: true
      size: 100Gi
      storageClass: fast-ssd
    resources:
      requests:
        memory: "2Gi"
        cpu: "500m"
      limits:
        memory: "4Gi"
        cpu: "2000m"
    esConfig:
      elasticsearch.yml: |
        node.name: pynomaly-es-node
        cluster.name: pynomaly-cluster
        discovery.type: single-node
        bootstrap.memory_lock: true
        xpack.security.enabled: false
        xpack.security.enrollment.enabled: false
    esJavaOpts: "-Xms1g -Xmx1g"
  
  kibana:
    enabled: true
    elasticsearchHosts: "http://elasticsearch-master:9200"
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "1Gi"
        cpu: "500m"
    persistence:
      enabled: true
      size: 5Gi
      storageClass: fast-ssd
  
  logstash:
    enabled: true
    replicas: 1
    resources:
      requests:
        memory: "512Mi"
        cpu: "250m"
      limits:
        memory: "2Gi"
        cpu: "1000m"
    logstashConfig:
      logstash.yml: |
        http.host: "0.0.0.0"
        xpack.monitoring.elasticsearch.hosts: [ "http://elasticsearch-master:9200" ]
    logstashPipeline:
      main: |
        input {
          beats {
            port => 5044
          }
        }
        filter {
          if [fields][service] == "pynomaly" {
            json {
              source => "message"
            }
            date {
              match => [ "timestamp", "ISO8601" ]
            }
          }
        }
        output {
          elasticsearch {
            hosts => ["elasticsearch-master:9200"]
            index => "pynomaly-logs-%{+YYYY.MM.dd}"
          }
        }
  
  filebeat:
    enabled: true
    filebeatConfig:
      filebeat.yml: |
        filebeat.inputs:
        - type: container
          paths:
            - /var/log/containers/pynomaly-*_pynomaly-production_*.log
          processors:
          - add_kubernetes_metadata:
              host: ${NODE_NAME}
              matchers:
              - logs_path:
                  logs_path: "/var/log/containers/"
        
        output.logstash:
          hosts: ["logstash:5044"]
        
        logging.level: info

# Ingress configuration
ingress:
  enabled: true
  className: "nginx"
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  hosts:
    - host: api.pynomaly.local
      paths:
        - path: /
          pathType: Prefix
          service:
            name: pynomaly-api
            port: 8000
    - host: grafana.pynomaly.local
      paths:
        - path: /
          pathType: Prefix
          service:
            name: grafana
            port: 3000
    - host: jaeger.pynomaly.local
      paths:
        - path: /
          pathType: Prefix
          service:
            name: jaeger-query
            port: 16686
    - host: kibana.pynomaly.local
      paths:
        - path: /
          pathType: Prefix
          service:
            name: kibana
            port: 5601
  tls:
    - secretName: pynomaly-tls-secret
      hosts:
        - api.pynomaly.local
        - grafana.pynomaly.local
        - jaeger.pynomaly.local
        - kibana.pynomaly.local

# Security configuration
security:
  networkPolicies:
    enabled: true
    policyTypes:
      - Ingress
      - Egress
    ingress:
      - from:
        - namespaceSelector:
            matchLabels:
              name: ingress-nginx
        - namespaceSelector:
            matchLabels:
              name: pynomaly-production
    egress:
      - to:
        - namespaceSelector:
            matchLabels:
              name: pynomaly-production
      - to: []
        ports:
        - protocol: TCP
          port: 53
        - protocol: UDP
          port: 53
        - protocol: TCP
          port: 443
        - protocol: TCP
          port: 80
  
  podSecurityPolicy:
    enabled: true
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
  
  rbac:
    enabled: true
    serviceAccount:
      create: true
      name: pynomaly-sa
      annotations: {}
    rules:
      - apiGroups: [""]
        resources: ["configmaps", "secrets"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["apps"]
        resources: ["deployments", "replicasets"]
        verbs: ["get", "list", "watch"]

# Backup and disaster recovery
backup:
  enabled: true
  schedule: "0 2 * * *"  # Daily at 2 AM
  retention: "30d"
  storage:
    type: s3
    s3:
      bucket: pynomaly-backups
      region: us-east-1
      accessKey: ""
      secretKey: ""
  databases:
    postgresql:
      enabled: true
    redis:
      enabled: true
  volumes:
    - name: app-storage
      schedule: "0 3 * * *"
    - name: prometheus-data
      schedule: "0 4 * * *"

# Configuration management
configManagement:
  enabled: true
  source: git
  git:
    repository: https://github.com/your-org/pynomaly-config
    branch: production
    path: configs/
    syncInterval: 300  # 5 minutes
  
  configs:
    - name: app-config
      path: app/config.yaml
      target: configmap
    - name: monitoring-config
      path: monitoring/prometheus.yml
      target: configmap
    - name: logging-config
      path: logging/filebeat.yml
      target: configmap

# Secrets management
secrets:
  external:
    enabled: true
    provider: vault  # vault, aws-secrets-manager, azure-key-vault
    vault:
      address: https://vault.company.com:8200
      role: pynomaly-production
      secretPath: secret/pynomaly/production
    sync:
      interval: 3600  # 1 hour
  
  managed:
    - name: database-credentials
      type: database
      database: postgresql
    - name: redis-credentials
      type: cache
      service: redis
    - name: api-keys
      type: application
      keys:
        - jwt-secret
        - app-secret
        - encryption-key

# Development and testing overrides
development:
  enabled: false
  replicas: 1
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "1Gi"
      cpu: "500m"
  monitoring:
    enabled: false
  tracing:
    enabled: true
    persistence: false
  logging:
    enabled: false
