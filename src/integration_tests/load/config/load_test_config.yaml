# Load Testing Configuration for Pynomaly
# This file contains configuration for various load testing scenarios

# Global settings
global:
  project_name: "Pynomaly"
  version: "1.0.0"
  test_environment: "staging"
  
# Target environments
environments:
  staging:
    host: "http://localhost:8000"
    description: "Staging environment for load testing"
    auth_required: true
    ssl_verify: false
    timeout: 30
    
  production:
    host: "https://api.pynomaly.com"
    description: "Production environment (use with caution)"
    auth_required: true
    ssl_verify: true
    timeout: 60

# Test scenarios configuration
scenarios:
  basic:
    description: "Basic load test for quick validation"
    users: 50
    spawn_rate: 10
    duration: "5m"
    user_classes:
      - "AnomalyDetectionUser"
      - "MonitoringUser"
    weights:
      AnomalyDetectionUser: 70
      MonitoringUser: 30
    
  comprehensive:
    description: "Comprehensive test covering all major features"
    users: 100
    spawn_rate: 20
    duration: "30m"
    user_classes:
      - "AnomalyDetectionUser"
      - "ModelTrainingUser"
      - "DataManagementUser"
      - "MonitoringUser"
    weights:
      AnomalyDetectionUser: 60
      ModelTrainingUser: 20
      DataManagementUser: 15
      MonitoringUser: 5
    
  stress:
    description: "Stress test to find system limits"
    users: 200
    spawn_rate: 50
    duration: "10m"
    user_classes:
      - "StressTestUser"
      - "HighVolumeUser"
    weights:
      StressTestUser: 60
      HighVolumeUser: 40
    
  endurance:
    description: "Long-running test for stability validation"
    users: 25
    spawn_rate: 5
    duration: "60m"
    user_classes:
      - "LongRunningUser"
      - "SustainedLoadUser"
    weights:
      LongRunningUser: 70
      SustainedLoadUser: 30
    
  spike:
    description: "Variable load test simulating traffic spikes"
    phases:
      - users: 25
        spawn_rate: 5
        duration: "2m"
      - users: 100
        spawn_rate: 25
        duration: "3m"
      - users: 50
        spawn_rate: 10
        duration: "2m"
      - users: 200
        spawn_rate: 50
        duration: "1m"
      - users: 25
        spawn_rate: 5
        duration: "2m"
    
  soak:
    description: "Extended duration test for memory leaks"
    users: 50
    spawn_rate: 10
    duration: "120m"
    user_classes:
      - "AnomalyDetectionUser"
      - "DataManagementUser"
    weights:
      AnomalyDetectionUser: 80
      DataManagementUser: 20
    
  volume:
    description: "High data volume test"
    users: 100
    spawn_rate: 30
    duration: "15m"
    user_classes:
      - "HighVolumeUser"
      - "DataManagementUser"
    weights:
      HighVolumeUser: 70
      DataManagementUser: 30
    
  api:
    description: "API-focused load test"
    users: 75
    spawn_rate: 15
    duration: "20m"
    user_classes:
      - "APITestUser"
      - "AnomalyDetectionUser"
    weights:
      APITestUser: 40
      AnomalyDetectionUser: 60
    tags:
      - "api"
    
  ui:
    description: "UI-focused load test"
    users: 30
    spawn_rate: 5
    duration: "10m"
    user_classes:
      - "MonitoringUser"
      - "DataManagementUser"
    weights:
      MonitoringUser: 60
      DataManagementUser: 40
    tags:
      - "ui"

# Performance thresholds
thresholds:
  response_time:
    p50: 500    # 50th percentile response time (ms)
    p95: 1000   # 95th percentile response time (ms)
    p99: 2000   # 99th percentile response time (ms)
    max: 5000   # Maximum acceptable response time (ms)
  
  error_rate:
    max: 0.01   # Maximum error rate (1%)
    
  throughput:
    min: 100    # Minimum requests per second
    
  resource_usage:
    cpu_max: 80     # Maximum CPU usage percentage
    memory_max: 80  # Maximum memory usage percentage
    disk_max: 80    # Maximum disk usage percentage

# Data generation settings
data_generation:
  time_series:
    default_size: 1000
    anomaly_rate: 0.05
    value_range: [-10, 10]
    noise_level: 0.1
    
  batch_processing:
    default_batch_size: 100
    max_batch_size: 1000
    
  datasets:
    small_dataset: 500
    medium_dataset: 5000
    large_dataset: 50000

# Authentication settings
authentication:
  method: "jwt"
  token_expiry: 3600
  refresh_enabled: true
  test_users:
    count: 1000
    prefix: "loadtest_user_"
    password: "loadtest_password"

# Monitoring configuration
monitoring:
  enabled: true
  metrics:
    - "response_time"
    - "error_rate"
    - "throughput"
    - "active_users"
    - "system_resources"
  
  alerts:
    high_error_rate: 0.05
    high_response_time: 2000
    low_throughput: 50
    
  collection_interval: 10  # seconds

# Reporting configuration
reporting:
  formats:
    - "html"
    - "csv"
    - "json"
  
  charts:
    - "response_time_distribution"
    - "error_rate_timeline"
    - "throughput_timeline"
    - "active_users_timeline"
    
  export_raw_data: true
  compress_results: true

# Distributed testing settings
distributed:
  enabled: false
  master_host: "localhost"
  master_port: 5557
  worker_count: 4
  
  # Worker configuration
  worker_config:
    cpu_limit: "1000m"
    memory_limit: "1Gi"
    
  # Load balancing
  load_balancing:
    strategy: "round_robin"
    health_check_interval: 30

# Advanced settings
advanced:
  # Connection settings
  connection:
    pool_size: 50
    keepalive: true
    timeout: 30
    retries: 3
    
  # Rate limiting
  rate_limiting:
    enabled: true
    requests_per_second: 1000
    burst_size: 100
    
  # Caching
  caching:
    enabled: true
    ttl: 300
    max_size: 1000
    
  # Logging
  logging:
    level: "INFO"
    format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    file: "load_test.log"
    max_size: "10MB"
    backup_count: 5

# Test data templates
test_data_templates:
  anomaly_detection:
    single_point:
      timestamp: "2024-01-01T00:00:00Z"
      value: 0.0
      features:
        feature_1: 0.5
        feature_2: 0.3
        feature_3: 0.8
    
    batch_data:
      count: 100
      value_range: [-5, 5]
      timestamp_interval: 60  # seconds
      
  model_training:
    dataset:
      name: "test_dataset"
      size: 1000
      anomaly_percentage: 0.1
      
    configuration:
      algorithm: "isolation_forest"
      parameters:
        contamination: 0.1
        n_estimators: 100
        max_samples: "auto"

# Environment-specific overrides
environment_overrides:
  staging:
    thresholds:
      response_time:
        p95: 1500
        p99: 3000
    
  production:
    thresholds:
      response_time:
        p95: 800
        p99: 1500
      error_rate:
        max: 0.005
    
    monitoring:
      alerts:
        high_error_rate: 0.01
        high_response_time: 1000

# Custom user behavior patterns
user_patterns:
  normal_user:
    think_time: [1, 3]
    session_duration: [5, 30]  # minutes
    actions_per_session: [5, 20]
    
  power_user:
    think_time: [0.5, 1.5]
    session_duration: [10, 60]
    actions_per_session: [20, 100]
    
  casual_user:
    think_time: [3, 10]
    session_duration: [2, 10]
    actions_per_session: [1, 5]

# Integration test settings
integration:
  database:
    test_connections: true
    max_connections: 100
    connection_timeout: 30
    
  cache:
    test_redis: true
    test_mongodb: true
    
  external_services:
    test_apis: true
    timeout: 60
    
  monitoring:
    test_metrics: true
    test_alerts: true

# Security test settings
security:
  authentication_tests:
    - "invalid_tokens"
    - "expired_tokens"
    - "token_refresh"
    
  authorization_tests:
    - "unauthorized_access"
    - "privilege_escalation"
    
  input_validation:
    - "sql_injection"
    - "xss_attempts"
    - "malformed_requests"

# Cleanup settings
cleanup:
  auto_cleanup: true
  cleanup_interval: 300  # seconds
  max_test_data_age: 3600  # seconds
  
  cleanup_actions:
    - "delete_test_users"
    - "delete_test_datasets"
    - "delete_test_models"
    - "clear_cache"

# Debugging settings
debug:
  enabled: false
  log_requests: false
  log_responses: false
  save_failed_requests: true
  verbose_errors: true
